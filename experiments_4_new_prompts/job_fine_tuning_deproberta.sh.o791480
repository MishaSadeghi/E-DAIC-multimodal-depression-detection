### Starting TaskPrologue of job 791480 on tg094 at Mon 25 Mar 2024 12:02:50 PM CET
Running on cores 64-95 with governor ondemand
Mon Mar 25 12:02:50 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:81:00.0 Off |                    0 |
| N/A   33C    P0             54W /  400W |       0MiB /  40960MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

/home/hpc/empk/empk004h/depression-detection/experiments_4_new_prompts
folder_path:  /home/hpc/empk/empk004h/depression-detection/data/original_transcripts_completions/prompt_3
csv_files:  ['df_test_prompt3.csv', 'df_dev_prompt3.csv', 'df_train_prompt3.csv']
fine tuning for prompt:  prompt_3
len train_loader:  21
Epoch 0, Batch 0, Learning Rate: 0.00000500, Train Loss: 1.437
Epoch 0, Batch 1, Learning Rate: 0.00000500, Train Loss: 1.004
Epoch 0, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.657
Epoch 0, Batch 3, Learning Rate: 0.00000500, Train Loss: 1.349
Epoch 0, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.876
Epoch 0, Batch 5, Learning Rate: 0.00000500, Train Loss: 1.341
Epoch 0, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.601
Epoch 0, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.960
Epoch 0, Batch 8, Learning Rate: 0.00000500, Train Loss: 1.123
Epoch 0, Batch 9, Learning Rate: 0.00000500, Train Loss: 1.041
Epoch 0, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.505
Epoch 0, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.634
Epoch 0, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.769
Epoch 0, Batch 13, Learning Rate: 0.00000500, Train Loss: 1.427
Epoch 0, Batch 14, Learning Rate: 0.00000500, Train Loss: 1.010
Epoch 0, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.653
Epoch 0, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.862
Epoch 0, Batch 17, Learning Rate: 0.00000500, Train Loss: 1.124
Epoch 0, Batch 18, Learning Rate: 0.00000500, Train Loss: 1.046
Epoch 0, Batch 19, Learning Rate: 0.00000500, Train Loss: 1.015
Epoch 0, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.915
Epoch 0, Dev Loss: 0.874, Dev Accuracy: 0.607
Learning rate adjusted. New learning rate: 0.00000500
len train_loader:  21
Epoch 1, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.687
Epoch 1, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.944
Epoch 1, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.839
Epoch 1, Batch 3, Learning Rate: 0.00000500, Train Loss: 1.008
Epoch 1, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.914
Epoch 1, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.881
Epoch 1, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.853
Epoch 1, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.521
Epoch 1, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.602
Epoch 1, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.722
Epoch 1, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.655
Epoch 1, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.273
Epoch 1, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.816
Epoch 1, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.701
Epoch 1, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.519
Epoch 1, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.974
Epoch 1, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.650
Epoch 1, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.544
Epoch 1, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.700
Epoch 1, Batch 19, Learning Rate: 0.00000500, Train Loss: 1.579
Epoch 1, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.569
Epoch 1, Dev Loss: 0.783, Dev Accuracy: 0.696
Learning rate adjusted. New learning rate: 0.00000500
len train_loader:  21
Epoch 2, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.651
Epoch 2, Batch 1, Learning Rate: 0.00000500, Train Loss: 1.026
Epoch 2, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.551
Epoch 2, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.728
Epoch 2, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.682
Epoch 2, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.570
Epoch 2, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.633
Epoch 2, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.763
Epoch 2, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.729
Epoch 2, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.526
Epoch 2, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.938
Epoch 2, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.258
Epoch 2, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.396
Epoch 2, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.667
Epoch 2, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.898
Epoch 2, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.716
Epoch 2, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.593
Epoch 2, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.495
Epoch 2, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.528
Epoch 2, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.181
Epoch 2, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.196
Epoch 2, Dev Loss: 0.852, Dev Accuracy: 0.732
Learning rate adjusted. New learning rate: 0.00000500
len train_loader:  21
Epoch 3, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.385
Epoch 3, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.201
Epoch 3, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.509
Epoch 3, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.424
Epoch 3, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.161
Epoch 3, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.580
Epoch 3, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.637
Epoch 3, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.224
Epoch 3, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.713
Epoch 3, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.464
Epoch 3, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.381
Epoch 3, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.654
Epoch 3, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.659
Epoch 3, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.582
Epoch 3, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.495
Epoch 3, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.800
Epoch 3, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.273
Epoch 3, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.284
Epoch 3, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.543
Epoch 3, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.555
Epoch 3, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.683
Epoch 3, Dev Loss: 1.027, Dev Accuracy: 0.643
Learning rate adjusted. New learning rate: 0.00000500
len train_loader:  21
Epoch 4, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.208
Epoch 4, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.154
Epoch 4, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.350
Epoch 4, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.649
Epoch 4, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.690
Epoch 4, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.827
Epoch 4, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.491
Epoch 4, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.808
Epoch 4, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.670
Epoch 4, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.391
Epoch 4, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.559
Epoch 4, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.468
Epoch 4, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.364
Epoch 4, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.259
Epoch 4, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.215
Epoch 4, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.256
Epoch 4, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.253
Epoch 4, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.098
Epoch 4, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.332
Epoch 4, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.517
Epoch 4, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.108
Epoch 4, Dev Loss: 1.171, Dev Accuracy: 0.589
Learning rate adjusted. New learning rate: 0.00000500
len train_loader:  21
Epoch 5, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.230
Epoch 5, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.539
Epoch 5, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.523
Epoch 5, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.214
Epoch 5, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.171
Epoch 5, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.156
Epoch 5, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.090
Epoch 5, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.203
Epoch 5, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.458
Epoch 5, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.240
Epoch 5, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.103
Epoch 5, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.118
Epoch 5, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.100
Epoch 5, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.209
Epoch 5, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.142
Epoch 5, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.318
Epoch 5, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.073
Epoch 5, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.193
Epoch 5, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.186
Epoch 5, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.126
Epoch 5, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.068
Epoch 5, Dev Loss: 1.270, Dev Accuracy: 0.625
Learning rate adjusted. New learning rate: 0.00000250
len train_loader:  21
Epoch 6, Batch 0, Learning Rate: 0.00000250, Train Loss: 0.090
Epoch 6, Batch 1, Learning Rate: 0.00000250, Train Loss: 0.068
Epoch 6, Batch 2, Learning Rate: 0.00000250, Train Loss: 0.087
Epoch 6, Batch 3, Learning Rate: 0.00000250, Train Loss: 0.044
Epoch 6, Batch 4, Learning Rate: 0.00000250, Train Loss: 0.087
Epoch 6, Batch 5, Learning Rate: 0.00000250, Train Loss: 0.682
Epoch 6, Batch 6, Learning Rate: 0.00000250, Train Loss: 0.045
Epoch 6, Batch 7, Learning Rate: 0.00000250, Train Loss: 0.097
Epoch 6, Batch 8, Learning Rate: 0.00000250, Train Loss: 0.029
Epoch 6, Batch 9, Learning Rate: 0.00000250, Train Loss: 0.064
Epoch 6, Batch 10, Learning Rate: 0.00000250, Train Loss: 0.091
Epoch 6, Batch 11, Learning Rate: 0.00000250, Train Loss: 0.068
Epoch 6, Batch 12, Learning Rate: 0.00000250, Train Loss: 0.119
Epoch 6, Batch 13, Learning Rate: 0.00000250, Train Loss: 0.584
Epoch 6, Batch 14, Learning Rate: 0.00000250, Train Loss: 0.124
Epoch 6, Batch 15, Learning Rate: 0.00000250, Train Loss: 0.120
Epoch 6, Batch 16, Learning Rate: 0.00000250, Train Loss: 0.070
Epoch 6, Batch 17, Learning Rate: 0.00000250, Train Loss: 0.124
Epoch 6, Batch 18, Learning Rate: 0.00000250, Train Loss: 0.098
Epoch 6, Batch 19, Learning Rate: 0.00000250, Train Loss: 0.011
Epoch 6, Batch 20, Learning Rate: 0.00000250, Train Loss: 0.291
Epoch 6, Dev Loss: 1.297, Dev Accuracy: 0.625
Learning rate adjusted. New learning rate: 0.00000250
len train_loader:  21
Epoch 7, Batch 0, Learning Rate: 0.00000250, Train Loss: 0.096
Epoch 7, Batch 1, Learning Rate: 0.00000250, Train Loss: 0.010
Epoch 7, Batch 2, Learning Rate: 0.00000250, Train Loss: 0.116
Epoch 7, Batch 3, Learning Rate: 0.00000250, Train Loss: 0.020
Epoch 7, Batch 4, Learning Rate: 0.00000250, Train Loss: 0.080
Epoch 7, Batch 5, Learning Rate: 0.00000250, Train Loss: 0.031
Epoch 7, Batch 6, Learning Rate: 0.00000250, Train Loss: 0.016
Epoch 7, Batch 7, Learning Rate: 0.00000250, Train Loss: 0.048
Epoch 7, Batch 8, Learning Rate: 0.00000250, Train Loss: 0.647
Epoch 7, Batch 9, Learning Rate: 0.00000250, Train Loss: 0.038
Epoch 7, Batch 10, Learning Rate: 0.00000250, Train Loss: 0.016
Epoch 7, Batch 11, Learning Rate: 0.00000250, Train Loss: 0.038
Epoch 7, Batch 12, Learning Rate: 0.00000250, Train Loss: 0.024
Epoch 7, Batch 13, Learning Rate: 0.00000250, Train Loss: 0.059
Epoch 7, Batch 14, Learning Rate: 0.00000250, Train Loss: 0.008
Epoch 7, Batch 15, Learning Rate: 0.00000250, Train Loss: 0.076
Epoch 7, Batch 16, Learning Rate: 0.00000250, Train Loss: 0.013
Epoch 7, Batch 17, Learning Rate: 0.00000250, Train Loss: 0.076
Epoch 7, Batch 18, Learning Rate: 0.00000250, Train Loss: 0.258
Epoch 7, Batch 19, Learning Rate: 0.00000250, Train Loss: 0.090
Epoch 7, Batch 20, Learning Rate: 0.00000250, Train Loss: 0.025
Epoch 7, Dev Loss: 1.617, Dev Accuracy: 0.607
Learning rate adjusted. New learning rate: 0.00000250
len train_loader:  21
Epoch 8, Batch 0, Learning Rate: 0.00000250, Train Loss: 0.015
Epoch 8, Batch 1, Learning Rate: 0.00000250, Train Loss: 0.495
Epoch 8, Batch 2, Learning Rate: 0.00000250, Train Loss: 0.058
Epoch 8, Batch 3, Learning Rate: 0.00000250, Train Loss: 0.026
Epoch 8, Batch 4, Learning Rate: 0.00000250, Train Loss: 0.015
Epoch 8, Batch 5, Learning Rate: 0.00000250, Train Loss: 0.007
Epoch 8, Batch 6, Learning Rate: 0.00000250, Train Loss: 0.185
Epoch 8, Batch 7, Learning Rate: 0.00000250, Train Loss: 0.015
Epoch 8, Batch 8, Learning Rate: 0.00000250, Train Loss: 0.016
Epoch 8, Batch 9, Learning Rate: 0.00000250, Train Loss: 0.011
Epoch 8, Batch 10, Learning Rate: 0.00000250, Train Loss: 0.026
Epoch 8, Batch 11, Learning Rate: 0.00000250, Train Loss: 0.372
Epoch 8, Batch 12, Learning Rate: 0.00000250, Train Loss: 0.019
Epoch 8, Batch 13, Learning Rate: 0.00000250, Train Loss: 0.006
Epoch 8, Batch 14, Learning Rate: 0.00000250, Train Loss: 0.023
Epoch 8, Batch 15, Learning Rate: 0.00000250, Train Loss: 0.019
Epoch 8, Batch 16, Learning Rate: 0.00000250, Train Loss: 0.028
Epoch 8, Batch 17, Learning Rate: 0.00000250, Train Loss: 0.018
Epoch 8, Batch 18, Learning Rate: 0.00000250, Train Loss: 0.023
Epoch 8, Batch 19, Learning Rate: 0.00000250, Train Loss: 0.028
Epoch 8, Batch 20, Learning Rate: 0.00000250, Train Loss: 0.056
Epoch 8, Dev Loss: 1.673, Dev Accuracy: 0.607
Learning rate adjusted. New learning rate: 0.00000250
len train_loader:  21
Epoch 9, Batch 0, Learning Rate: 0.00000250, Train Loss: 0.048
Epoch 9, Batch 1, Learning Rate: 0.00000250, Train Loss: 0.015
Epoch 9, Batch 2, Learning Rate: 0.00000250, Train Loss: 0.030
Epoch 9, Batch 3, Learning Rate: 0.00000250, Train Loss: 0.339
Epoch 9, Batch 4, Learning Rate: 0.00000250, Train Loss: 0.006
Epoch 9, Batch 5, Learning Rate: 0.00000250, Train Loss: 0.037
Epoch 9, Batch 6, Learning Rate: 0.00000250, Train Loss: 0.024
Epoch 9, Batch 7, Learning Rate: 0.00000250, Train Loss: 0.006
Epoch 9, Batch 8, Learning Rate: 0.00000250, Train Loss: 0.159
Epoch 9, Batch 9, Learning Rate: 0.00000250, Train Loss: 0.011
Epoch 9, Batch 10, Learning Rate: 0.00000250, Train Loss: 0.010
Epoch 9, Batch 11, Learning Rate: 0.00000250, Train Loss: 0.013
Epoch 9, Batch 12, Learning Rate: 0.00000250, Train Loss: 0.383
Epoch 9, Batch 13, Learning Rate: 0.00000250, Train Loss: 0.021
Epoch 9, Batch 14, Learning Rate: 0.00000250, Train Loss: 0.008
Epoch 9, Batch 15, Learning Rate: 0.00000250, Train Loss: 0.011
Epoch 9, Batch 16, Learning Rate: 0.00000250, Train Loss: 0.013
Epoch 9, Batch 17, Learning Rate: 0.00000250, Train Loss: 0.005
Epoch 9, Batch 18, Learning Rate: 0.00000250, Train Loss: 0.003
Epoch 9, Batch 19, Learning Rate: 0.00000250, Train Loss: 0.006
Epoch 9, Batch 20, Learning Rate: 0.00000250, Train Loss: 0.004
Epoch 9, Dev Loss: 1.788, Dev Accuracy: 0.589
Learning rate adjusted. New learning rate: 0.00000125
len train_loader:  21
Epoch 10, Batch 0, Learning Rate: 0.00000125, Train Loss: 0.008
Epoch 10, Batch 1, Learning Rate: 0.00000125, Train Loss: 0.005
Epoch 10, Batch 2, Learning Rate: 0.00000125, Train Loss: 0.007
Epoch 10, Batch 3, Learning Rate: 0.00000125, Train Loss: 0.447
Epoch 10, Batch 4, Learning Rate: 0.00000125, Train Loss: 0.009
Epoch 10, Batch 5, Learning Rate: 0.00000125, Train Loss: 0.007
Epoch 10, Batch 6, Learning Rate: 0.00000125, Train Loss: 0.012
Epoch 10, Batch 7, Learning Rate: 0.00000125, Train Loss: 0.019
Epoch 10, Batch 8, Learning Rate: 0.00000125, Train Loss: 0.005
Epoch 10, Batch 9, Learning Rate: 0.00000125, Train Loss: 0.006
Epoch 10, Batch 10, Learning Rate: 0.00000125, Train Loss: 0.004
Epoch 10, Batch 11, Learning Rate: 0.00000125, Train Loss: 0.014
Epoch 10, Batch 12, Learning Rate: 0.00000125, Train Loss: 0.005
Epoch 10, Batch 13, Learning Rate: 0.00000125, Train Loss: 0.038
Epoch 10, Batch 14, Learning Rate: 0.00000125, Train Loss: 0.004
Epoch 10, Batch 15, Learning Rate: 0.00000125, Train Loss: 0.005
Epoch 10, Batch 16, Learning Rate: 0.00000125, Train Loss: 0.007
Epoch 10, Batch 17, Learning Rate: 0.00000125, Train Loss: 0.013
Epoch 10, Batch 18, Learning Rate: 0.00000125, Train Loss: 0.005
Epoch 10, Batch 19, Learning Rate: 0.00000125, Train Loss: 0.035
Epoch 10, Batch 20, Learning Rate: 0.00000125, Train Loss: 0.036
Epoch 10, Dev Loss: 1.730, Dev Accuracy: 0.661
Learning rate adjusted. New learning rate: 0.00000125
len train_loader:  21
Epoch 11, Batch 0, Learning Rate: 0.00000125, Train Loss: 0.432
Epoch 11, Batch 1, Learning Rate: 0.00000125, Train Loss: 0.010
Epoch 11, Batch 2, Learning Rate: 0.00000125, Train Loss: 0.006
Epoch 11, Batch 3, Learning Rate: 0.00000125, Train Loss: 0.006
Epoch 11, Batch 4, Learning Rate: 0.00000125, Train Loss: 0.005
Epoch 11, Batch 5, Learning Rate: 0.00000125, Train Loss: 0.009
Epoch 11, Batch 6, Learning Rate: 0.00000125, Train Loss: 0.004
Epoch 11, Batch 7, Learning Rate: 0.00000125, Train Loss: 0.007
Epoch 11, Batch 8, Learning Rate: 0.00000125, Train Loss: 0.008
Epoch 11, Batch 9, Learning Rate: 0.00000125, Train Loss: 0.007
Epoch 11, Batch 10, Learning Rate: 0.00000125, Train Loss: 0.003
Epoch 11, Batch 11, Learning Rate: 0.00000125, Train Loss: 0.008
Epoch 11, Batch 12, Learning Rate: 0.00000125, Train Loss: 0.004
Epoch 11, Batch 13, Learning Rate: 0.00000125, Train Loss: 0.029
Epoch 11, Batch 14, Learning Rate: 0.00000125, Train Loss: 0.005
Epoch 11, Batch 15, Learning Rate: 0.00000125, Train Loss: 0.006
Epoch 11, Batch 16, Learning Rate: 0.00000125, Train Loss: 0.007
Epoch 11, Batch 17, Learning Rate: 0.00000125, Train Loss: 0.007
Epoch 11, Batch 18, Learning Rate: 0.00000125, Train Loss: 0.002
Epoch 11, Batch 19, Learning Rate: 0.00000125, Train Loss: 0.005
Epoch 11, Batch 20, Learning Rate: 0.00000125, Train Loss: 0.004
Epoch 11, Dev Loss: 1.862, Dev Accuracy: 0.643
Learning rate adjusted. New learning rate: 0.00000125
len train_loader:  21
Epoch 12, Batch 0, Learning Rate: 0.00000125, Train Loss: 0.003
Epoch 12, Batch 1, Learning Rate: 0.00000125, Train Loss: 0.004
Epoch 12, Batch 2, Learning Rate: 0.00000125, Train Loss: 0.007
Epoch 12, Batch 3, Learning Rate: 0.00000125, Train Loss: 0.007
Epoch 12, Batch 4, Learning Rate: 0.00000125, Train Loss: 0.290
Epoch 12, Batch 5, Learning Rate: 0.00000125, Train Loss: 0.003
Epoch 12, Batch 6, Learning Rate: 0.00000125, Train Loss: 0.003
Epoch 12, Batch 7, Learning Rate: 0.00000125, Train Loss: 0.003
Epoch 12, Batch 8, Learning Rate: 0.00000125, Train Loss: 0.010
Epoch 12, Batch 9, Learning Rate: 0.00000125, Train Loss: 0.003
Epoch 12, Batch 10, Learning Rate: 0.00000125, Train Loss: 0.012
Epoch 12, Batch 11, Learning Rate: 0.00000125, Train Loss: 0.006
Epoch 12, Batch 12, Learning Rate: 0.00000125, Train Loss: 0.004
Epoch 12, Batch 13, Learning Rate: 0.00000125, Train Loss: 0.007
Epoch 12, Batch 14, Learning Rate: 0.00000125, Train Loss: 0.002
Epoch 12, Batch 15, Learning Rate: 0.00000125, Train Loss: 0.003
Epoch 12, Batch 16, Learning Rate: 0.00000125, Train Loss: 0.003
Epoch 12, Batch 17, Learning Rate: 0.00000125, Train Loss: 0.004
Epoch 12, Batch 18, Learning Rate: 0.00000125, Train Loss: 0.004
Epoch 12, Batch 19, Learning Rate: 0.00000125, Train Loss: 0.009
Epoch 12, Batch 20, Learning Rate: 0.00000125, Train Loss: 0.003
Epoch 12, Dev Loss: 1.976, Dev Accuracy: 0.643
Learning rate adjusted. New learning rate: 0.00000125
len train_loader:  21
Epoch 13, Batch 0, Learning Rate: 0.00000125, Train Loss: 0.007
Epoch 13, Batch 1, Learning Rate: 0.00000125, Train Loss: 0.003
Epoch 13, Batch 2, Learning Rate: 0.00000125, Train Loss: 0.005
Epoch 13, Batch 3, Learning Rate: 0.00000125, Train Loss: 0.001
Epoch 13, Batch 4, Learning Rate: 0.00000125, Train Loss: 0.004
Epoch 13, Batch 5, Learning Rate: 0.00000125, Train Loss: 0.002
Epoch 13, Batch 6, Learning Rate: 0.00000125, Train Loss: 0.002
Epoch 13, Batch 7, Learning Rate: 0.00000125, Train Loss: 0.003
Epoch 13, Batch 8, Learning Rate: 0.00000125, Train Loss: 0.005
Epoch 13, Batch 9, Learning Rate: 0.00000125, Train Loss: 0.005
Epoch 13, Batch 10, Learning Rate: 0.00000125, Train Loss: 0.003
Epoch 13, Batch 11, Learning Rate: 0.00000125, Train Loss: 0.001
Epoch 13, Batch 12, Learning Rate: 0.00000125, Train Loss: 0.004
Epoch 13, Batch 13, Learning Rate: 0.00000125, Train Loss: 0.002
Epoch 13, Batch 14, Learning Rate: 0.00000125, Train Loss: 0.003
Epoch 13, Batch 15, Learning Rate: 0.00000125, Train Loss: 0.002
Epoch 13, Batch 16, Learning Rate: 0.00000125, Train Loss: 0.002
Epoch 13, Batch 17, Learning Rate: 0.00000125, Train Loss: 0.001
Epoch 13, Batch 18, Learning Rate: 0.00000125, Train Loss: 0.029
Epoch 13, Batch 19, Learning Rate: 0.00000125, Train Loss: 0.003
Epoch 13, Batch 20, Learning Rate: 0.00000125, Train Loss: 0.720
Epoch 13, Dev Loss: 2.083, Dev Accuracy: 0.625
Learning rate adjusted. New learning rate: 0.00000063
len train_loader:  21
Epoch 14, Batch 0, Learning Rate: 0.00000063, Train Loss: 0.002
Epoch 14, Batch 1, Learning Rate: 0.00000063, Train Loss: 0.002
Epoch 14, Batch 2, Learning Rate: 0.00000063, Train Loss: 0.002
Epoch 14, Batch 3, Learning Rate: 0.00000063, Train Loss: 0.002
Epoch 14, Batch 4, Learning Rate: 0.00000063, Train Loss: 0.003
Epoch 14, Batch 5, Learning Rate: 0.00000063, Train Loss: 0.002
Epoch 14, Batch 6, Learning Rate: 0.00000063, Train Loss: 0.008
Epoch 14, Batch 7, Learning Rate: 0.00000063, Train Loss: 0.002
Epoch 14, Batch 8, Learning Rate: 0.00000063, Train Loss: 0.002
Epoch 14, Batch 9, Learning Rate: 0.00000063, Train Loss: 0.003
Epoch 14, Batch 10, Learning Rate: 0.00000063, Train Loss: 0.002
Epoch 14, Batch 11, Learning Rate: 0.00000063, Train Loss: 0.002
Epoch 14, Batch 12, Learning Rate: 0.00000063, Train Loss: 0.004
Epoch 14, Batch 13, Learning Rate: 0.00000063, Train Loss: 0.003
Epoch 14, Batch 14, Learning Rate: 0.00000063, Train Loss: 0.002
Epoch 14, Batch 15, Learning Rate: 0.00000063, Train Loss: 0.002
Epoch 14, Batch 16, Learning Rate: 0.00000063, Train Loss: 0.002
Epoch 14, Batch 17, Learning Rate: 0.00000063, Train Loss: 0.307
Epoch 14, Batch 18, Learning Rate: 0.00000063, Train Loss: 0.003
Epoch 14, Batch 19, Learning Rate: 0.00000063, Train Loss: 0.002
Epoch 14, Batch 20, Learning Rate: 0.00000063, Train Loss: 0.003
Epoch 14, Dev Loss: 2.103, Dev Accuracy: 0.625
Learning rate adjusted. New learning rate: 0.00000063
=== JOB_STATISTICS ===
=== current date     : Mon 25 Mar 2024 12:09:58 PM CET
= Job-ID             : 791480 on tinygpu
= Job-Name           : job_fine_tuning_deproberta.sh
= Job-Command        : /home/hpc/empk/empk004h/depression-detection/experiments_4_new_prompts/job_fine_tuning_deproberta.sh
= Initial workdir    : /home/hpc/empk/empk004h/depression-detection/experiments_4_new_prompts
= Queue/Partition    : a100
= Slurm account      : empk with QOS=normal
= Requested resources:  for 20:00:00
= Elapsed runtime    : 00:07:12
= Total RAM usage    : 2.6 GiB of requested  GiB (%)   
= Node list          : tg094
= Subm/Elig/Start/End: 2024-03-25T12:02:45 / 2024-03-25T12:02:45 / 2024-03-25T12:02:46 / 2024-03-25T12:09:58
======================
=== Quota infos ======
    Path              Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc           52.1G   104.9G   209.7G        N/A  44,635      500K   1,000K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
NVIDIA A100-SXM4-40GB, 00000000:81:00.0, 2533832, 32 %, 8 %, 13016 MiB, 416019 ms
