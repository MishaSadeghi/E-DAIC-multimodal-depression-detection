### Starting TaskPrologue of job 782940 on tg092 at Fri 08 Mar 2024 03:39:02 PM CET
Running on cores 96-127 with governor ondemand
Fri Mar  8 15:39:02 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.113.01             Driver Version: 535.113.01   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  | 00000000:C1:00.0 Off |                    0 |
| N/A   39C    P0              53W / 400W |      4MiB / 40960MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
### Finished TaskPrologue

/home/hpc/empk/empk004h/depression-detection/experiments_4_new_prompts
folder_path:  /home/hpc/empk/empk004h/depression-detection/data/original_transcripts_completions/prompt_1
csv_files:  ['df_train_prompt1.csv', 'df_dev_prompt1.csv', 'df_test_prompt1.csv']
fine tuning for prompt:  prompt_1
len train_loader:  21
Epoch 0, Batch 0, Learning Rate: 0.00000500, Train Loss: 1.296
Epoch 0, Batch 1, Learning Rate: 0.00000500, Train Loss: 1.248
Epoch 0, Batch 2, Learning Rate: 0.00000500, Train Loss: 1.489
Epoch 0, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.856
Epoch 0, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.705
Epoch 0, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.801
Epoch 0, Batch 6, Learning Rate: 0.00000500, Train Loss: 1.182
Epoch 0, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.806
Epoch 0, Batch 8, Learning Rate: 0.00000500, Train Loss: 1.230
Epoch 0, Batch 9, Learning Rate: 0.00000500, Train Loss: 1.153
Epoch 0, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.962
Epoch 0, Batch 11, Learning Rate: 0.00000500, Train Loss: 1.140
Epoch 0, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.754
Epoch 0, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.830
Epoch 0, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.810
Epoch 0, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.605
Epoch 0, Batch 16, Learning Rate: 0.00000500, Train Loss: 1.055
Epoch 0, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.645
Epoch 0, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.990
Epoch 0, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.424
Epoch 0, Batch 20, Learning Rate: 0.00000500, Train Loss: 1.060
Epoch 0, Batch 20, Dev Loss: 0.976
len train_loader:  21
Epoch 1, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.905
Epoch 1, Batch 1, Learning Rate: 0.00000500, Train Loss: 1.156
Epoch 1, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.511
Epoch 1, Batch 3, Learning Rate: 0.00000500, Train Loss: 1.006
Epoch 1, Batch 4, Learning Rate: 0.00000500, Train Loss: 1.187
Epoch 1, Batch 5, Learning Rate: 0.00000500, Train Loss: 1.157
Epoch 1, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.876
Epoch 1, Batch 7, Learning Rate: 0.00000500, Train Loss: 1.043
Epoch 1, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.722
Epoch 1, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.916
Epoch 1, Batch 10, Learning Rate: 0.00000500, Train Loss: 1.045
Epoch 1, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.861
Epoch 1, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.890
Epoch 1, Batch 13, Learning Rate: 0.00000500, Train Loss: 1.045
Epoch 1, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.702
Epoch 1, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.813
Epoch 1, Batch 16, Learning Rate: 0.00000500, Train Loss: 1.321
Epoch 1, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.842
Epoch 1, Batch 18, Learning Rate: 0.00000500, Train Loss: 1.281
Epoch 1, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.743
Epoch 1, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.920
Epoch 1, Batch 20, Dev Loss: 0.912
len train_loader:  21
Epoch 2, Batch 0, Learning Rate: 0.00000500, Train Loss: 1.002
Epoch 2, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.657
Epoch 2, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.862
Epoch 2, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.705
Epoch 2, Batch 4, Learning Rate: 0.00000500, Train Loss: 1.214
Epoch 2, Batch 5, Learning Rate: 0.00000500, Train Loss: 1.022
Epoch 2, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.873
Epoch 2, Batch 7, Learning Rate: 0.00000500, Train Loss: 1.040
Epoch 2, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.960
Epoch 2, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.949
Epoch 2, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.825
Epoch 2, Batch 11, Learning Rate: 0.00000500, Train Loss: 1.096
Epoch 2, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.623
Epoch 2, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.719
Epoch 2, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.674
Epoch 2, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.725
Epoch 2, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.853
Epoch 2, Batch 17, Learning Rate: 0.00000500, Train Loss: 1.277
Epoch 2, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.631
Epoch 2, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.403
Epoch 2, Batch 20, Learning Rate: 0.00000500, Train Loss: 1.569
Epoch 2, Batch 20, Dev Loss: 0.893
len train_loader:  21
Epoch 3, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.671
Epoch 3, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.742
Epoch 3, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.552
Epoch 3, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.764
Epoch 3, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.726
Epoch 3, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.689
Epoch 3, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.807
Epoch 3, Batch 7, Learning Rate: 0.00000500, Train Loss: 1.086
Epoch 3, Batch 8, Learning Rate: 0.00000500, Train Loss: 1.032
Epoch 3, Batch 9, Learning Rate: 0.00000500, Train Loss: 1.075
Epoch 3, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.908
Epoch 3, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.619
Epoch 3, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.924
Epoch 3, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.933
Epoch 3, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.600
Epoch 3, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.673
Epoch 3, Batch 16, Learning Rate: 0.00000500, Train Loss: 1.165
Epoch 3, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.834
Epoch 3, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.504
Epoch 3, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.963
Epoch 3, Batch 20, Learning Rate: 0.00000500, Train Loss: 1.115
Epoch 3, Batch 20, Dev Loss: 0.904
len train_loader:  21
Epoch 4, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.592
Epoch 4, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.768
Epoch 4, Batch 2, Learning Rate: 0.00000500, Train Loss: 1.177
Epoch 4, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.714
Epoch 4, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.477
Epoch 4, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.870
Epoch 4, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.931
Epoch 4, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.980
Epoch 4, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.537
Epoch 4, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.966
Epoch 4, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.972
Epoch 4, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.526
Epoch 4, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.508
Epoch 4, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.797
Epoch 4, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.702
Epoch 4, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.571
Epoch 4, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.844
Epoch 4, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.701
Epoch 4, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.645
Epoch 4, Batch 19, Learning Rate: 0.00000500, Train Loss: 1.163
Epoch 4, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.568
Epoch 4, Batch 20, Dev Loss: 0.911
len train_loader:  21
Epoch 5, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.952
Epoch 5, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.831
Epoch 5, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.714
Epoch 5, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.614
Epoch 5, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.876
Epoch 5, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.752
Epoch 5, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.700
Epoch 5, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.608
Epoch 5, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.421
Epoch 5, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.634
Epoch 5, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.622
Epoch 5, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.457
Epoch 5, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.568
Epoch 5, Batch 13, Learning Rate: 0.00000500, Train Loss: 1.257
Epoch 5, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.976
Epoch 5, Batch 15, Learning Rate: 0.00000500, Train Loss: 1.141
Epoch 5, Batch 16, Learning Rate: 0.00000500, Train Loss: 1.188
Epoch 5, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.398
Epoch 5, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.915
Epoch 5, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.602
Epoch 5, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.723
Epoch 5, Batch 20, Dev Loss: 0.926
Early stopping triggered. No improvement in dev loss.
folder_path:  /home/hpc/empk/empk004h/depression-detection/data/original_transcripts_completions/prompt_2
csv_files:  ['df_dev_prompt2.csv', 'df_test_prompt2.csv', 'df_train_prompt2.csv']
fine tuning for prompt:  prompt_2
len train_loader:  21
Epoch 0, Batch 0, Learning Rate: 0.00000500, Train Loss: 1.162
Epoch 0, Batch 1, Learning Rate: 0.00000500, Train Loss: 1.435
Epoch 0, Batch 2, Learning Rate: 0.00000500, Train Loss: 1.181
Epoch 0, Batch 3, Learning Rate: 0.00000500, Train Loss: 1.043
Epoch 0, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.514
Epoch 0, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.839
Epoch 0, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.817
Epoch 0, Batch 7, Learning Rate: 0.00000500, Train Loss: 1.327
Epoch 0, Batch 8, Learning Rate: 0.00000500, Train Loss: 1.480
Epoch 0, Batch 9, Learning Rate: 0.00000500, Train Loss: 1.029
Epoch 0, Batch 10, Learning Rate: 0.00000500, Train Loss: 1.230
Epoch 0, Batch 11, Learning Rate: 0.00000500, Train Loss: 1.481
Epoch 0, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.713
Epoch 0, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.586
Epoch 0, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.843
Epoch 0, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.823
Epoch 0, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.591
Epoch 0, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.602
Epoch 0, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.785
Epoch 0, Batch 19, Learning Rate: 0.00000500, Train Loss: 1.176
Epoch 0, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.882
Epoch 0, Batch 20, Dev Loss: 0.949
len train_loader:  21
Epoch 1, Batch 0, Learning Rate: 0.00000500, Train Loss: 1.140
Epoch 1, Batch 1, Learning Rate: 0.00000500, Train Loss: 1.249
Epoch 1, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.778
Epoch 1, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.744
Epoch 1, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.658
Epoch 1, Batch 5, Learning Rate: 0.00000500, Train Loss: 1.103
Epoch 1, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.843
Epoch 1, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.874
Epoch 1, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.718
Epoch 1, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.840
Epoch 1, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.793
Epoch 1, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.857
Epoch 1, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.716
Epoch 1, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.710
Epoch 1, Batch 14, Learning Rate: 0.00000500, Train Loss: 1.040
Epoch 1, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.907
Epoch 1, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.845
Epoch 1, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.960
Epoch 1, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.716
Epoch 1, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.516
Epoch 1, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.760
Epoch 1, Batch 20, Dev Loss: 0.927
len train_loader:  21
Epoch 2, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.897
Epoch 2, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.770
Epoch 2, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.555
Epoch 2, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.919
Epoch 2, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.652
Epoch 2, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.582
Epoch 2, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.757
Epoch 2, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.457
Epoch 2, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.734
Epoch 2, Batch 9, Learning Rate: 0.00000500, Train Loss: 1.509
Epoch 2, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.809
Epoch 2, Batch 11, Learning Rate: 0.00000500, Train Loss: 1.176
Epoch 2, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.827
Epoch 2, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.713
Epoch 2, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.808
Epoch 2, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.795
Epoch 2, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.404
Epoch 2, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.829
Epoch 2, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.640
Epoch 2, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.993
Epoch 2, Batch 20, Learning Rate: 0.00000500, Train Loss: 1.877
Epoch 2, Batch 20, Dev Loss: 0.975
len train_loader:  21
Epoch 3, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.806
Epoch 3, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.709
Epoch 3, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.561
Epoch 3, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.894
Epoch 3, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.709
Epoch 3, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.744
Epoch 3, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.802
Epoch 3, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.691
Epoch 3, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.917
Epoch 3, Batch 9, Learning Rate: 0.00000500, Train Loss: 1.131
Epoch 3, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.688
Epoch 3, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.896
Epoch 3, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.635
Epoch 3, Batch 13, Learning Rate: 0.00000500, Train Loss: 1.067
Epoch 3, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.488
Epoch 3, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.841
Epoch 3, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.623
Epoch 3, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.971
Epoch 3, Batch 18, Learning Rate: 0.00000500, Train Loss: 1.038
Epoch 3, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.507
Epoch 3, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.821
Epoch 3, Batch 20, Dev Loss: 0.871
len train_loader:  21
Epoch 4, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.705
Epoch 4, Batch 1, Learning Rate: 0.00000500, Train Loss: 1.015
Epoch 4, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.862
Epoch 4, Batch 3, Learning Rate: 0.00000500, Train Loss: 1.027
Epoch 4, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.696
Epoch 4, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.930
Epoch 4, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.725
Epoch 4, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.707
Epoch 4, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.868
Epoch 4, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.567
Epoch 4, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.805
Epoch 4, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.719
Epoch 4, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.459
Epoch 4, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.539
Epoch 4, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.643
Epoch 4, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.578
Epoch 4, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.429
Epoch 4, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.532
Epoch 4, Batch 18, Learning Rate: 0.00000500, Train Loss: 1.005
Epoch 4, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.768
Epoch 4, Batch 20, Learning Rate: 0.00000500, Train Loss: 1.290
Epoch 4, Batch 20, Dev Loss: 0.918
len train_loader:  21
Epoch 5, Batch 0, Learning Rate: 0.00000500, Train Loss: 1.320
Epoch 5, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.830
Epoch 5, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.668
Epoch 5, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.477
Epoch 5, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.369
Epoch 5, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.497
Epoch 5, Batch 6, Learning Rate: 0.00000500, Train Loss: 1.128
Epoch 5, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.417
Epoch 5, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.639
Epoch 5, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.735
Epoch 5, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.747
Epoch 5, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.973
Epoch 5, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.853
Epoch 5, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.624
Epoch 5, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.871
Epoch 5, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.683
Epoch 5, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.729
Epoch 5, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.341
Epoch 5, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.351
Epoch 5, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.216
Epoch 5, Batch 20, Learning Rate: 0.00000500, Train Loss: 1.082
Epoch 5, Batch 20, Dev Loss: 0.903
len train_loader:  21
Epoch 6, Batch 0, Learning Rate: 0.00000500, Train Loss: 1.023
Epoch 6, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.583
Epoch 6, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.743
Epoch 6, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.725
Epoch 6, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.879
Epoch 6, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.554
Epoch 6, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.629
Epoch 6, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.306
Epoch 6, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.614
Epoch 6, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.309
Epoch 6, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.444
Epoch 6, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.877
Epoch 6, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.664
Epoch 6, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.449
Epoch 6, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.878
Epoch 6, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.298
Epoch 6, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.441
Epoch 6, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.592
Epoch 6, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.467
Epoch 6, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.348
Epoch 6, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.548
Epoch 6, Batch 20, Dev Loss: 0.877
Early stopping triggered. No improvement in dev loss.
folder_path:  /home/hpc/empk/empk004h/depression-detection/data/original_transcripts_completions/prompt_3
csv_files:  ['df_test_prompt3.csv', 'df_dev_prompt3.csv', 'df_train_prompt3.csv']
fine tuning for prompt:  prompt_3
len train_loader:  21
Epoch 0, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.813
Epoch 0, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.841
Epoch 0, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.707
Epoch 0, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.754
Epoch 0, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.449
Epoch 0, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.856
Epoch 0, Batch 6, Learning Rate: 0.00000500, Train Loss: 1.224
Epoch 0, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.777
Epoch 0, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.916
Epoch 0, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.860
Epoch 0, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.768
Epoch 0, Batch 11, Learning Rate: 0.00000500, Train Loss: 1.075
Epoch 0, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.950
Epoch 0, Batch 13, Learning Rate: 0.00000500, Train Loss: 1.659
Epoch 0, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.942
Epoch 0, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.652
Epoch 0, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.890
Epoch 0, Batch 17, Learning Rate: 0.00000500, Train Loss: 1.018
Epoch 0, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.936
Epoch 0, Batch 19, Learning Rate: 0.00000500, Train Loss: 1.295
Epoch 0, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.971
Epoch 0, Batch 20, Dev Loss: 0.951
len train_loader:  21
Epoch 1, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.753
Epoch 1, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.707
Epoch 1, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.688
Epoch 1, Batch 3, Learning Rate: 0.00000500, Train Loss: 1.100
Epoch 1, Batch 4, Learning Rate: 0.00000500, Train Loss: 1.257
Epoch 1, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.846
Epoch 1, Batch 6, Learning Rate: 0.00000500, Train Loss: 1.053
Epoch 1, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.766
Epoch 1, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.663
Epoch 1, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.863
Epoch 1, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.652
Epoch 1, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.490
Epoch 1, Batch 12, Learning Rate: 0.00000500, Train Loss: 1.210
Epoch 1, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.803
Epoch 1, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.915
Epoch 1, Batch 15, Learning Rate: 0.00000500, Train Loss: 1.062
Epoch 1, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.890
Epoch 1, Batch 17, Learning Rate: 0.00000500, Train Loss: 1.258
Epoch 1, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.857
Epoch 1, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.710
Epoch 1, Batch 20, Learning Rate: 0.00000500, Train Loss: 1.227
Epoch 1, Batch 20, Dev Loss: 0.896
len train_loader:  21
Epoch 2, Batch 0, Learning Rate: 0.00000500, Train Loss: 1.177
Epoch 2, Batch 1, Learning Rate: 0.00000500, Train Loss: 1.223
Epoch 2, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.621
Epoch 2, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.959
Epoch 2, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.580
Epoch 2, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.937
Epoch 2, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.987
Epoch 2, Batch 7, Learning Rate: 0.00000500, Train Loss: 1.009
Epoch 2, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.653
Epoch 2, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.834
Epoch 2, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.682
Epoch 2, Batch 11, Learning Rate: 0.00000500, Train Loss: 1.149
Epoch 2, Batch 12, Learning Rate: 0.00000500, Train Loss: 1.005
Epoch 2, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.795
Epoch 2, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.656
Epoch 2, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.837
Epoch 2, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.610
Epoch 2, Batch 17, Learning Rate: 0.00000500, Train Loss: 1.222
Epoch 2, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.890
Epoch 2, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.346
Epoch 2, Batch 20, Learning Rate: 0.00000500, Train Loss: 1.171
Epoch 2, Batch 20, Dev Loss: 0.917
len train_loader:  21
Epoch 3, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.796
Epoch 3, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.861
Epoch 3, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.447
Epoch 3, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.844
Epoch 3, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.951
Epoch 3, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.593
Epoch 3, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.679
Epoch 3, Batch 7, Learning Rate: 0.00000500, Train Loss: 1.063
Epoch 3, Batch 8, Learning Rate: 0.00000500, Train Loss: 1.028
Epoch 3, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.647
Epoch 3, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.898
Epoch 3, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.523
Epoch 3, Batch 12, Learning Rate: 0.00000500, Train Loss: 1.393
Epoch 3, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.530
Epoch 3, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.610
Epoch 3, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.853
Epoch 3, Batch 16, Learning Rate: 0.00000500, Train Loss: 1.027
Epoch 3, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.633
Epoch 3, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.863
Epoch 3, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.726
Epoch 3, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.404
Epoch 3, Batch 20, Dev Loss: 0.946
len train_loader:  21
Epoch 4, Batch 0, Learning Rate: 0.00000500, Train Loss: 1.161
Epoch 4, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.655
Epoch 4, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.465
Epoch 4, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.468
Epoch 4, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.554
Epoch 4, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.580
Epoch 4, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.799
Epoch 4, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.911
Epoch 4, Batch 8, Learning Rate: 0.00000500, Train Loss: 1.164
Epoch 4, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.940
Epoch 4, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.923
Epoch 4, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.707
Epoch 4, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.478
Epoch 4, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.598
Epoch 4, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.744
Epoch 4, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.801
Epoch 4, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.771
Epoch 4, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.863
Epoch 4, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.644
Epoch 4, Batch 19, Learning Rate: 0.00000500, Train Loss: 1.168
Epoch 4, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.539
Epoch 4, Batch 20, Dev Loss: 0.943
Early stopping triggered. No improvement in dev loss.
folder_path:  /home/hpc/empk/empk004h/depression-detection/data/revised_transcripts_completions/prompt_1
csv_files:  ['df_train_prompt1.csv', 'df_dev_prompt1.csv', 'df_test_prompt1.csv']
fine tuning for prompt:  prompt_1
len train_loader:  21
Epoch 0, Batch 0, Learning Rate: 0.00000500, Train Loss: 1.700
Epoch 0, Batch 1, Learning Rate: 0.00000500, Train Loss: 1.146
Epoch 0, Batch 2, Learning Rate: 0.00000500, Train Loss: 1.035
Epoch 0, Batch 3, Learning Rate: 0.00000500, Train Loss: 1.327
Epoch 0, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.990
Epoch 0, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.725
Epoch 0, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.998
Epoch 0, Batch 7, Learning Rate: 0.00000500, Train Loss: 1.132
Epoch 0, Batch 8, Learning Rate: 0.00000500, Train Loss: 1.181
Epoch 0, Batch 9, Learning Rate: 0.00000500, Train Loss: 1.145
Epoch 0, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.751
Epoch 0, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.803
Epoch 0, Batch 12, Learning Rate: 0.00000500, Train Loss: 1.160
Epoch 0, Batch 13, Learning Rate: 0.00000500, Train Loss: 1.032
Epoch 0, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.999
Epoch 0, Batch 15, Learning Rate: 0.00000500, Train Loss: 1.171
Epoch 0, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.831
Epoch 0, Batch 17, Learning Rate: 0.00000500, Train Loss: 1.024
Epoch 0, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.710
Epoch 0, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.952
Epoch 0, Batch 20, Learning Rate: 0.00000500, Train Loss: 1.077
Epoch 0, Batch 20, Dev Loss: 0.959
len train_loader:  21
Epoch 1, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.864
Epoch 1, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.635
Epoch 1, Batch 2, Learning Rate: 0.00000500, Train Loss: 1.216
Epoch 1, Batch 3, Learning Rate: 0.00000500, Train Loss: 1.191
Epoch 1, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.807
Epoch 1, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.919
Epoch 1, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.802
Epoch 1, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.763
Epoch 1, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.659
Epoch 1, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.943
Epoch 1, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.916
Epoch 1, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.575
Epoch 1, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.752
Epoch 1, Batch 13, Learning Rate: 0.00000500, Train Loss: 1.082
Epoch 1, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.772
Epoch 1, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.964
Epoch 1, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.927
Epoch 1, Batch 17, Learning Rate: 0.00000500, Train Loss: 1.030
Epoch 1, Batch 18, Learning Rate: 0.00000500, Train Loss: 1.027
Epoch 1, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.968
Epoch 1, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.718
Epoch 1, Batch 20, Dev Loss: 0.972
len train_loader:  21
Epoch 2, Batch 0, Learning Rate: 0.00000500, Train Loss: 1.032
Epoch 2, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.728
Epoch 2, Batch 2, Learning Rate: 0.00000500, Train Loss: 1.160
Epoch 2, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.861
Epoch 2, Batch 4, Learning Rate: 0.00000500, Train Loss: 1.059
Epoch 2, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.876
Epoch 2, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.899
Epoch 2, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.712
Epoch 2, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.914
Epoch 2, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.648
Epoch 2, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.637
Epoch 2, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.802
Epoch 2, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.686
Epoch 2, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.588
Epoch 2, Batch 14, Learning Rate: 0.00000500, Train Loss: 1.104
Epoch 2, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.916
Epoch 2, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.591
Epoch 2, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.836
Epoch 2, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.796
Epoch 2, Batch 19, Learning Rate: 0.00000500, Train Loss: 1.100
Epoch 2, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.813
Epoch 2, Batch 20, Dev Loss: 1.042
len train_loader:  21
Epoch 3, Batch 0, Learning Rate: 0.00000500, Train Loss: 1.489
Epoch 3, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.390
Epoch 3, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.788
Epoch 3, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.727
Epoch 3, Batch 4, Learning Rate: 0.00000500, Train Loss: 1.023
Epoch 3, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.851
Epoch 3, Batch 6, Learning Rate: 0.00000500, Train Loss: 1.135
Epoch 3, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.749
Epoch 3, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.636
Epoch 3, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.531
Epoch 3, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.814
Epoch 3, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.740
Epoch 3, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.793
Epoch 3, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.818
Epoch 3, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.760
Epoch 3, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.549
Epoch 3, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.745
Epoch 3, Batch 17, Learning Rate: 0.00000500, Train Loss: 1.139
Epoch 3, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.916
Epoch 3, Batch 19, Learning Rate: 0.00000500, Train Loss: 1.229
Epoch 3, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.566
Epoch 3, Batch 20, Dev Loss: 1.026
Early stopping triggered. No improvement in dev loss.
folder_path:  /home/hpc/empk/empk004h/depression-detection/data/revised_transcripts_completions/prompt_2
csv_files:  ['df_dev_prompt2.csv', 'df_test_prompt2.csv', 'df_train_prompt2.csv']
fine tuning for prompt:  prompt_2
len train_loader:  21
Epoch 0, Batch 0, Learning Rate: 0.00000500, Train Loss: 1.168
Epoch 0, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.663
Epoch 0, Batch 2, Learning Rate: 0.00000500, Train Loss: 1.254
Epoch 0, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.976
Epoch 0, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.785
Epoch 0, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.809
Epoch 0, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.936
Epoch 0, Batch 7, Learning Rate: 0.00000500, Train Loss: 1.176
Epoch 0, Batch 8, Learning Rate: 0.00000500, Train Loss: 1.263
Epoch 0, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.728
Epoch 0, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.786
Epoch 0, Batch 11, Learning Rate: 0.00000500, Train Loss: 1.254
Epoch 0, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.924
Epoch 0, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.897
Epoch 0, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.982
Epoch 0, Batch 15, Learning Rate: 0.00000500, Train Loss: 1.179
Epoch 0, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.931
Epoch 0, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.701
Epoch 0, Batch 18, Learning Rate: 0.00000500, Train Loss: 1.274
Epoch 0, Batch 19, Learning Rate: 0.00000500, Train Loss: 1.013
Epoch 0, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.290
Epoch 0, Batch 20, Dev Loss: 0.989
len train_loader:  21
Epoch 1, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.946
Epoch 1, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.854
Epoch 1, Batch 2, Learning Rate: 0.00000500, Train Loss: 1.302
Epoch 1, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.744
Epoch 1, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.967
Epoch 1, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.998
Epoch 1, Batch 6, Learning Rate: 0.00000500, Train Loss: 1.060
Epoch 1, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.772
Epoch 1, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.598
Epoch 1, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.756
Epoch 1, Batch 10, Learning Rate: 0.00000500, Train Loss: 1.046
Epoch 1, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.975
Epoch 1, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.752
Epoch 1, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.565
Epoch 1, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.865
Epoch 1, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.548
Epoch 1, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.884
Epoch 1, Batch 17, Learning Rate: 0.00000500, Train Loss: 1.267
Epoch 1, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.945
Epoch 1, Batch 19, Learning Rate: 0.00000500, Train Loss: 1.066
Epoch 1, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.377
Epoch 1, Batch 20, Dev Loss: 0.984
len train_loader:  21
Epoch 2, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.793
Epoch 2, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.481
Epoch 2, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.749
Epoch 2, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.672
Epoch 2, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.960
Epoch 2, Batch 5, Learning Rate: 0.00000500, Train Loss: 1.953
Epoch 2, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.665
Epoch 2, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.767
Epoch 2, Batch 8, Learning Rate: 0.00000500, Train Loss: 1.097
Epoch 2, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.671
Epoch 2, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.620
Epoch 2, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.759
Epoch 2, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.655
Epoch 2, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.805
Epoch 2, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.711
Epoch 2, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.814
Epoch 2, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.726
Epoch 2, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.866
Epoch 2, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.920
Epoch 2, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.803
Epoch 2, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.772
Epoch 2, Batch 20, Dev Loss: 0.994
len train_loader:  21
Epoch 3, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.743
Epoch 3, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.877
Epoch 3, Batch 2, Learning Rate: 0.00000500, Train Loss: 1.331
Epoch 3, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.722
Epoch 3, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.817
Epoch 3, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.777
Epoch 3, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.558
Epoch 3, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.888
Epoch 3, Batch 8, Learning Rate: 0.00000500, Train Loss: 1.076
Epoch 3, Batch 9, Learning Rate: 0.00000500, Train Loss: 1.076
Epoch 3, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.886
Epoch 3, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.724
Epoch 3, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.660
Epoch 3, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.698
Epoch 3, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.694
Epoch 3, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.599
Epoch 3, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.408
Epoch 3, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.653
Epoch 3, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.694
Epoch 3, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.636
Epoch 3, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.434
Epoch 3, Batch 20, Dev Loss: 1.019
len train_loader:  21
Epoch 4, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.749
Epoch 4, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.981
Epoch 4, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.751
Epoch 4, Batch 3, Learning Rate: 0.00000500, Train Loss: 1.098
Epoch 4, Batch 4, Learning Rate: 0.00000500, Train Loss: 1.118
Epoch 4, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.783
Epoch 4, Batch 6, Learning Rate: 0.00000500, Train Loss: 1.004
Epoch 4, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.672
Epoch 4, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.976
Epoch 4, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.448
Epoch 4, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.443
Epoch 4, Batch 11, Learning Rate: 0.00000500, Train Loss: 1.179
Epoch 4, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.627
Epoch 4, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.518
Epoch 4, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.785
Epoch 4, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.478
Epoch 4, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.583
Epoch 4, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.408
Epoch 4, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.597
Epoch 4, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.559
Epoch 4, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.460
Epoch 4, Batch 20, Dev Loss: 1.034
Early stopping triggered. No improvement in dev loss.
folder_path:  /home/hpc/empk/empk004h/depression-detection/data/revised_transcripts_completions/prompt_3
csv_files:  ['df_test_prompt3.csv', 'df_dev_prompt3.csv', 'df_train_prompt3.csv']
fine tuning for prompt:  prompt_3
len train_loader:  21
Epoch 0, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.605
Epoch 0, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.975
Epoch 0, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.907
Epoch 0, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.559
Epoch 0, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.806
Epoch 0, Batch 5, Learning Rate: 0.00000500, Train Loss: 1.238
Epoch 0, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.636
Epoch 0, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.717
Epoch 0, Batch 8, Learning Rate: 0.00000500, Train Loss: 1.085
Epoch 0, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.880
Epoch 0, Batch 10, Learning Rate: 0.00000500, Train Loss: 1.074
Epoch 0, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.957
Epoch 0, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.767
Epoch 0, Batch 13, Learning Rate: 0.00000500, Train Loss: 1.309
Epoch 0, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.750
Epoch 0, Batch 15, Learning Rate: 0.00000500, Train Loss: 1.100
Epoch 0, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.943
Epoch 0, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.726
Epoch 0, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.762
Epoch 0, Batch 19, Learning Rate: 0.00000500, Train Loss: 1.062
Epoch 0, Batch 20, Learning Rate: 0.00000500, Train Loss: 1.670
Epoch 0, Batch 20, Dev Loss: 0.944
len train_loader:  21
Epoch 1, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.715
Epoch 1, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.780
Epoch 1, Batch 2, Learning Rate: 0.00000500, Train Loss: 1.183
Epoch 1, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.850
Epoch 1, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.947
Epoch 1, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.570
Epoch 1, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.540
Epoch 1, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.780
Epoch 1, Batch 8, Learning Rate: 0.00000500, Train Loss: 1.256
Epoch 1, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.523
Epoch 1, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.999
Epoch 1, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.715
Epoch 1, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.489
Epoch 1, Batch 13, Learning Rate: 0.00000500, Train Loss: 1.063
Epoch 1, Batch 14, Learning Rate: 0.00000500, Train Loss: 1.178
Epoch 1, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.684
Epoch 1, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.947
Epoch 1, Batch 17, Learning Rate: 0.00000500, Train Loss: 1.134
Epoch 1, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.298
Epoch 1, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.962
Epoch 1, Batch 20, Learning Rate: 0.00000500, Train Loss: 1.184
Epoch 1, Batch 20, Dev Loss: 0.941
len train_loader:  21
Epoch 2, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.745
Epoch 2, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.728
Epoch 2, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.695
Epoch 2, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.957
Epoch 2, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.909
Epoch 2, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.804
Epoch 2, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.285
Epoch 2, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.523
Epoch 2, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.783
Epoch 2, Batch 9, Learning Rate: 0.00000500, Train Loss: 1.139
Epoch 2, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.606
Epoch 2, Batch 11, Learning Rate: 0.00000500, Train Loss: 1.365
Epoch 2, Batch 12, Learning Rate: 0.00000500, Train Loss: 1.044
Epoch 2, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.988
Epoch 2, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.539
Epoch 2, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.896
Epoch 2, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.376
Epoch 2, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.902
Epoch 2, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.949
Epoch 2, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.789
Epoch 2, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.948
Epoch 2, Batch 20, Dev Loss: 0.992
len train_loader:  21
Epoch 3, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.556
Epoch 3, Batch 1, Learning Rate: 0.00000500, Train Loss: 1.177
Epoch 3, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.824
Epoch 3, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.871
Epoch 3, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.884
Epoch 3, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.714
Epoch 3, Batch 6, Learning Rate: 0.00000500, Train Loss: 1.128
Epoch 3, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.673
Epoch 3, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.832
Epoch 3, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.402
Epoch 3, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.805
Epoch 3, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.988
Epoch 3, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.768
Epoch 3, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.545
Epoch 3, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.883
Epoch 3, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.663
Epoch 3, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.703
Epoch 3, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.797
Epoch 3, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.664
Epoch 3, Batch 19, Learning Rate: 0.00000500, Train Loss: 1.049
Epoch 3, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.928
Epoch 3, Batch 20, Dev Loss: 0.940
len train_loader:  21
Epoch 4, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.456
Epoch 4, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.774
Epoch 4, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.665
Epoch 4, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.517
Epoch 4, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.943
Epoch 4, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.284
Epoch 4, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.669
Epoch 4, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.863
Epoch 4, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.522
Epoch 4, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.221
Epoch 4, Batch 10, Learning Rate: 0.00000500, Train Loss: 1.106
Epoch 4, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.965
Epoch 4, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.896
Epoch 4, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.832
Epoch 4, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.733
Epoch 4, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.676
Epoch 4, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.683
Epoch 4, Batch 17, Learning Rate: 0.00000500, Train Loss: 1.078
Epoch 4, Batch 18, Learning Rate: 0.00000500, Train Loss: 1.037
Epoch 4, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.768
Epoch 4, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.732
Epoch 4, Batch 20, Dev Loss: 0.898
len train_loader:  21
Epoch 5, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.928
Epoch 5, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.769
Epoch 5, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.500
Epoch 5, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.583
Epoch 5, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.927
Epoch 5, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.646
Epoch 5, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.633
Epoch 5, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.514
Epoch 5, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.910
Epoch 5, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.855
Epoch 5, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.680
Epoch 5, Batch 11, Learning Rate: 0.00000500, Train Loss: 1.117
Epoch 5, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.768
Epoch 5, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.739
Epoch 5, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.688
Epoch 5, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.506
Epoch 5, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.305
Epoch 5, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.701
Epoch 5, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.405
Epoch 5, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.638
Epoch 5, Batch 20, Learning Rate: 0.00000500, Train Loss: 1.415
Epoch 5, Batch 20, Dev Loss: 0.908
len train_loader:  21
Epoch 6, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.608
Epoch 6, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.285
Epoch 6, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.707
Epoch 6, Batch 3, Learning Rate: 0.00000500, Train Loss: 1.131
Epoch 6, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.667
Epoch 6, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.612
Epoch 6, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.682
Epoch 6, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.750
Epoch 6, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.864
Epoch 6, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.618
Epoch 6, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.649
Epoch 6, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.610
Epoch 6, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.410
Epoch 6, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.740
Epoch 6, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.783
Epoch 6, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.912
Epoch 6, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.748
Epoch 6, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.597
Epoch 6, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.817
Epoch 6, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.576
Epoch 6, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.621
Epoch 6, Batch 20, Dev Loss: 0.916
len train_loader:  21
Epoch 7, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.808
Epoch 7, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.692
Epoch 7, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.395
Epoch 7, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.334
Epoch 7, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.690
Epoch 7, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.573
Epoch 7, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.624
Epoch 7, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.658
Epoch 7, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.520
Epoch 7, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.425
Epoch 7, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.415
Epoch 7, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.995
Epoch 7, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.806
Epoch 7, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.567
Epoch 7, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.626
Epoch 7, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.476
Epoch 7, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.702
Epoch 7, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.575
Epoch 7, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.497
Epoch 7, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.936
Epoch 7, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.538
Epoch 7, Batch 20, Dev Loss: 1.018
Early stopping triggered. No improvement in dev loss.
=== JOB_STATISTICS ===
=== current date     : Fri 08 Mar 2024 04:08:54 PM CET
= Job-ID             : 782940 on tinygpu
= Job-Name           : job_fine_tuning_deproberta.sh
= Job-Command        : /home/hpc/empk/empk004h/depression-detection/experiments_4_new_prompts/job_fine_tuning_deproberta.sh
= Initial workdir    : /home/hpc/empk/empk004h/depression-detection/experiments_4_new_prompts
= Queue/Partition    : a100
= Slurm account      : empk with QOS=normal
= Requested resources:  for 20:00:00
= Elapsed runtime    : 00:29:53
= Total RAM usage    : 3.1 GiB of requested  GiB (%)   
= Node list          : tg092
= Subm/Elig/Start/End: 2024-03-08T14:54:05 / 2024-03-08T14:54:05 / 2024-03-08T15:39:01 / 2024-03-08T16:08:54
======================
=== Quota infos ======
    Path              Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc           77.5G   104.9G   209.7G        N/A  46,112      500K   1,000K        N/A    
    /home/woody        335.9G   500.0G   750.0G        N/A     315K   5,000K   7,500K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
NVIDIA A100-SXM4-40GB, 00000000:C1:00.0, 1949846, 12 %, 2 %, 14616 MiB, 1779598 ms
