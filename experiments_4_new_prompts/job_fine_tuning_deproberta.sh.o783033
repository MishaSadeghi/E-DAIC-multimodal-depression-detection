### Starting TaskPrologue of job 783033 on tg095 at Fri 08 Mar 2024 06:13:01 PM CET
Running on cores 64-95 with governor ondemand
Fri Mar  8 18:13:01 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.113.01             Driver Version: 535.113.01   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  | 00000000:81:00.0 Off |                    0 |
| N/A   40C    P0              57W / 400W |      4MiB / 40960MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
### Finished TaskPrologue

/home/hpc/empk/empk004h/depression-detection/experiments_4_new_prompts
folder_path:  /home/hpc/empk/empk004h/depression-detection/data/original_transcripts_completions/prompt_1
csv_files:  ['df_train_prompt1.csv', 'df_dev_prompt1.csv', 'df_test_prompt1.csv']
fine tuning for prompt:  prompt_1
len train_loader:  21
Epoch 0, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.514
Epoch 0, Batch 1, Learning Rate: 0.00000500, Train Loss: 3.786
Epoch 0, Batch 2, Learning Rate: 0.00000500, Train Loss: 1.320
Epoch 0, Batch 3, Learning Rate: 0.00000500, Train Loss: 1.491
Epoch 0, Batch 4, Learning Rate: 0.00000500, Train Loss: 1.009
Epoch 0, Batch 5, Learning Rate: 0.00000500, Train Loss: 1.286
Epoch 0, Batch 6, Learning Rate: 0.00000500, Train Loss: 1.200
Epoch 0, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.990
Epoch 0, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.876
Epoch 0, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.833
Epoch 0, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.800
Epoch 0, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.902
Epoch 0, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.895
Epoch 0, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.755
Epoch 0, Batch 14, Learning Rate: 0.00000500, Train Loss: 1.408
Epoch 0, Batch 15, Learning Rate: 0.00000500, Train Loss: 1.837
Epoch 0, Batch 16, Learning Rate: 0.00000500, Train Loss: 1.244
Epoch 0, Batch 17, Learning Rate: 0.00000500, Train Loss: 1.044
Epoch 0, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.771
Epoch 0, Batch 19, Learning Rate: 0.00000500, Train Loss: 1.098
Epoch 0, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.935
Epoch 0, Batch 20, Dev Loss: 0.991
len train_loader:  21
Epoch 1, Batch 0, Learning Rate: 0.00000500, Train Loss: 1.388
Epoch 1, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.712
Epoch 1, Batch 2, Learning Rate: 0.00000500, Train Loss: 1.192
Epoch 1, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.693
Epoch 1, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.965
Epoch 1, Batch 5, Learning Rate: 0.00000500, Train Loss: 1.015
Epoch 1, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.987
Epoch 1, Batch 7, Learning Rate: 0.00000500, Train Loss: 1.061
Epoch 1, Batch 8, Learning Rate: 0.00000500, Train Loss: 1.139
Epoch 1, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.956
Epoch 1, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.758
Epoch 1, Batch 11, Learning Rate: 0.00000500, Train Loss: 1.117
Epoch 1, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.838
Epoch 1, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.922
Epoch 1, Batch 14, Learning Rate: 0.00000500, Train Loss: 1.061
Epoch 1, Batch 15, Learning Rate: 0.00000500, Train Loss: 1.155
Epoch 1, Batch 16, Learning Rate: 0.00000500, Train Loss: 1.576
Epoch 1, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.941
Epoch 1, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.707
Epoch 1, Batch 19, Learning Rate: 0.00000500, Train Loss: 1.132
Epoch 1, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.831
Epoch 1, Batch 20, Dev Loss: 0.974
len train_loader:  21
Epoch 2, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.878
Epoch 2, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.857
Epoch 2, Batch 2, Learning Rate: 0.00000500, Train Loss: 1.087
Epoch 2, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.590
Epoch 2, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.826
Epoch 2, Batch 5, Learning Rate: 0.00000500, Train Loss: 1.286
Epoch 2, Batch 6, Learning Rate: 0.00000500, Train Loss: 1.024
Epoch 2, Batch 7, Learning Rate: 0.00000500, Train Loss: 1.637
Epoch 2, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.963
Epoch 2, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.753
Epoch 2, Batch 10, Learning Rate: 0.00000500, Train Loss: 1.143
Epoch 2, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.928
Epoch 2, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.962
Epoch 2, Batch 13, Learning Rate: 0.00000500, Train Loss: 1.326
Epoch 2, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.942
Epoch 2, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.780
Epoch 2, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.755
Epoch 2, Batch 17, Learning Rate: 0.00000500, Train Loss: 1.078
Epoch 2, Batch 18, Learning Rate: 0.00000500, Train Loss: 1.048
Epoch 2, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.793
Epoch 2, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.278
Epoch 2, Batch 20, Dev Loss: 0.948
len train_loader:  21
Epoch 3, Batch 0, Learning Rate: 0.00000500, Train Loss: 1.218
Epoch 3, Batch 1, Learning Rate: 0.00000500, Train Loss: 1.120
Epoch 3, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.868
Epoch 3, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.786
Epoch 3, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.860
Epoch 3, Batch 5, Learning Rate: 0.00000500, Train Loss: 1.090
Epoch 3, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.826
Epoch 3, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.868
Epoch 3, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.610
Epoch 3, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.604
Epoch 3, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.829
Epoch 3, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.548
Epoch 3, Batch 12, Learning Rate: 0.00000500, Train Loss: 1.581
Epoch 3, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.681
Epoch 3, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.964
Epoch 3, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.891
Epoch 3, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.938
Epoch 3, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.973
Epoch 3, Batch 18, Learning Rate: 0.00000500, Train Loss: 1.075
Epoch 3, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.791
Epoch 3, Batch 20, Learning Rate: 0.00000500, Train Loss: 1.716
Epoch 3, Batch 20, Dev Loss: 0.904
len train_loader:  21
Epoch 4, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.771
Epoch 4, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.641
Epoch 4, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.651
Epoch 4, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.970
Epoch 4, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.997
Epoch 4, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.728
Epoch 4, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.613
Epoch 4, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.360
Epoch 4, Batch 8, Learning Rate: 0.00000500, Train Loss: 1.174
Epoch 4, Batch 9, Learning Rate: 0.00000500, Train Loss: 1.085
Epoch 4, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.804
Epoch 4, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.938
Epoch 4, Batch 12, Learning Rate: 0.00000500, Train Loss: 1.258
Epoch 4, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.813
Epoch 4, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.868
Epoch 4, Batch 15, Learning Rate: 0.00000500, Train Loss: 1.113
Epoch 4, Batch 16, Learning Rate: 0.00000500, Train Loss: 1.134
Epoch 4, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.865
Epoch 4, Batch 18, Learning Rate: 0.00000500, Train Loss: 1.171
Epoch 4, Batch 19, Learning Rate: 0.00000500, Train Loss: 1.441
Epoch 4, Batch 20, Learning Rate: 0.00000500, Train Loss: 1.012
Epoch 4, Batch 20, Dev Loss: 0.884
len train_loader:  21
Epoch 5, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.995
Epoch 5, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.800
Epoch 5, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.688
Epoch 5, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.924
Epoch 5, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.810
Epoch 5, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.912
Epoch 5, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.567
Epoch 5, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.812
Epoch 5, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.747
Epoch 5, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.533
Epoch 5, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.862
Epoch 5, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.750
Epoch 5, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.314
Epoch 5, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.575
Epoch 5, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.472
Epoch 5, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.429
Epoch 5, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.308
Epoch 5, Batch 17, Learning Rate: 0.00000500, Train Loss: 1.703
Epoch 5, Batch 18, Learning Rate: 0.00000500, Train Loss: 1.189
Epoch 5, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.414
Epoch 5, Batch 20, Learning Rate: 0.00000500, Train Loss: 1.366
Epoch 5, Batch 20, Dev Loss: 1.269
len train_loader:  21
Epoch 6, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.269
Epoch 6, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.139
Epoch 6, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.565
Epoch 6, Batch 3, Learning Rate: 0.00000500, Train Loss: 1.039
Epoch 6, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.664
Epoch 6, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.978
Epoch 6, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.687
Epoch 6, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.966
Epoch 6, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.445
Epoch 6, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.599
Epoch 6, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.811
Epoch 6, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.580
Epoch 6, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.786
Epoch 6, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.468
Epoch 6, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.363
Epoch 6, Batch 15, Learning Rate: 0.00000500, Train Loss: 1.825
Epoch 6, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.447
Epoch 6, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.530
Epoch 6, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.665
Epoch 6, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.872
Epoch 6, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.276
Epoch 6, Batch 20, Dev Loss: 1.050
len train_loader:  21
Epoch 7, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.392
Epoch 7, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.455
Epoch 7, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.621
Epoch 7, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.451
Epoch 7, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.369
Epoch 7, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.383
Epoch 7, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.460
Epoch 7, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.321
Epoch 7, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.271
Epoch 7, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.440
Epoch 7, Batch 10, Learning Rate: 0.00000500, Train Loss: 1.497
Epoch 7, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.471
Epoch 7, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.270
Epoch 7, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.736
Epoch 7, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.430
Epoch 7, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.753
Epoch 7, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.382
Epoch 7, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.257
Epoch 7, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.651
Epoch 7, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.328
Epoch 7, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.453
Epoch 7, Batch 20, Dev Loss: 1.333
Early stopping triggered. No improvement in dev loss.
folder_path:  /home/hpc/empk/empk004h/depression-detection/data/original_transcripts_completions/prompt_2
csv_files:  ['df_dev_prompt2.csv', 'df_test_prompt2.csv', 'df_train_prompt2.csv']
fine tuning for prompt:  prompt_2
len train_loader:  21
Epoch 0, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.469
Epoch 0, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.926
Epoch 0, Batch 2, Learning Rate: 0.00000500, Train Loss: 1.176
Epoch 0, Batch 3, Learning Rate: 0.00000500, Train Loss: 1.879
Epoch 0, Batch 4, Learning Rate: 0.00000500, Train Loss: 2.095
Epoch 0, Batch 5, Learning Rate: 0.00000500, Train Loss: 1.051
Epoch 0, Batch 6, Learning Rate: 0.00000500, Train Loss: 1.062
Epoch 0, Batch 7, Learning Rate: 0.00000500, Train Loss: 1.145
Epoch 0, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.960
Epoch 0, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.801
Epoch 0, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.817
Epoch 0, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.843
Epoch 0, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.640
Epoch 0, Batch 13, Learning Rate: 0.00000500, Train Loss: 1.119
Epoch 0, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.805
Epoch 0, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.907
Epoch 0, Batch 16, Learning Rate: 0.00000500, Train Loss: 1.328
Epoch 0, Batch 17, Learning Rate: 0.00000500, Train Loss: 1.749
Epoch 0, Batch 18, Learning Rate: 0.00000500, Train Loss: 1.238
Epoch 0, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.935
Epoch 0, Batch 20, Learning Rate: 0.00000500, Train Loss: 1.006
Epoch 0, Batch 20, Dev Loss: 0.963
len train_loader:  21
Epoch 1, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.963
Epoch 1, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.925
Epoch 1, Batch 2, Learning Rate: 0.00000500, Train Loss: 1.017
Epoch 1, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.845
Epoch 1, Batch 4, Learning Rate: 0.00000500, Train Loss: 1.083
Epoch 1, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.789
Epoch 1, Batch 6, Learning Rate: 0.00000500, Train Loss: 1.016
Epoch 1, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.855
Epoch 1, Batch 8, Learning Rate: 0.00000500, Train Loss: 1.050
Epoch 1, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.263
Epoch 1, Batch 10, Learning Rate: 0.00000500, Train Loss: 1.305
Epoch 1, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.911
Epoch 1, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.602
Epoch 1, Batch 13, Learning Rate: 0.00000500, Train Loss: 1.062
Epoch 1, Batch 14, Learning Rate: 0.00000500, Train Loss: 1.011
Epoch 1, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.864
Epoch 1, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.741
Epoch 1, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.639
Epoch 1, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.788
Epoch 1, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.672
Epoch 1, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.959
Epoch 1, Batch 20, Dev Loss: 0.931
len train_loader:  21
Epoch 2, Batch 0, Learning Rate: 0.00000500, Train Loss: 1.009
Epoch 2, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.857
Epoch 2, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.778
Epoch 2, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.692
Epoch 2, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.541
Epoch 2, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.687
Epoch 2, Batch 6, Learning Rate: 0.00000500, Train Loss: 1.331
Epoch 2, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.647
Epoch 2, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.790
Epoch 2, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.825
Epoch 2, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.754
Epoch 2, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.617
Epoch 2, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.761
Epoch 2, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.725
Epoch 2, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.727
Epoch 2, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.859
Epoch 2, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.698
Epoch 2, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.655
Epoch 2, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.610
Epoch 2, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.664
Epoch 2, Batch 20, Learning Rate: 0.00000500, Train Loss: 1.434
Epoch 2, Batch 20, Dev Loss: 1.150
len train_loader:  21
Epoch 3, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.225
Epoch 3, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.763
Epoch 3, Batch 2, Learning Rate: 0.00000500, Train Loss: 1.225
Epoch 3, Batch 3, Learning Rate: 0.00000500, Train Loss: 2.114
Epoch 3, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.991
Epoch 3, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.470
Epoch 3, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.660
Epoch 3, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.775
Epoch 3, Batch 8, Learning Rate: 0.00000500, Train Loss: 1.790
Epoch 3, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.823
Epoch 3, Batch 10, Learning Rate: 0.00000500, Train Loss: 1.471
Epoch 3, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.807
Epoch 3, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.889
Epoch 3, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.780
Epoch 3, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.513
Epoch 3, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.458
Epoch 3, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.880
Epoch 3, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.807
Epoch 3, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.961
Epoch 3, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.416
Epoch 3, Batch 20, Learning Rate: 0.00000500, Train Loss: 1.461
Epoch 3, Batch 20, Dev Loss: 1.070
len train_loader:  21
Epoch 4, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.338
Epoch 4, Batch 1, Learning Rate: 0.00000500, Train Loss: 1.127
Epoch 4, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.814
Epoch 4, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.528
Epoch 4, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.453
Epoch 4, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.918
Epoch 4, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.577
Epoch 4, Batch 7, Learning Rate: 0.00000500, Train Loss: 1.057
Epoch 4, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.812
Epoch 4, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.750
Epoch 4, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.389
Epoch 4, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.147
Epoch 4, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.446
Epoch 4, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.396
Epoch 4, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.705
Epoch 4, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.827
Epoch 4, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.118
Epoch 4, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.495
Epoch 4, Batch 18, Learning Rate: 0.00000500, Train Loss: 1.278
Epoch 4, Batch 19, Learning Rate: 0.00000500, Train Loss: 1.229
Epoch 4, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.407
Epoch 4, Batch 20, Dev Loss: 1.269
Early stopping triggered. No improvement in dev loss.
folder_path:  /home/hpc/empk/empk004h/depression-detection/data/original_transcripts_completions/prompt_3
csv_files:  ['df_test_prompt3.csv', 'df_dev_prompt3.csv', 'df_train_prompt3.csv']
fine tuning for prompt:  prompt_3
len train_loader:  21
Epoch 0, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.512
Epoch 0, Batch 1, Learning Rate: 0.00000500, Train Loss: 1.368
Epoch 0, Batch 2, Learning Rate: 0.00000500, Train Loss: 1.179
Epoch 0, Batch 3, Learning Rate: 0.00000500, Train Loss: 1.572
Epoch 0, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.785
Epoch 0, Batch 5, Learning Rate: 0.00000500, Train Loss: 1.304
Epoch 0, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.880
Epoch 0, Batch 7, Learning Rate: 0.00000500, Train Loss: 1.230
Epoch 0, Batch 8, Learning Rate: 0.00000500, Train Loss: 1.221
Epoch 0, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.944
Epoch 0, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.980
Epoch 0, Batch 11, Learning Rate: 0.00000500, Train Loss: 1.293
Epoch 0, Batch 12, Learning Rate: 0.00000500, Train Loss: 1.109
Epoch 0, Batch 13, Learning Rate: 0.00000500, Train Loss: 1.471
Epoch 0, Batch 14, Learning Rate: 0.00000500, Train Loss: 1.050
Epoch 0, Batch 15, Learning Rate: 0.00000500, Train Loss: 1.018
Epoch 0, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.839
Epoch 0, Batch 17, Learning Rate: 0.00000500, Train Loss: 1.023
Epoch 0, Batch 18, Learning Rate: 0.00000500, Train Loss: 1.142
Epoch 0, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.740
Epoch 0, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.930
Epoch 0, Batch 20, Dev Loss: 0.933
len train_loader:  21
Epoch 1, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.878
Epoch 1, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.625
Epoch 1, Batch 2, Learning Rate: 0.00000500, Train Loss: 1.301
Epoch 1, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.751
Epoch 1, Batch 4, Learning Rate: 0.00000500, Train Loss: 1.204
Epoch 1, Batch 5, Learning Rate: 0.00000500, Train Loss: 1.186
Epoch 1, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.651
Epoch 1, Batch 7, Learning Rate: 0.00000500, Train Loss: 1.189
Epoch 1, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.825
Epoch 1, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.780
Epoch 1, Batch 10, Learning Rate: 0.00000500, Train Loss: 1.195
Epoch 1, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.827
Epoch 1, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.816
Epoch 1, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.828
Epoch 1, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.818
Epoch 1, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.913
Epoch 1, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.728
Epoch 1, Batch 17, Learning Rate: 0.00000500, Train Loss: 1.108
Epoch 1, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.707
Epoch 1, Batch 19, Learning Rate: 0.00000500, Train Loss: 1.417
Epoch 1, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.105
Epoch 1, Batch 20, Dev Loss: 1.083
len train_loader:  21
Epoch 2, Batch 0, Learning Rate: 0.00000500, Train Loss: 1.462
Epoch 2, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.999
Epoch 2, Batch 2, Learning Rate: 0.00000500, Train Loss: 1.014
Epoch 2, Batch 3, Learning Rate: 0.00000500, Train Loss: 1.257
Epoch 2, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.794
Epoch 2, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.692
Epoch 2, Batch 6, Learning Rate: 0.00000500, Train Loss: 1.097
Epoch 2, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.765
Epoch 2, Batch 8, Learning Rate: 0.00000500, Train Loss: 1.018
Epoch 2, Batch 9, Learning Rate: 0.00000500, Train Loss: 1.161
Epoch 2, Batch 10, Learning Rate: 0.00000500, Train Loss: 1.319
Epoch 2, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.992
Epoch 2, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.600
Epoch 2, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.726
Epoch 2, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.893
Epoch 2, Batch 15, Learning Rate: 0.00000500, Train Loss: 1.003
Epoch 2, Batch 16, Learning Rate: 0.00000500, Train Loss: 1.079
Epoch 2, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.777
Epoch 2, Batch 18, Learning Rate: 0.00000500, Train Loss: 1.186
Epoch 2, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.709
Epoch 2, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.176
Epoch 2, Batch 20, Dev Loss: 0.976
len train_loader:  21
Epoch 3, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.758
Epoch 3, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.201
Epoch 3, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.535
Epoch 3, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.860
Epoch 3, Batch 4, Learning Rate: 0.00000500, Train Loss: 1.255
Epoch 3, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.492
Epoch 3, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.965
Epoch 3, Batch 7, Learning Rate: 0.00000500, Train Loss: 1.202
Epoch 3, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.556
Epoch 3, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.845
Epoch 3, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.807
Epoch 3, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.832
Epoch 3, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.694
Epoch 3, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.599
Epoch 3, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.388
Epoch 3, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.916
Epoch 3, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.541
Epoch 3, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.445
Epoch 3, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.561
Epoch 3, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.514
Epoch 3, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.367
Epoch 3, Batch 20, Dev Loss: 1.207
Early stopping triggered. No improvement in dev loss.
folder_path:  /home/hpc/empk/empk004h/depression-detection/data/revised_transcripts_completions/prompt_1
csv_files:  ['df_train_prompt1.csv', 'df_dev_prompt1.csv', 'df_test_prompt1.csv']
fine tuning for prompt:  prompt_1
len train_loader:  21
Epoch 0, Batch 0, Learning Rate: 0.00000500, Train Loss: 1.225
Epoch 0, Batch 1, Learning Rate: 0.00000500, Train Loss: 2.146
Epoch 0, Batch 2, Learning Rate: 0.00000500, Train Loss: 1.352
Epoch 0, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.833
Epoch 0, Batch 4, Learning Rate: 0.00000500, Train Loss: 1.090
Epoch 0, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.778
Epoch 0, Batch 6, Learning Rate: 0.00000500, Train Loss: 1.334
Epoch 0, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.988
Epoch 0, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.783
Epoch 0, Batch 9, Learning Rate: 0.00000500, Train Loss: 1.177
Epoch 0, Batch 10, Learning Rate: 0.00000500, Train Loss: 1.135
Epoch 0, Batch 11, Learning Rate: 0.00000500, Train Loss: 1.017
Epoch 0, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.786
Epoch 0, Batch 13, Learning Rate: 0.00000500, Train Loss: 1.081
Epoch 0, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.730
Epoch 0, Batch 15, Learning Rate: 0.00000500, Train Loss: 1.090
Epoch 0, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.875
Epoch 0, Batch 17, Learning Rate: 0.00000500, Train Loss: 1.021
Epoch 0, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.764
Epoch 0, Batch 19, Learning Rate: 0.00000500, Train Loss: 1.165
Epoch 0, Batch 20, Learning Rate: 0.00000500, Train Loss: 2.555
Epoch 0, Batch 20, Dev Loss: 1.027
len train_loader:  21
Epoch 1, Batch 0, Learning Rate: 0.00000500, Train Loss: 1.097
Epoch 1, Batch 1, Learning Rate: 0.00000500, Train Loss: 1.079
Epoch 1, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.777
Epoch 1, Batch 3, Learning Rate: 0.00000500, Train Loss: 1.094
Epoch 1, Batch 4, Learning Rate: 0.00000500, Train Loss: 1.002
Epoch 1, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.850
Epoch 1, Batch 6, Learning Rate: 0.00000500, Train Loss: 1.045
Epoch 1, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.892
Epoch 1, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.983
Epoch 1, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.921
Epoch 1, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.903
Epoch 1, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.993
Epoch 1, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.723
Epoch 1, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.796
Epoch 1, Batch 14, Learning Rate: 0.00000500, Train Loss: 1.126
Epoch 1, Batch 15, Learning Rate: 0.00000500, Train Loss: 1.091
Epoch 1, Batch 16, Learning Rate: 0.00000500, Train Loss: 1.018
Epoch 1, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.547
Epoch 1, Batch 18, Learning Rate: 0.00000500, Train Loss: 1.017
Epoch 1, Batch 19, Learning Rate: 0.00000500, Train Loss: 1.426
Epoch 1, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.264
Epoch 1, Batch 20, Dev Loss: 0.941
len train_loader:  21
Epoch 2, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.665
Epoch 2, Batch 1, Learning Rate: 0.00000500, Train Loss: 1.248
Epoch 2, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.898
Epoch 2, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.405
Epoch 2, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.627
Epoch 2, Batch 5, Learning Rate: 0.00000500, Train Loss: 1.002
Epoch 2, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.811
Epoch 2, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.682
Epoch 2, Batch 8, Learning Rate: 0.00000500, Train Loss: 1.306
Epoch 2, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.782
Epoch 2, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.864
Epoch 2, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.968
Epoch 2, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.976
Epoch 2, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.720
Epoch 2, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.883
Epoch 2, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.864
Epoch 2, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.860
Epoch 2, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.971
Epoch 2, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.609
Epoch 2, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.842
Epoch 2, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.742
Epoch 2, Batch 20, Dev Loss: 1.062
len train_loader:  21
Epoch 3, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.835
Epoch 3, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.644
Epoch 3, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.810
Epoch 3, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.722
Epoch 3, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.769
Epoch 3, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.964
Epoch 3, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.874
Epoch 3, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.761
Epoch 3, Batch 8, Learning Rate: 0.00000500, Train Loss: 1.067
Epoch 3, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.715
Epoch 3, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.643
Epoch 3, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.681
Epoch 3, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.971
Epoch 3, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.550
Epoch 3, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.884
Epoch 3, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.626
Epoch 3, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.842
Epoch 3, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.651
Epoch 3, Batch 18, Learning Rate: 0.00000500, Train Loss: 1.187
Epoch 3, Batch 19, Learning Rate: 0.00000500, Train Loss: 1.259
Epoch 3, Batch 20, Learning Rate: 0.00000500, Train Loss: 1.021
Epoch 3, Batch 20, Dev Loss: 0.934
len train_loader:  21
Epoch 4, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.815
Epoch 4, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.813
Epoch 4, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.939
Epoch 4, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.776
Epoch 4, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.692
Epoch 4, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.926
Epoch 4, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.358
Epoch 4, Batch 7, Learning Rate: 0.00000500, Train Loss: 1.176
Epoch 4, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.849
Epoch 4, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.972
Epoch 4, Batch 10, Learning Rate: 0.00000500, Train Loss: 1.166
Epoch 4, Batch 11, Learning Rate: 0.00000500, Train Loss: 1.574
Epoch 4, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.755
Epoch 4, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.626
Epoch 4, Batch 14, Learning Rate: 0.00000500, Train Loss: 1.008
Epoch 4, Batch 15, Learning Rate: 0.00000500, Train Loss: 1.091
Epoch 4, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.835
Epoch 4, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.877
Epoch 4, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.631
Epoch 4, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.919
Epoch 4, Batch 20, Learning Rate: 0.00000500, Train Loss: 1.357
Epoch 4, Batch 20, Dev Loss: 1.113
len train_loader:  21
Epoch 5, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.425
Epoch 5, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.770
Epoch 5, Batch 2, Learning Rate: 0.00000500, Train Loss: 1.145
Epoch 5, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.388
Epoch 5, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.541
Epoch 5, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.791
Epoch 5, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.638
Epoch 5, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.613
Epoch 5, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.721
Epoch 5, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.314
Epoch 5, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.748
Epoch 5, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.514
Epoch 5, Batch 12, Learning Rate: 0.00000500, Train Loss: 1.122
Epoch 5, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.399
Epoch 5, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.853
Epoch 5, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.869
Epoch 5, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.626
Epoch 5, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.715
Epoch 5, Batch 18, Learning Rate: 0.00000500, Train Loss: 1.466
Epoch 5, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.788
Epoch 5, Batch 20, Learning Rate: 0.00000500, Train Loss: 1.268
Epoch 5, Batch 20, Dev Loss: 1.190
len train_loader:  21
Epoch 6, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.662
Epoch 6, Batch 1, Learning Rate: 0.00000500, Train Loss: 1.066
Epoch 6, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.611
Epoch 6, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.563
Epoch 6, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.732
Epoch 6, Batch 5, Learning Rate: 0.00000500, Train Loss: 1.095
Epoch 6, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.542
Epoch 6, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.557
Epoch 6, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.903
Epoch 6, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.712
Epoch 6, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.668
Epoch 6, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.473
Epoch 6, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.631
Epoch 6, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.610
Epoch 6, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.555
Epoch 6, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.440
Epoch 6, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.579
Epoch 6, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.559
Epoch 6, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.944
Epoch 6, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.492
Epoch 6, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.806
Epoch 6, Batch 20, Dev Loss: 1.373
Early stopping triggered. No improvement in dev loss.
folder_path:  /home/hpc/empk/empk004h/depression-detection/data/revised_transcripts_completions/prompt_2
csv_files:  ['df_dev_prompt2.csv', 'df_test_prompt2.csv', 'df_train_prompt2.csv']
fine tuning for prompt:  prompt_2
len train_loader:  21
Epoch 0, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.596
Epoch 0, Batch 1, Learning Rate: 0.00000500, Train Loss: 1.431
Epoch 0, Batch 2, Learning Rate: 0.00000500, Train Loss: 1.153
Epoch 0, Batch 3, Learning Rate: 0.00000500, Train Loss: 1.705
Epoch 0, Batch 4, Learning Rate: 0.00000500, Train Loss: 1.134
Epoch 0, Batch 5, Learning Rate: 0.00000500, Train Loss: 1.279
Epoch 0, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.840
Epoch 0, Batch 7, Learning Rate: 0.00000500, Train Loss: 1.042
Epoch 0, Batch 8, Learning Rate: 0.00000500, Train Loss: 1.165
Epoch 0, Batch 9, Learning Rate: 0.00000500, Train Loss: 1.558
Epoch 0, Batch 10, Learning Rate: 0.00000500, Train Loss: 1.609
Epoch 0, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.595
Epoch 0, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.953
Epoch 0, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.941
Epoch 0, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.972
Epoch 0, Batch 15, Learning Rate: 0.00000500, Train Loss: 1.055
Epoch 0, Batch 16, Learning Rate: 0.00000500, Train Loss: 1.103
Epoch 0, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.782
Epoch 0, Batch 18, Learning Rate: 0.00000500, Train Loss: 1.102
Epoch 0, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.985
Epoch 0, Batch 20, Learning Rate: 0.00000500, Train Loss: 1.353
Epoch 0, Batch 20, Dev Loss: 0.958
len train_loader:  21
Epoch 1, Batch 0, Learning Rate: 0.00000500, Train Loss: 1.073
Epoch 1, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.674
Epoch 1, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.590
Epoch 1, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.585
Epoch 1, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.792
Epoch 1, Batch 5, Learning Rate: 0.00000500, Train Loss: 1.132
Epoch 1, Batch 6, Learning Rate: 0.00000500, Train Loss: 1.285
Epoch 1, Batch 7, Learning Rate: 0.00000500, Train Loss: 1.210
Epoch 1, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.860
Epoch 1, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.730
Epoch 1, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.815
Epoch 1, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.786
Epoch 1, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.558
Epoch 1, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.527
Epoch 1, Batch 14, Learning Rate: 0.00000500, Train Loss: 1.643
Epoch 1, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.726
Epoch 1, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.550
Epoch 1, Batch 17, Learning Rate: 0.00000500, Train Loss: 1.269
Epoch 1, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.794
Epoch 1, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.802
Epoch 1, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.380
Epoch 1, Batch 20, Dev Loss: 1.064
len train_loader:  21
Epoch 2, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.826
Epoch 2, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.912
Epoch 2, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.660
Epoch 2, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.692
Epoch 2, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.689
Epoch 2, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.599
Epoch 2, Batch 6, Learning Rate: 0.00000500, Train Loss: 1.204
Epoch 2, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.801
Epoch 2, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.638
Epoch 2, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.627
Epoch 2, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.467
Epoch 2, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.481
Epoch 2, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.960
Epoch 2, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.502
Epoch 2, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.913
Epoch 2, Batch 15, Learning Rate: 0.00000500, Train Loss: 1.082
Epoch 2, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.832
Epoch 2, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.702
Epoch 2, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.769
Epoch 2, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.517
Epoch 2, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.555
Epoch 2, Batch 20, Dev Loss: 1.031
len train_loader:  21
Epoch 3, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.844
Epoch 3, Batch 1, Learning Rate: 0.00000500, Train Loss: 1.009
Epoch 3, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.601
Epoch 3, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.824
Epoch 3, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.668
Epoch 3, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.688
Epoch 3, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.189
Epoch 3, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.305
Epoch 3, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.324
Epoch 3, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.508
Epoch 3, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.989
Epoch 3, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.877
Epoch 3, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.484
Epoch 3, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.673
Epoch 3, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.566
Epoch 3, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.644
Epoch 3, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.632
Epoch 3, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.735
Epoch 3, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.719
Epoch 3, Batch 19, Learning Rate: 0.00000500, Train Loss: 1.028
Epoch 3, Batch 20, Learning Rate: 0.00000500, Train Loss: 1.508
Epoch 3, Batch 20, Dev Loss: 1.155
Early stopping triggered. No improvement in dev loss.
folder_path:  /home/hpc/empk/empk004h/depression-detection/data/revised_transcripts_completions/prompt_3
csv_files:  ['df_test_prompt3.csv', 'df_dev_prompt3.csv', 'df_train_prompt3.csv']
fine tuning for prompt:  prompt_3
len train_loader:  21
Epoch 0, Batch 0, Learning Rate: 0.00000500, Train Loss: 1.151
Epoch 0, Batch 1, Learning Rate: 0.00000500, Train Loss: 1.491
Epoch 0, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.598
Epoch 0, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.994
Epoch 0, Batch 4, Learning Rate: 0.00000500, Train Loss: 1.695
Epoch 0, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.475
Epoch 0, Batch 6, Learning Rate: 0.00000500, Train Loss: 1.167
Epoch 0, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.619
Epoch 0, Batch 8, Learning Rate: 0.00000500, Train Loss: 1.272
Epoch 0, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.767
Epoch 0, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.765
Epoch 0, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.722
Epoch 0, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.975
Epoch 0, Batch 13, Learning Rate: 0.00000500, Train Loss: 1.203
Epoch 0, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.822
Epoch 0, Batch 15, Learning Rate: 0.00000500, Train Loss: 1.132
Epoch 0, Batch 16, Learning Rate: 0.00000500, Train Loss: 1.290
Epoch 0, Batch 17, Learning Rate: 0.00000500, Train Loss: 1.066
Epoch 0, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.870
Epoch 0, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.954
Epoch 0, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.833
Epoch 0, Batch 20, Dev Loss: 0.892
len train_loader:  21
Epoch 1, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.722
Epoch 1, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.720
Epoch 1, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.828
Epoch 1, Batch 3, Learning Rate: 0.00000500, Train Loss: 1.209
Epoch 1, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.817
Epoch 1, Batch 5, Learning Rate: 0.00000500, Train Loss: 1.420
Epoch 1, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.924
Epoch 1, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.904
Epoch 1, Batch 8, Learning Rate: 0.00000500, Train Loss: 1.159
Epoch 1, Batch 9, Learning Rate: 0.00000500, Train Loss: 1.121
Epoch 1, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.899
Epoch 1, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.710
Epoch 1, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.624
Epoch 1, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.820
Epoch 1, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.515
Epoch 1, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.896
Epoch 1, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.899
Epoch 1, Batch 17, Learning Rate: 0.00000500, Train Loss: 1.081
Epoch 1, Batch 18, Learning Rate: 0.00000500, Train Loss: 1.067
Epoch 1, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.807
Epoch 1, Batch 20, Learning Rate: 0.00000500, Train Loss: 1.076
Epoch 1, Batch 20, Dev Loss: 0.858
len train_loader:  21
Epoch 2, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.610
Epoch 2, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.952
Epoch 2, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.889
Epoch 2, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.732
Epoch 2, Batch 4, Learning Rate: 0.00000500, Train Loss: 1.296
Epoch 2, Batch 5, Learning Rate: 0.00000500, Train Loss: 1.013
Epoch 2, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.713
Epoch 2, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.844
Epoch 2, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.777
Epoch 2, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.640
Epoch 2, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.826
Epoch 2, Batch 11, Learning Rate: 0.00000500, Train Loss: 1.056
Epoch 2, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.906
Epoch 2, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.858
Epoch 2, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.806
Epoch 2, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.269
Epoch 2, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.863
Epoch 2, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.971
Epoch 2, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.988
Epoch 2, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.819
Epoch 2, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.974
Epoch 2, Batch 20, Dev Loss: 0.949
len train_loader:  21
Epoch 3, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.768
Epoch 3, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.483
Epoch 3, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.617
Epoch 3, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.689
Epoch 3, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.307
Epoch 3, Batch 5, Learning Rate: 0.00000500, Train Loss: 1.316
Epoch 3, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.264
Epoch 3, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.854
Epoch 3, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.511
Epoch 3, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.702
Epoch 3, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.596
Epoch 3, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.199
Epoch 3, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.760
Epoch 3, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.744
Epoch 3, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.505
Epoch 3, Batch 15, Learning Rate: 0.00000500, Train Loss: 2.115
Epoch 3, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.683
Epoch 3, Batch 17, Learning Rate: 0.00000500, Train Loss: 0.851
Epoch 3, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.697
Epoch 3, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.618
Epoch 3, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.591
Epoch 3, Batch 20, Dev Loss: 1.207
len train_loader:  21
Epoch 4, Batch 0, Learning Rate: 0.00000500, Train Loss: 0.993
Epoch 4, Batch 1, Learning Rate: 0.00000500, Train Loss: 0.423
Epoch 4, Batch 2, Learning Rate: 0.00000500, Train Loss: 0.612
Epoch 4, Batch 3, Learning Rate: 0.00000500, Train Loss: 0.663
Epoch 4, Batch 4, Learning Rate: 0.00000500, Train Loss: 0.649
Epoch 4, Batch 5, Learning Rate: 0.00000500, Train Loss: 0.276
Epoch 4, Batch 6, Learning Rate: 0.00000500, Train Loss: 0.665
Epoch 4, Batch 7, Learning Rate: 0.00000500, Train Loss: 0.525
Epoch 4, Batch 8, Learning Rate: 0.00000500, Train Loss: 0.536
Epoch 4, Batch 9, Learning Rate: 0.00000500, Train Loss: 0.386
Epoch 4, Batch 10, Learning Rate: 0.00000500, Train Loss: 0.419
Epoch 4, Batch 11, Learning Rate: 0.00000500, Train Loss: 0.311
Epoch 4, Batch 12, Learning Rate: 0.00000500, Train Loss: 0.665
Epoch 4, Batch 13, Learning Rate: 0.00000500, Train Loss: 0.454
Epoch 4, Batch 14, Learning Rate: 0.00000500, Train Loss: 0.646
Epoch 4, Batch 15, Learning Rate: 0.00000500, Train Loss: 0.407
Epoch 4, Batch 16, Learning Rate: 0.00000500, Train Loss: 0.389
Epoch 4, Batch 17, Learning Rate: 0.00000500, Train Loss: 1.365
Epoch 4, Batch 18, Learning Rate: 0.00000500, Train Loss: 0.295
Epoch 4, Batch 19, Learning Rate: 0.00000500, Train Loss: 0.527
Epoch 4, Batch 20, Learning Rate: 0.00000500, Train Loss: 0.331
Epoch 4, Batch 20, Dev Loss: 1.476
Early stopping triggered. No improvement in dev loss.
=== JOB_STATISTICS ===
=== current date     : Fri 08 Mar 2024 06:42:13 PM CET
= Job-ID             : 783033 on tinygpu
= Job-Name           : job_fine_tuning_deproberta.sh
= Job-Command        : /home/hpc/empk/empk004h/depression-detection/experiments_4_new_prompts/job_fine_tuning_deproberta.sh
= Initial workdir    : /home/hpc/empk/empk004h/depression-detection/experiments_4_new_prompts
= Queue/Partition    : a100
= Slurm account      : empk with QOS=normal
= Requested resources:  for 20:00:00
= Elapsed runtime    : 00:29:15
= Total RAM usage    : 3.0 GiB of requested  GiB (%)   
= Node list          : tg095
= Subm/Elig/Start/End: 2024-03-08T17:38:06 / 2024-03-08T17:38:06 / 2024-03-08T18:12:58 / 2024-03-08T18:42:13
======================
=== Quota infos ======
    Path              Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc           77.4G   104.9G   209.7G        N/A  46,117      500K   1,000K        N/A    
    /home/vault         96.5T   150.3T   171.8T        N/A      75K     300K     450K        N/A    
    /home/woody        352.6G   500.0G   750.0G        N/A     315K   5,000K   7,500K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
NVIDIA A100-SXM4-40GB, 00000000:81:00.0, 551244, 11 %, 2 %, 14616 MiB, 1739924 ms
