{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = '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' # for my personal account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "transcripts_df = pd.read_csv('../data/DAIC/transcripts.csv')\n",
    "# remove first column\n",
    "transcripts_df = transcripts_df.iloc[:,1:]\n",
    "transcripts_df.columns = ['id', 'text']\n",
    "\n",
    "labels_dev_df = pd.read_csv('../data/DAIC/labels/dev_split.csv')\n",
    "labels_dev_df.columns = ['id', 'Gender', 'PHQ_Binary', 'PHQ_Score', 'PCL-C (PTSD)', 'PTSD Severity']\n",
    "\n",
    "labels_train_df = pd.read_csv('../data/DAIC/labels/train_split.csv')\n",
    "labels_train_df.columns = ['id', 'Gender', 'PHQ_Binary', 'PHQ_Score', 'PCL-C (PTSD)', 'PTSD Severity']\n",
    "\n",
    "labels_test_df = pd.read_csv('../data/DAIC/labels/test_split.csv')\n",
    "labels_test_df.columns = ['id', 'Gender', 'PHQ_Binary', 'PHQ_Score', 'PCL-C (PTSD)', 'PTSD Severity']\n",
    "\n",
    "# merge dataframes on id\n",
    "df_dev = pd.merge(labels_dev_df, transcripts_df, on='id')\n",
    "df_train = pd.merge(labels_train_df, transcripts_df, on='id')\n",
    "df_test = pd.merge(labels_test_df, transcripts_df, on='id')\n",
    "\n",
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def clean_text(text):\n",
    "    # remove punctuation and special characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # lowercase all words\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = [word for word in text.split() if word not in stop_words]\n",
    "\n",
    "    # stem/lemmatize words\n",
    "    # stemmer = PorterStemmer()\n",
    "    # text = [stemmer.stem(word) for word in text]\n",
    "\n",
    "    # remove numbers\n",
    "    # text = [word for word in text if not word.isdigit()]\n",
    "\n",
    "    return \" \".join(text)\n",
    "\n",
    "# clean all transcripts\n",
    "df_dev['text'] = df_dev['text'].apply(clean_text)\n",
    "df_train['text'] = df_train['text'].apply(clean_text)\n",
    "df_test['text'] = df_test['text'].apply(clean_text)\n",
    "\n",
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!! this is the prompt that we will use for GPT-3 !!!!!\n",
    "prompt = \"\"\" Here is an interview with a person who might have depression. Determine if the text might be relevant to depression. Explain your answer in a verbose manner.  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1057 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated cost: $6.629600000000001\n"
     ]
    }
   ],
   "source": [
    "# GPT-3 cost estimator for all completions\n",
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "\n",
    "token_counts = []\n",
    "# for all tokens in all transcripts in dev, train, and test sets\n",
    "for text in df_dev['text'].tolist() + df_train['text'].tolist() + df_test['text'].tolist():\n",
    "    # tokenize text\n",
    "    tokens = tokenizer.encode(text)\n",
    "    # tokenize prompt\n",
    "    prompt_tokens = tokenizer.encode(prompt)\n",
    "\n",
    "    # append token count to list\n",
    "    token_counts.append(len(tokens) + len(prompt_tokens) + 512)\n",
    "\n",
    "# Final cost estimataion\n",
    "print(f'Estimated cost: ${(sum(token_counts) / 1000 * 0.02)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(prompt, text):\n",
    "    return \"\"\"{}: \\n{} \\nfindings: \"\"\".format(prompt, text)\n",
    "\n",
    "# extract GPT-3 completions for each transcript\n",
    "def get_completions(prompt, text):\n",
    "    prompt = make_prompt(prompt, text)\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=512,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].text\n",
    "\n",
    "def get_completions_batch(prompt, texts):\n",
    "    prompts = [make_prompt(prompt, text) for text in texts]\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompts,\n",
    "        max_tokens=512,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return [choice.text for choice in response.choices]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is an interview with a person who might have depression. Determine if the text might be relevant to depression. Explain your answer in a verbose manner.  : \n",
      "start im going start virtual human shes going chat bit shes done shell let know shell say goodbye im going put doorbell right let okay thank high valley okay yes right new york state girlfriend months ago okay little different working weathers nice nothing far pretty good working nice thats real well moment theyre real good mean criminal justice wanted go boces one courses decided pick one certified nurses aide dont know maybe nursing someday much gets expensive read usually dont know usually dont get real real mad pretty good lot better child cant even remember long time guess tell dont know really ratings right well waiting appointment recently girlfriends positive met sisterinlaw muscle close anymore know right oh dont anything common dont talk dont know really dont impatient listen try reliable move california new york thats thats good experience nice exciting fairly difficult wake easily sometimes takes long time get tired fall asleep know quiet try stay cuz get irritable right anxious trying find job really know pretty pretty normal children ive got four 310 11 year olds thats dont know things day lot fun watching grow grow way interact sometimes people really amazing see fast dont develop dont know theres theres lot tied probably memorable probably yeah pretty easy lot fun worrying know worry getting hurt thats much probably go college get know try find look better job know feel happy time though mean thats real hard pinpoint \n",
      "findings: \n",
      "------------------------------------\n",
      "This is the completion:\n",
      "\n",
      "\n",
      "This text might be relevant to depression as it contains words and phrases that could indicate the person is struggling with depression. For example, the person mentions feeling \"real mad\" and \"anxious\", which are common symptoms of depression. They also mention feeling \"tired\" and \"irritable\", which are also common symptoms of depression. Additionally, the person mentions feeling \"worrying\" and \"impatient\", which are both common signs of depression. Finally, the person mentions feeling \"unhappy\" and \"difficult\", which are both common feelings associated with depression. All of these words and phrases could indicate that the person is struggling with depression.\n"
     ]
    }
   ],
   "source": [
    "# Explore the result\n",
    "# get completion for the first transcript in the dev set\n",
    "id = 347\n",
    "# find dv_dev row with id\n",
    "row = df_dev[df_dev['id'] == id]\n",
    "# get the value of the text column\n",
    "text = row['text'].values[0]\n",
    "print('This is the text:')\n",
    "print(make_prompt(prompt, text))\n",
    "print('------------------------------------')\n",
    "print('This is the completion:')\n",
    "completion = get_completions(prompt, text)\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we're sure that the prompt and completion are working as expected\n",
    "# Let's extract completions for all transcripts in the train, dev, and test sets\n",
    "# we will do this in batches of 10 to prevent API rate limits\n",
    "\n",
    "# get complettions in parallel in batches of 10\n",
    "df_dev['completions'] = ''\n",
    "for i in range(0, len(df_dev), 10):\n",
    "    print(f'Getting completions for dev transcripts {i} to {i+10}...')\n",
    "    # create a new column for completions\n",
    "    completions = get_completions_batch(prompt, df_dev['text'][i:i+10])\n",
    "    # convert list of completions to dataframe\n",
    "    df_completions = pd.DataFrame(completions, columns=['completions'])\n",
    "    # add completions to df_dev\n",
    "    df_dev['completions'][i:i+10] = df_completions['completions']\n",
    "\n",
    "\n",
    "df_train['completions'] = ''\n",
    "for i in range(0, len(df_train), 10):\n",
    "    print(f'Getting completions for train transcripts {i} to {i+10}...')\n",
    "    # create a new column for completions\n",
    "    completions = get_completions_batch(prompt, df_train['text'][i:i+10])\n",
    "    # convert list of completions to dataframe\n",
    "    df_completions = pd.DataFrame(completions, columns=['completions'])\n",
    "    # add completions to df_dev\n",
    "    df_train['completions'][i:i+10] = df_completions['completions']\n",
    "\n",
    "\n",
    "df_test['completions'] = ''\n",
    "for i in range(0, len(df_test), 10):\n",
    "    print(f'Getting completions for test transcripts {i} to {i+10}...')\n",
    "    # create a new column for completions\n",
    "    completions = get_completions_batch(prompt, df_test['text'][i:i+10])\n",
    "    # convert list of completions to dataframe\n",
    "    df_completions = pd.DataFrame(completions, columns=['completions'])\n",
    "    # add completions to df_dev\n",
    "    df_test['completions'][i:i+10] = df_completions['completions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>PHQ_Binary</th>\n",
       "      <th>PHQ_Score</th>\n",
       "      <th>PCL-C (PTSD)</th>\n",
       "      <th>PTSD Severity</th>\n",
       "      <th>text</th>\n",
       "      <th>completions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>okay coming go ahead shrink back continue sett...</td>\n",
       "      <td>\\n\\nThe text does appear to be relevant to dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>602</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>super need like either home wow okay alrighty ...</td>\n",
       "      <td>\\n\\nThis text is potentially relevant to depre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>604</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>passed make sure audio recognition system work...</td>\n",
       "      <td>\\n\\nThis text might be relevant to depression ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>605</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>remember bring virtual human second hes ill le...</td>\n",
       "      <td>\\n\\nThis text might be relevant to depression ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>606</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>hey got got new okay theres new phone kind har...</td>\n",
       "      <td>\\n\\nThis text could be relevant to depression,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  Gender  PHQ_Binary  PHQ_Score  PCL-C (PTSD)  PTSD Severity  \\\n",
       "0  600  female           0          5             0           23.0   \n",
       "1  602  female           1         13             1           67.0   \n",
       "2  604    male           1         12             0           30.0   \n",
       "3  605    male           0          2             0           23.0   \n",
       "4  606  female           0          5             0           46.0   \n",
       "\n",
       "                                                text  \\\n",
       "0  okay coming go ahead shrink back continue sett...   \n",
       "1  super need like either home wow okay alrighty ...   \n",
       "2  passed make sure audio recognition system work...   \n",
       "3  remember bring virtual human second hes ill le...   \n",
       "4  hey got got new okay theres new phone kind har...   \n",
       "\n",
       "                                         completions  \n",
       "0  \\n\\nThe text does appear to be relevant to dep...  \n",
       "1  \\n\\nThis text is potentially relevant to depre...  \n",
       "2  \\n\\nThis text might be relevant to depression ...  \n",
       "3  \\n\\nThis text might be relevant to depression ...  \n",
       "4  \\n\\nThis text could be relevant to depression,...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract deproberta features from column df['text']\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"rafalposwiata/deproberta-large-depression\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"rafalposwiata/deproberta-large-depression\")\n",
    "\n",
    "# model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "X_train = df_train['completions']\n",
    "X_dev = df_dev['completions']\n",
    "X_test = df_test['completions']\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_dev))\n",
    "print(len(X_test))\n",
    "\n",
    "# extract features from train data\n",
    "X_train_features = []\n",
    "for i in range(len(X_train)):\n",
    "    input_ids = torch.tensor(tokenizer.encode(X_train[i], add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "    outputs = model(input_ids)\n",
    "    X_train_features.append(outputs[0].detach().numpy())\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "\n",
    "# extract features from dev data\n",
    "X_dev_features = []\n",
    "for i in range(len(X_dev)):\n",
    "    input_ids = torch.tensor(tokenizer.encode(X_dev[i], add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "    outputs = model(input_ids)\n",
    "    X_dev_features.append(outputs[0].detach().numpy())\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "\n",
    "# extract features from test data\n",
    "X_test_features = []\n",
    "for i in range(len(X_test)):\n",
    "    input_ids = torch.tensor(tokenizer.encode(X_test[i], add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "    outputs = model(input_ids)\n",
    "    X_test_features.append(outputs[0].detach().numpy())\n",
    "    if i % 100 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy arrays\n",
    "deproberta_features_train = np.array(X_train_features)\n",
    "deproberta_features_dev = np.array(X_dev_features)\n",
    "deproberta_features_test = np.array(X_test_features)\n",
    "\n",
    "# reshape the features\n",
    "deproberta_features_train = deproberta_features_train.reshape(deproberta_features_train.shape[0], deproberta_features_train.shape[2])\n",
    "deproberta_features_dev = deproberta_features_dev.reshape(deproberta_features_dev.shape[0], deproberta_features_dev.shape[2])\n",
    "deproberta_features_test = deproberta_features_test.reshape(deproberta_features_test.shape[0], deproberta_features_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a SVR model on the bert_features and PHQ_Score as the target\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X_train = np.array(deproberta_features_train)\n",
    "X_dev = np.array(deproberta_features_dev)\n",
    "X_test = np.array(deproberta_features_test)\n",
    "y_train = np.array(df_train['PHQ_Score'])\n",
    "y_dev = np.array(df_dev['PHQ_Score'])\n",
    "y_test = np.array(df_test['PHQ_Score'])\n",
    "\n",
    "# train a SVR model on X_train and y_train\n",
    "svr = SVR(kernel='rbf', C=3.5, gamma=0.1)\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# predict on X_train and calculate the mean squared error and mean absolute error\n",
    "y_pred = svr.predict(X_train)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "print('rmse for train: ', np.sqrt(mse))\n",
    "print('mae for train: ', mae)\n",
    "\n",
    "# predict on X_dev and calculate the mean squared error and mean absolute error\n",
    "y_pred = svr.predict(X_dev)\n",
    "mse = mean_squared_error(y_dev, y_pred)\n",
    "mae = mean_absolute_error(y_dev, y_pred)\n",
    "print('rmse for dev: ', np.sqrt(mse))\n",
    "print('mae for dev: ', mae)\n",
    "\n",
    "# predict on X_dev and calculate the mean squared error and mean absolute error\n",
    "y_pred = svr.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('rmse for test: ', np.sqrt(mse))\n",
    "print('mae for test: ', mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bfacfc1d625e194ec392e142e035347b9b52a1a4dcc1c7f95dc9d16649dbfb09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
