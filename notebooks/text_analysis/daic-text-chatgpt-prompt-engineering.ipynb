{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = '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' # for my personal account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_13824/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>PHQ_Binary</th>\n",
       "      <th>PHQ_Score</th>\n",
       "      <th>PCL-C (PTSD)</th>\n",
       "      <th>PTSD Severity</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>which will record your body. So I'll show you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>Yeah, there's all sorts of different studies ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>306</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>Okay, looks like we're good. But let's move a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>317</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>Okay. How long is this? This is probably goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>320</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>Okay, everything looks good. Okay. Perfect. O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  Gender  PHQ_Binary  PHQ_Score  PCL-C (PTSD)  PTSD Severity  \\\n",
       "0  300    male           0          2             0             25   \n",
       "1  301    male           0          3             0             17   \n",
       "2  306  female           0          0             0             21   \n",
       "3  317    male           0          8             1             51   \n",
       "4  320  female           0         11             1             64   \n",
       "\n",
       "                                                text  \n",
       "0   which will record your body. So I'll show you...  \n",
       "1   Yeah, there's all sorts of different studies ...  \n",
       "2   Okay, looks like we're good. But let's move a...  \n",
       "3   Okay. How long is this? This is probably goin...  \n",
       "4   Okay, everything looks good. Okay. Perfect. O...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "directory_path = '../data/transcripts_from_whisper/'\n",
    "\n",
    "transcripts_df = pd.DataFrame(columns=[\"id\", \"text\"])\n",
    "\n",
    "# extract ids from filenames and text from files\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_id = filename[:3]\n",
    "        with open(os.path.join(directory_path, filename), \"r\") as file:\n",
    "            file_contents = file.read()\n",
    "        transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
    "\n",
    "transcripts_df[\"id\"] = transcripts_df[\"id\"].astype(\"int64\")\n",
    "\n",
    "labels_dev_df = pd.read_csv('../data/labels/dev_split.csv')\n",
    "labels_dev_df.columns = ['id', 'Gender', 'PHQ_Binary', 'PHQ_Score', 'PCL-C (PTSD)', 'PTSD Severity']\n",
    "\n",
    "labels_train_df = pd.read_csv('../data/labels/train_split.csv')\n",
    "labels_train_df.columns = ['id', 'Gender', 'PHQ_Binary', 'PHQ_Score', 'PCL-C (PTSD)', 'PTSD Severity']\n",
    "\n",
    "labels_test_df = pd.read_csv('../data/labels/test_split.csv')\n",
    "labels_test_df.columns = ['id', 'Gender', 'PHQ_Binary', 'PHQ_Score', 'PCL-C (PTSD)', 'PTSD Severity']\n",
    "\n",
    "# merge dataframes on id\n",
    "df_dev = pd.merge(labels_dev_df, transcripts_df, on='id')\n",
    "df_train = pd.merge(labels_train_df, transcripts_df, on='id')\n",
    "df_test = pd.merge(labels_test_df, transcripts_df, on='id')\n",
    "\n",
    "df_dev = df_dev.sort_values(by=\"id\")\n",
    "df_train = df_train.sort_values(by=\"id\")\n",
    "df_test = df_test.sort_values(by=\"id\")\n",
    "\n",
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df_train['PHQ_Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# transcripts_df = pd.read_csv('../data/transcripts.csv')\n",
    "# # remove first column\n",
    "# transcripts_df = transcripts_df.iloc[:,1:]\n",
    "# transcripts_df.columns = ['id', 'text']\n",
    "\n",
    "# labels_dev_df = pd.read_csv('../data/labels/dev_split.csv')\n",
    "# labels_dev_df.columns = ['id', 'Gender', 'PHQ_Binary', 'PHQ_Score', 'PCL-C (PTSD)', 'PTSD Severity']\n",
    "\n",
    "# labels_train_df = pd.read_csv('../data/labels/train_split.csv')\n",
    "# labels_train_df.columns = ['id', 'Gender', 'PHQ_Binary', 'PHQ_Score', 'PCL-C (PTSD)', 'PTSD Severity']\n",
    "\n",
    "# labels_test_df = pd.read_csv('../data/labels/test_split.csv')\n",
    "# labels_test_df.columns = ['id', 'Gender', 'PHQ_Binary', 'PHQ_Score', 'PCL-C (PTSD)', 'PTSD Severity']\n",
    "\n",
    "# # merge dataframes on id\n",
    "# df_dev = pd.merge(labels_dev_df, transcripts_df, on='id')\n",
    "# df_train = pd.merge(labels_train_df, transcripts_df, on='id')\n",
    "# df_test = pd.merge(labels_test_df, transcripts_df, on='id')\n",
    "\n",
    "# df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem import PorterStemmer\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# def clean_text(text):\n",
    "#     # remove punctuation and special characters\n",
    "#     text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "#     # lowercase all words\n",
    "#     text = text.lower()\n",
    "\n",
    "#     # remove stop words\n",
    "#     stop_words = set(stopwords.words('english'))\n",
    "#     text = [word for word in text.split() if word not in stop_words]\n",
    "\n",
    "#     # stem/lemmatize words\n",
    "#     # stemmer = PorterStemmer()\n",
    "#     # text = [stemmer.stem(word) for word in text]\n",
    "\n",
    "#     # remove numbers\n",
    "#     # text = [word for word in text if not word.isdigit()]\n",
    "\n",
    "#     return \" \".join(text)\n",
    "\n",
    "# # clean all transcripts\n",
    "# df_dev['text'] = df_dev['text'].apply(clean_text)\n",
    "# df_train['text'] = df_train['text'].apply(clean_text)\n",
    "# df_test['text'] = df_test['text'].apply(clean_text)\n",
    "\n",
    "# df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!! this is the prompt that we will use for Chat-GPT API !!!!!\n",
    "# prompt = \"\"\" Here is an interview with a person who might have depression. Determine if the text might be relevant to depression. Explain your answer in a verbose manner.  \"\"\"\n",
    "# prompt = \"\"\"  I am sending a text from an interview with a person. Can you tell me  features that can be clues for depression in the text? Additionally, mention the positive aspects in the person's interview if there is any. Please don't present features in a numbered list and explain your answer in a verbose and detail manner. Here is the text: \"\"\"\n",
    "# prompt = \"\"\"  I am sending a text from an interview with a person. Can you tell me features that are clues for depression detection in the text? Here is the text: \"\"\"\n",
    "# prompt = \"\"\" I am sending a transcript of an interview with a person. What are the key linguistic features that are indicative of depression in written text? Avoid being overly pessimistic and solely focusing on negative features. Be sure to include positive attributes and responses of the person as well. Be concise and to the point. Here is the text: \"\"\"\n",
    "prompt1 = \"\"\" Your task is to read the following text which is an interview with a person and to summarize the key points that might be related to the depression of the person. Please be concise and to the point.\"\"\"\n",
    "# prompt 1 results:\n",
    "# rmse for train:  5.639914434096471\n",
    "# mae for train:  4.253329681080664\n",
    "# rmse for dev:  5.315697780631046\n",
    "# mae for dev:  3.9190065015199598\n",
    "# rmse for test:  5.872976836334969\n",
    "# mae for test:  4.730438183491851\n",
    "prompt2 = \"\"\" Your task is to read the following text which is an interview with a person and to give a number from 0 to 100 that how likely is that this person has depression. \n",
    "Only give a number and do not explain your answer. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated cost: $1.3496780000000002\n"
     ]
    }
   ],
   "source": [
    "# GPT-3 cost estimator for all completions\n",
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "\n",
    "token_counts = []\n",
    "# for all tokens in all transcripts in dev, train, and test sets\n",
    "for text in df_dev['text'].tolist() + df_train['text'].tolist() + df_test['text'].tolist():\n",
    "    # tokenize text\n",
    "    tokens = tokenizer.encode(text)\n",
    "    # tokenize prompt\n",
    "    prompt_tokens = tokenizer.encode(prompt1)\n",
    "\n",
    "    # append token count to list\n",
    "    token_counts.append(len(tokens) + len(prompt_tokens) + 512)\n",
    "\n",
    "# Final cost estimataion\n",
    "print(f'Estimated cost: ${(sum(token_counts) / 1000 * 0.002)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def make_prompt(prompt, text):\n",
    "    return \"\"\"{}\\nHere is the interview between triple backticks:\\n```{}```\"\"\".format(prompt, text)\n",
    "\n",
    "# extract ChatGPT completions for each transcript\n",
    "def get_completions(prompt, text):\n",
    "    prompt = make_prompt(prompt, text)\n",
    "    # send request to API\n",
    "    response = requests.post(\n",
    "        \"http://localhost:4100/parallel-requests\",\n",
    "        json={\"prompts\": prompt}\n",
    "    )\n",
    "    # get response\n",
    "    response = response.json()\n",
    "    return response[\"response\"]\n",
    "\n",
    "def get_completions_batch(prompt, texts):\n",
    "    prompts = [make_prompt(prompt, text) for text in texts]\n",
    "    prompts = \"---\".join(prompts)\n",
    "\n",
    "    # send request to API\n",
    "    response = requests.post(\n",
    "        \"http://localhost:4100/parallel-requests\",\n",
    "        json={\"prompts\": prompts}\n",
    "    )\n",
    "\n",
    "    # get response\n",
    "    response = response.json()\n",
    "    return response[\"response\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the result\n",
    "# get completion for the first transcript in the dev set\n",
    "id = 633\n",
    "# find dv_dev row with id\n",
    "row = df_train[df_train['id'] == id]\n",
    "# get the value of the text column\n",
    "text = row['text'].values[0]\n",
    "print('This is the text:')\n",
    "print(make_prompt(prompt1, text))\n",
    "print('------------------------------------')\n",
    "print('This is the completion:')\n",
    "completions = get_completions(prompt1, text)\n",
    "print(completions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we're sure that the prompt and completion are working as expected\n",
    "# Let's extract completions for all transcripts in the train, dev, and test sets\n",
    "# we will do this in batches of 10 to prevent API rate limits\n",
    "\n",
    "# get complettions in parallel in batches of 10\n",
    "# df_dev['completions'] = ''\n",
    "# for i in range(0, len(df_dev), 10):\n",
    "#     print(f'Getting completions for dev transcripts {i} to {i+10}...')\n",
    "#     # create a new column for completions\n",
    "#     completions = get_completions_batch(prompt, df_dev['text'][i:i+10])\n",
    "#     # convert list of completions to dataframe\n",
    "#     df_completions = pd.DataFrame(completions, columns=['completions'])\n",
    "#     # add completions to df_dev\n",
    "#     df_dev['completions'][i:i+10] = df_completions['completions']\n",
    "\n",
    "# df_train['completions'] = ''\n",
    "# for i in range(0, len(df_train), 10):\n",
    "#     print(f'Getting completions for train transcripts {i} to {i+10}...')\n",
    "#     # create a new column for completions\n",
    "#     completions = get_completions_batch(prompt1, df_train['text'][i:i+10])\n",
    "#     # convert list of completions to dataframe\n",
    "#     df_completions = pd.DataFrame(completions, columns=['completions'])\n",
    "#     # add completions to df_dev\n",
    "#     df_train['completions'][i:i+10] = df_completions['completions']\n",
    "\n",
    "\n",
    "# df_test['completions'] = ''\n",
    "# for i in range(0, len(df_test), 10):\n",
    "#     print(f'Getting completions for test transcripts {i} to {i+10}...')\n",
    "#     # create a new column for completions\n",
    "#     completions = get_completions_batch(prompt, df_test['text'][i:i+10])\n",
    "#     # convert list of completions to dataframe\n",
    "#     df_completions = pd.DataFrame(completions, columns=['completions'])\n",
    "#     # add completions to df_dev\n",
    "#     df_test['completions'][i:i+10] = df_completions['completions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.to_csv('df_train_prompt_1.csv', index=False)\n",
    "# df_dev.to_csv('df_dev_prompt_1.csv', index=False)\n",
    "# df_test.to_csv('df_test_prompt_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>PHQ_Binary</th>\n",
       "      <th>PHQ_Score</th>\n",
       "      <th>PCL-C (PTSD)</th>\n",
       "      <th>PTSD Severity</th>\n",
       "      <th>text</th>\n",
       "      <th>completions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Alright, there you are. Perfect. So you're go...</td>\n",
       "      <td>I was diagnosed with depression in 2002 after ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>602</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>This is super neat. I like this. Me either at...</td>\n",
       "      <td>I have been diagnosed with PTSD almost two yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>604</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>So if you could just say 1, 2, 3, 4, 5. 1, 2,...</td>\n",
       "      <td>I have not been diagnosed with depression, but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>605</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>I'm going to bring up our virtual human for a...</td>\n",
       "      <td>I was interviewed by a virtual human where I r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>606</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Okay, I just got it. I just got it new. So, o...</td>\n",
       "      <td>The interviewee seems to have a negative attit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  Gender  PHQ_Binary  PHQ_Score  PCL-C (PTSD)  PTSD Severity  \\\n",
       "0  600  female           0          5             0           23.0   \n",
       "1  602  female           1         13             1           67.0   \n",
       "2  604    male           1         12             0           30.0   \n",
       "3  605    male           0          2             0           23.0   \n",
       "4  606  female           0          5             0           46.0   \n",
       "\n",
       "                                                text  \\\n",
       "0   Alright, there you are. Perfect. So you're go...   \n",
       "1   This is super neat. I like this. Me either at...   \n",
       "2   So if you could just say 1, 2, 3, 4, 5. 1, 2,...   \n",
       "3   I'm going to bring up our virtual human for a...   \n",
       "4   Okay, I just got it. I just got it new. So, o...   \n",
       "\n",
       "                                         completions  \n",
       "0  I was diagnosed with depression in 2002 after ...  \n",
       "1  I have been diagnosed with PTSD almost two yea...  \n",
       "2  I have not been diagnosed with depression, but...  \n",
       "3  I was interviewed by a virtual human where I r...  \n",
       "4  The interviewee seems to have a negative attit...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('df_train_prompt_3_firstperson.csv')\n",
    "df_dev = pd.read_csv('df_dev_prompt_3_firstperson.csv')\n",
    "df_test = pd.read_csv('df_test_prompt_3_firstperson.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['completions'] = df_train['completions'].astype('string')\n",
    "df_dev['completions'] = df_dev['completions'].astype('string')\n",
    "df_test['completions'] = df_test['completions'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id, Gender, PHQ_Binary, PHQ_Score, PCL-C (PTSD), PTSD Severity, text, completions]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(df_test.loc[df_test['completions'].str.len() == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>PHQ_Binary</th>\n",
       "      <th>PHQ_Score</th>\n",
       "      <th>PCL-C (PTSD)</th>\n",
       "      <th>PTSD Severity</th>\n",
       "      <th>text</th>\n",
       "      <th>completions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>which will record your body. So I'll show you...</td>\n",
       "      <td>I have not found any key points related to dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>Yeah, there's all sorts of different studies ...</td>\n",
       "      <td>I work as an administrative assistant through ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>306</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>Okay, looks like we're good. But let's move a...</td>\n",
       "      <td>I had an interview with a computer program des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>317</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>Okay. How long is this? This is probably goin...</td>\n",
       "      <td>I moved from New York to start over, and it wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>320</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>Okay, everything looks good. Okay. Perfect. O...</td>\n",
       "      <td>I was interviewed by a virtual human who asked...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  Gender  PHQ_Binary  PHQ_Score  PCL-C (PTSD)  PTSD Severity  \\\n",
       "0  300    male           0          2             0             25   \n",
       "1  301    male           0          3             0             17   \n",
       "2  306  female           0          0             0             21   \n",
       "3  317    male           0          8             1             51   \n",
       "4  320  female           0         11             1             64   \n",
       "\n",
       "                                                text  \\\n",
       "0   which will record your body. So I'll show you...   \n",
       "1   Yeah, there's all sorts of different studies ...   \n",
       "2   Okay, looks like we're good. But let's move a...   \n",
       "3   Okay. How long is this? This is probably goin...   \n",
       "4   Okay, everything looks good. Okay. Perfect. O...   \n",
       "\n",
       "                                         completions  \n",
       "0  I have not found any key points related to dep...  \n",
       "1  I work as an administrative assistant through ...  \n",
       "2  I had an interview with a computer program des...  \n",
       "3  I moved from New York to start over, and it wa...  \n",
       "4  I was interviewed by a virtual human who asked...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print df_train that completions is empty\n",
    "# # df_train[df_train['completions'] == '']\n",
    "\n",
    "# # for rows with empty completions\n",
    "# for i in range(0, len(df_train)):\n",
    "#     if df_train['completions'][i] == '':\n",
    "#         print(i)\n",
    "#         print(df_train['id'][i])\n",
    "#         # # find file that starts with id\n",
    "#         file_path = '../data/transcripts_from_whisper/' + str(df_train['id'][i]) + '_whisper.txt'\n",
    "#         # open file\n",
    "#         with open(file_path, 'r') as file:\n",
    "#             # read file\n",
    "#             text = file.read()\n",
    "#             print(text)\n",
    "#             df_train['text'][i] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_nan_df_train = df_train.dropna()\n",
    "# non_nan_df_dev = df_dev.dropna()\n",
    "# non_nan_df_test = df_test.dropna()\n",
    "\n",
    "# non_nan_df_train = non_nan_df_train.reset_index(drop=True)\n",
    "# non_nan_df_dev = non_nan_df_dev.reset_index(drop=True)\n",
    "# non_nan_df_test = non_nan_df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta.embeddings.word_embeddings.weight\n",
      "roberta.embeddings.position_embeddings.weight\n",
      "roberta.embeddings.token_type_embeddings.weight\n",
      "roberta.embeddings.LayerNorm.weight\n",
      "roberta.embeddings.LayerNorm.bias\n",
      "roberta.encoder.layer.0.attention.self.query.weight\n",
      "roberta.encoder.layer.0.attention.self.query.bias\n",
      "roberta.encoder.layer.0.attention.self.key.weight\n",
      "roberta.encoder.layer.0.attention.self.key.bias\n",
      "roberta.encoder.layer.0.attention.self.value.weight\n",
      "roberta.encoder.layer.0.attention.self.value.bias\n",
      "roberta.encoder.layer.0.attention.output.dense.weight\n",
      "roberta.encoder.layer.0.attention.output.dense.bias\n",
      "roberta.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.0.intermediate.dense.weight\n",
      "roberta.encoder.layer.0.intermediate.dense.bias\n",
      "roberta.encoder.layer.0.output.dense.weight\n",
      "roberta.encoder.layer.0.output.dense.bias\n",
      "roberta.encoder.layer.0.output.LayerNorm.weight\n",
      "roberta.encoder.layer.0.output.LayerNorm.bias\n",
      "roberta.encoder.layer.1.attention.self.query.weight\n",
      "roberta.encoder.layer.1.attention.self.query.bias\n",
      "roberta.encoder.layer.1.attention.self.key.weight\n",
      "roberta.encoder.layer.1.attention.self.key.bias\n",
      "roberta.encoder.layer.1.attention.self.value.weight\n",
      "roberta.encoder.layer.1.attention.self.value.bias\n",
      "roberta.encoder.layer.1.attention.output.dense.weight\n",
      "roberta.encoder.layer.1.attention.output.dense.bias\n",
      "roberta.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.1.intermediate.dense.weight\n",
      "roberta.encoder.layer.1.intermediate.dense.bias\n",
      "roberta.encoder.layer.1.output.dense.weight\n",
      "roberta.encoder.layer.1.output.dense.bias\n",
      "roberta.encoder.layer.1.output.LayerNorm.weight\n",
      "roberta.encoder.layer.1.output.LayerNorm.bias\n",
      "roberta.encoder.layer.2.attention.self.query.weight\n",
      "roberta.encoder.layer.2.attention.self.query.bias\n",
      "roberta.encoder.layer.2.attention.self.key.weight\n",
      "roberta.encoder.layer.2.attention.self.key.bias\n",
      "roberta.encoder.layer.2.attention.self.value.weight\n",
      "roberta.encoder.layer.2.attention.self.value.bias\n",
      "roberta.encoder.layer.2.attention.output.dense.weight\n",
      "roberta.encoder.layer.2.attention.output.dense.bias\n",
      "roberta.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.2.intermediate.dense.weight\n",
      "roberta.encoder.layer.2.intermediate.dense.bias\n",
      "roberta.encoder.layer.2.output.dense.weight\n",
      "roberta.encoder.layer.2.output.dense.bias\n",
      "roberta.encoder.layer.2.output.LayerNorm.weight\n",
      "roberta.encoder.layer.2.output.LayerNorm.bias\n",
      "roberta.encoder.layer.3.attention.self.query.weight\n",
      "roberta.encoder.layer.3.attention.self.query.bias\n",
      "roberta.encoder.layer.3.attention.self.key.weight\n",
      "roberta.encoder.layer.3.attention.self.key.bias\n",
      "roberta.encoder.layer.3.attention.self.value.weight\n",
      "roberta.encoder.layer.3.attention.self.value.bias\n",
      "roberta.encoder.layer.3.attention.output.dense.weight\n",
      "roberta.encoder.layer.3.attention.output.dense.bias\n",
      "roberta.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.3.intermediate.dense.weight\n",
      "roberta.encoder.layer.3.intermediate.dense.bias\n",
      "roberta.encoder.layer.3.output.dense.weight\n",
      "roberta.encoder.layer.3.output.dense.bias\n",
      "roberta.encoder.layer.3.output.LayerNorm.weight\n",
      "roberta.encoder.layer.3.output.LayerNorm.bias\n",
      "roberta.encoder.layer.4.attention.self.query.weight\n",
      "roberta.encoder.layer.4.attention.self.query.bias\n",
      "roberta.encoder.layer.4.attention.self.key.weight\n",
      "roberta.encoder.layer.4.attention.self.key.bias\n",
      "roberta.encoder.layer.4.attention.self.value.weight\n",
      "roberta.encoder.layer.4.attention.self.value.bias\n",
      "roberta.encoder.layer.4.attention.output.dense.weight\n",
      "roberta.encoder.layer.4.attention.output.dense.bias\n",
      "roberta.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.4.intermediate.dense.weight\n",
      "roberta.encoder.layer.4.intermediate.dense.bias\n",
      "roberta.encoder.layer.4.output.dense.weight\n",
      "roberta.encoder.layer.4.output.dense.bias\n",
      "roberta.encoder.layer.4.output.LayerNorm.weight\n",
      "roberta.encoder.layer.4.output.LayerNorm.bias\n",
      "roberta.encoder.layer.5.attention.self.query.weight\n",
      "roberta.encoder.layer.5.attention.self.query.bias\n",
      "roberta.encoder.layer.5.attention.self.key.weight\n",
      "roberta.encoder.layer.5.attention.self.key.bias\n",
      "roberta.encoder.layer.5.attention.self.value.weight\n",
      "roberta.encoder.layer.5.attention.self.value.bias\n",
      "roberta.encoder.layer.5.attention.output.dense.weight\n",
      "roberta.encoder.layer.5.attention.output.dense.bias\n",
      "roberta.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.5.intermediate.dense.weight\n",
      "roberta.encoder.layer.5.intermediate.dense.bias\n",
      "roberta.encoder.layer.5.output.dense.weight\n",
      "roberta.encoder.layer.5.output.dense.bias\n",
      "roberta.encoder.layer.5.output.LayerNorm.weight\n",
      "roberta.encoder.layer.5.output.LayerNorm.bias\n",
      "roberta.encoder.layer.6.attention.self.query.weight\n",
      "roberta.encoder.layer.6.attention.self.query.bias\n",
      "roberta.encoder.layer.6.attention.self.key.weight\n",
      "roberta.encoder.layer.6.attention.self.key.bias\n",
      "roberta.encoder.layer.6.attention.self.value.weight\n",
      "roberta.encoder.layer.6.attention.self.value.bias\n",
      "roberta.encoder.layer.6.attention.output.dense.weight\n",
      "roberta.encoder.layer.6.attention.output.dense.bias\n",
      "roberta.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.6.intermediate.dense.weight\n",
      "roberta.encoder.layer.6.intermediate.dense.bias\n",
      "roberta.encoder.layer.6.output.dense.weight\n",
      "roberta.encoder.layer.6.output.dense.bias\n",
      "roberta.encoder.layer.6.output.LayerNorm.weight\n",
      "roberta.encoder.layer.6.output.LayerNorm.bias\n",
      "roberta.encoder.layer.7.attention.self.query.weight\n",
      "roberta.encoder.layer.7.attention.self.query.bias\n",
      "roberta.encoder.layer.7.attention.self.key.weight\n",
      "roberta.encoder.layer.7.attention.self.key.bias\n",
      "roberta.encoder.layer.7.attention.self.value.weight\n",
      "roberta.encoder.layer.7.attention.self.value.bias\n",
      "roberta.encoder.layer.7.attention.output.dense.weight\n",
      "roberta.encoder.layer.7.attention.output.dense.bias\n",
      "roberta.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.7.intermediate.dense.weight\n",
      "roberta.encoder.layer.7.intermediate.dense.bias\n",
      "roberta.encoder.layer.7.output.dense.weight\n",
      "roberta.encoder.layer.7.output.dense.bias\n",
      "roberta.encoder.layer.7.output.LayerNorm.weight\n",
      "roberta.encoder.layer.7.output.LayerNorm.bias\n",
      "roberta.encoder.layer.8.attention.self.query.weight\n",
      "roberta.encoder.layer.8.attention.self.query.bias\n",
      "roberta.encoder.layer.8.attention.self.key.weight\n",
      "roberta.encoder.layer.8.attention.self.key.bias\n",
      "roberta.encoder.layer.8.attention.self.value.weight\n",
      "roberta.encoder.layer.8.attention.self.value.bias\n",
      "roberta.encoder.layer.8.attention.output.dense.weight\n",
      "roberta.encoder.layer.8.attention.output.dense.bias\n",
      "roberta.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.8.intermediate.dense.weight\n",
      "roberta.encoder.layer.8.intermediate.dense.bias\n",
      "roberta.encoder.layer.8.output.dense.weight\n",
      "roberta.encoder.layer.8.output.dense.bias\n",
      "roberta.encoder.layer.8.output.LayerNorm.weight\n",
      "roberta.encoder.layer.8.output.LayerNorm.bias\n",
      "roberta.encoder.layer.9.attention.self.query.weight\n",
      "roberta.encoder.layer.9.attention.self.query.bias\n",
      "roberta.encoder.layer.9.attention.self.key.weight\n",
      "roberta.encoder.layer.9.attention.self.key.bias\n",
      "roberta.encoder.layer.9.attention.self.value.weight\n",
      "roberta.encoder.layer.9.attention.self.value.bias\n",
      "roberta.encoder.layer.9.attention.output.dense.weight\n",
      "roberta.encoder.layer.9.attention.output.dense.bias\n",
      "roberta.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.9.intermediate.dense.weight\n",
      "roberta.encoder.layer.9.intermediate.dense.bias\n",
      "roberta.encoder.layer.9.output.dense.weight\n",
      "roberta.encoder.layer.9.output.dense.bias\n",
      "roberta.encoder.layer.9.output.LayerNorm.weight\n",
      "roberta.encoder.layer.9.output.LayerNorm.bias\n",
      "roberta.encoder.layer.10.attention.self.query.weight\n",
      "roberta.encoder.layer.10.attention.self.query.bias\n",
      "roberta.encoder.layer.10.attention.self.key.weight\n",
      "roberta.encoder.layer.10.attention.self.key.bias\n",
      "roberta.encoder.layer.10.attention.self.value.weight\n",
      "roberta.encoder.layer.10.attention.self.value.bias\n",
      "roberta.encoder.layer.10.attention.output.dense.weight\n",
      "roberta.encoder.layer.10.attention.output.dense.bias\n",
      "roberta.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.10.intermediate.dense.weight\n",
      "roberta.encoder.layer.10.intermediate.dense.bias\n",
      "roberta.encoder.layer.10.output.dense.weight\n",
      "roberta.encoder.layer.10.output.dense.bias\n",
      "roberta.encoder.layer.10.output.LayerNorm.weight\n",
      "roberta.encoder.layer.10.output.LayerNorm.bias\n",
      "roberta.encoder.layer.11.attention.self.query.weight\n",
      "roberta.encoder.layer.11.attention.self.query.bias\n",
      "roberta.encoder.layer.11.attention.self.key.weight\n",
      "roberta.encoder.layer.11.attention.self.key.bias\n",
      "roberta.encoder.layer.11.attention.self.value.weight\n",
      "roberta.encoder.layer.11.attention.self.value.bias\n",
      "roberta.encoder.layer.11.attention.output.dense.weight\n",
      "roberta.encoder.layer.11.attention.output.dense.bias\n",
      "roberta.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.11.intermediate.dense.weight\n",
      "roberta.encoder.layer.11.intermediate.dense.bias\n",
      "roberta.encoder.layer.11.output.dense.weight\n",
      "roberta.encoder.layer.11.output.dense.bias\n",
      "roberta.encoder.layer.11.output.LayerNorm.weight\n",
      "roberta.encoder.layer.11.output.LayerNorm.bias\n",
      "roberta.encoder.layer.12.attention.self.query.weight\n",
      "roberta.encoder.layer.12.attention.self.query.bias\n",
      "roberta.encoder.layer.12.attention.self.key.weight\n",
      "roberta.encoder.layer.12.attention.self.key.bias\n",
      "roberta.encoder.layer.12.attention.self.value.weight\n",
      "roberta.encoder.layer.12.attention.self.value.bias\n",
      "roberta.encoder.layer.12.attention.output.dense.weight\n",
      "roberta.encoder.layer.12.attention.output.dense.bias\n",
      "roberta.encoder.layer.12.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.12.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.12.intermediate.dense.weight\n",
      "roberta.encoder.layer.12.intermediate.dense.bias\n",
      "roberta.encoder.layer.12.output.dense.weight\n",
      "roberta.encoder.layer.12.output.dense.bias\n",
      "roberta.encoder.layer.12.output.LayerNorm.weight\n",
      "roberta.encoder.layer.12.output.LayerNorm.bias\n",
      "roberta.encoder.layer.13.attention.self.query.weight\n",
      "roberta.encoder.layer.13.attention.self.query.bias\n",
      "roberta.encoder.layer.13.attention.self.key.weight\n",
      "roberta.encoder.layer.13.attention.self.key.bias\n",
      "roberta.encoder.layer.13.attention.self.value.weight\n",
      "roberta.encoder.layer.13.attention.self.value.bias\n",
      "roberta.encoder.layer.13.attention.output.dense.weight\n",
      "roberta.encoder.layer.13.attention.output.dense.bias\n",
      "roberta.encoder.layer.13.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.13.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.13.intermediate.dense.weight\n",
      "roberta.encoder.layer.13.intermediate.dense.bias\n",
      "roberta.encoder.layer.13.output.dense.weight\n",
      "roberta.encoder.layer.13.output.dense.bias\n",
      "roberta.encoder.layer.13.output.LayerNorm.weight\n",
      "roberta.encoder.layer.13.output.LayerNorm.bias\n",
      "roberta.encoder.layer.14.attention.self.query.weight\n",
      "roberta.encoder.layer.14.attention.self.query.bias\n",
      "roberta.encoder.layer.14.attention.self.key.weight\n",
      "roberta.encoder.layer.14.attention.self.key.bias\n",
      "roberta.encoder.layer.14.attention.self.value.weight\n",
      "roberta.encoder.layer.14.attention.self.value.bias\n",
      "roberta.encoder.layer.14.attention.output.dense.weight\n",
      "roberta.encoder.layer.14.attention.output.dense.bias\n",
      "roberta.encoder.layer.14.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.14.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.14.intermediate.dense.weight\n",
      "roberta.encoder.layer.14.intermediate.dense.bias\n",
      "roberta.encoder.layer.14.output.dense.weight\n",
      "roberta.encoder.layer.14.output.dense.bias\n",
      "roberta.encoder.layer.14.output.LayerNorm.weight\n",
      "roberta.encoder.layer.14.output.LayerNorm.bias\n",
      "roberta.encoder.layer.15.attention.self.query.weight\n",
      "roberta.encoder.layer.15.attention.self.query.bias\n",
      "roberta.encoder.layer.15.attention.self.key.weight\n",
      "roberta.encoder.layer.15.attention.self.key.bias\n",
      "roberta.encoder.layer.15.attention.self.value.weight\n",
      "roberta.encoder.layer.15.attention.self.value.bias\n",
      "roberta.encoder.layer.15.attention.output.dense.weight\n",
      "roberta.encoder.layer.15.attention.output.dense.bias\n",
      "roberta.encoder.layer.15.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.15.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.15.intermediate.dense.weight\n",
      "roberta.encoder.layer.15.intermediate.dense.bias\n",
      "roberta.encoder.layer.15.output.dense.weight\n",
      "roberta.encoder.layer.15.output.dense.bias\n",
      "roberta.encoder.layer.15.output.LayerNorm.weight\n",
      "roberta.encoder.layer.15.output.LayerNorm.bias\n",
      "roberta.encoder.layer.16.attention.self.query.weight\n",
      "roberta.encoder.layer.16.attention.self.query.bias\n",
      "roberta.encoder.layer.16.attention.self.key.weight\n",
      "roberta.encoder.layer.16.attention.self.key.bias\n",
      "roberta.encoder.layer.16.attention.self.value.weight\n",
      "roberta.encoder.layer.16.attention.self.value.bias\n",
      "roberta.encoder.layer.16.attention.output.dense.weight\n",
      "roberta.encoder.layer.16.attention.output.dense.bias\n",
      "roberta.encoder.layer.16.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.16.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.16.intermediate.dense.weight\n",
      "roberta.encoder.layer.16.intermediate.dense.bias\n",
      "roberta.encoder.layer.16.output.dense.weight\n",
      "roberta.encoder.layer.16.output.dense.bias\n",
      "roberta.encoder.layer.16.output.LayerNorm.weight\n",
      "roberta.encoder.layer.16.output.LayerNorm.bias\n",
      "roberta.encoder.layer.17.attention.self.query.weight\n",
      "roberta.encoder.layer.17.attention.self.query.bias\n",
      "roberta.encoder.layer.17.attention.self.key.weight\n",
      "roberta.encoder.layer.17.attention.self.key.bias\n",
      "roberta.encoder.layer.17.attention.self.value.weight\n",
      "roberta.encoder.layer.17.attention.self.value.bias\n",
      "roberta.encoder.layer.17.attention.output.dense.weight\n",
      "roberta.encoder.layer.17.attention.output.dense.bias\n",
      "roberta.encoder.layer.17.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.17.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.17.intermediate.dense.weight\n",
      "roberta.encoder.layer.17.intermediate.dense.bias\n",
      "roberta.encoder.layer.17.output.dense.weight\n",
      "roberta.encoder.layer.17.output.dense.bias\n",
      "roberta.encoder.layer.17.output.LayerNorm.weight\n",
      "roberta.encoder.layer.17.output.LayerNorm.bias\n",
      "roberta.encoder.layer.18.attention.self.query.weight\n",
      "roberta.encoder.layer.18.attention.self.query.bias\n",
      "roberta.encoder.layer.18.attention.self.key.weight\n",
      "roberta.encoder.layer.18.attention.self.key.bias\n",
      "roberta.encoder.layer.18.attention.self.value.weight\n",
      "roberta.encoder.layer.18.attention.self.value.bias\n",
      "roberta.encoder.layer.18.attention.output.dense.weight\n",
      "roberta.encoder.layer.18.attention.output.dense.bias\n",
      "roberta.encoder.layer.18.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.18.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.18.intermediate.dense.weight\n",
      "roberta.encoder.layer.18.intermediate.dense.bias\n",
      "roberta.encoder.layer.18.output.dense.weight\n",
      "roberta.encoder.layer.18.output.dense.bias\n",
      "roberta.encoder.layer.18.output.LayerNorm.weight\n",
      "roberta.encoder.layer.18.output.LayerNorm.bias\n",
      "roberta.encoder.layer.19.attention.self.query.weight\n",
      "roberta.encoder.layer.19.attention.self.query.bias\n",
      "roberta.encoder.layer.19.attention.self.key.weight\n",
      "roberta.encoder.layer.19.attention.self.key.bias\n",
      "roberta.encoder.layer.19.attention.self.value.weight\n",
      "roberta.encoder.layer.19.attention.self.value.bias\n",
      "roberta.encoder.layer.19.attention.output.dense.weight\n",
      "roberta.encoder.layer.19.attention.output.dense.bias\n",
      "roberta.encoder.layer.19.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.19.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.19.intermediate.dense.weight\n",
      "roberta.encoder.layer.19.intermediate.dense.bias\n",
      "roberta.encoder.layer.19.output.dense.weight\n",
      "roberta.encoder.layer.19.output.dense.bias\n",
      "roberta.encoder.layer.19.output.LayerNorm.weight\n",
      "roberta.encoder.layer.19.output.LayerNorm.bias\n",
      "roberta.encoder.layer.20.attention.self.query.weight\n",
      "roberta.encoder.layer.20.attention.self.query.bias\n",
      "roberta.encoder.layer.20.attention.self.key.weight\n",
      "roberta.encoder.layer.20.attention.self.key.bias\n",
      "roberta.encoder.layer.20.attention.self.value.weight\n",
      "roberta.encoder.layer.20.attention.self.value.bias\n",
      "roberta.encoder.layer.20.attention.output.dense.weight\n",
      "roberta.encoder.layer.20.attention.output.dense.bias\n",
      "roberta.encoder.layer.20.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.20.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.20.intermediate.dense.weight\n",
      "roberta.encoder.layer.20.intermediate.dense.bias\n",
      "roberta.encoder.layer.20.output.dense.weight\n",
      "roberta.encoder.layer.20.output.dense.bias\n",
      "roberta.encoder.layer.20.output.LayerNorm.weight\n",
      "roberta.encoder.layer.20.output.LayerNorm.bias\n",
      "roberta.encoder.layer.21.attention.self.query.weight\n",
      "roberta.encoder.layer.21.attention.self.query.bias\n",
      "roberta.encoder.layer.21.attention.self.key.weight\n",
      "roberta.encoder.layer.21.attention.self.key.bias\n",
      "roberta.encoder.layer.21.attention.self.value.weight\n",
      "roberta.encoder.layer.21.attention.self.value.bias\n",
      "roberta.encoder.layer.21.attention.output.dense.weight\n",
      "roberta.encoder.layer.21.attention.output.dense.bias\n",
      "roberta.encoder.layer.21.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.21.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.21.intermediate.dense.weight\n",
      "roberta.encoder.layer.21.intermediate.dense.bias\n",
      "roberta.encoder.layer.21.output.dense.weight\n",
      "roberta.encoder.layer.21.output.dense.bias\n",
      "roberta.encoder.layer.21.output.LayerNorm.weight\n",
      "roberta.encoder.layer.21.output.LayerNorm.bias\n",
      "roberta.encoder.layer.22.attention.self.query.weight\n",
      "roberta.encoder.layer.22.attention.self.query.bias\n",
      "roberta.encoder.layer.22.attention.self.key.weight\n",
      "roberta.encoder.layer.22.attention.self.key.bias\n",
      "roberta.encoder.layer.22.attention.self.value.weight\n",
      "roberta.encoder.layer.22.attention.self.value.bias\n",
      "roberta.encoder.layer.22.attention.output.dense.weight\n",
      "roberta.encoder.layer.22.attention.output.dense.bias\n",
      "roberta.encoder.layer.22.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.22.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.22.intermediate.dense.weight\n",
      "roberta.encoder.layer.22.intermediate.dense.bias\n",
      "roberta.encoder.layer.22.output.dense.weight\n",
      "roberta.encoder.layer.22.output.dense.bias\n",
      "roberta.encoder.layer.22.output.LayerNorm.weight\n",
      "roberta.encoder.layer.22.output.LayerNorm.bias\n",
      "roberta.encoder.layer.23.attention.self.query.weight\n",
      "roberta.encoder.layer.23.attention.self.query.bias\n",
      "roberta.encoder.layer.23.attention.self.key.weight\n",
      "roberta.encoder.layer.23.attention.self.key.bias\n",
      "roberta.encoder.layer.23.attention.self.value.weight\n",
      "roberta.encoder.layer.23.attention.self.value.bias\n",
      "roberta.encoder.layer.23.attention.output.dense.weight\n",
      "roberta.encoder.layer.23.attention.output.dense.bias\n",
      "roberta.encoder.layer.23.attention.output.LayerNorm.weight\n",
      "roberta.encoder.layer.23.attention.output.LayerNorm.bias\n",
      "roberta.encoder.layer.23.intermediate.dense.weight\n",
      "roberta.encoder.layer.23.intermediate.dense.bias\n",
      "roberta.encoder.layer.23.output.dense.weight\n",
      "roberta.encoder.layer.23.output.dense.bias\n",
      "roberta.encoder.layer.23.output.LayerNorm.weight\n",
      "roberta.encoder.layer.23.output.LayerNorm.bias\n",
      "classifier.dense.weight\n",
      "classifier.dense.bias\n",
      "classifier.out_proj.weight\n",
      "classifier.out_proj.bias\n"
     ]
    }
   ],
   "source": [
    "# Print layer names\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"rafalposwiata/deproberta-large-depression\", output_hidden_states=True)\n",
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n",
      "56\n",
      "56\n",
      "0\n",
      "100\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# extract deproberta features from column df['text']\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"rafalposwiata/deproberta-large-depression\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"rafalposwiata/deproberta-large-depression\", output_hidden_states=True)\n",
    "\n",
    "# model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "# # first convert NaNs to empty strings\n",
    "# df_train['completions'] = df_train['completions'].fillna('')\n",
    "# df_dev['completions'] = df_dev['completions'].fillna('')\n",
    "# df_test['completions'] = df_test['completions'].fillna('')\n",
    "\n",
    "X_train = df_train['completions']\n",
    "X_dev = df_dev['completions']\n",
    "X_test = df_test['completions']\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_dev))\n",
    "print(len(X_test))\n",
    "\n",
    "y_train = np.array(df_train['PHQ_Score'])\n",
    "y_dev = np.array(df_dev['PHQ_Score'])\n",
    "y_test = np.array(df_test['PHQ_Score'])\n",
    "\n",
    "# extract features from train data\n",
    "X_train_features = []\n",
    "for i in range(len(X_train)):\n",
    "    # print('i train: ', i)\n",
    "    input_ids = torch.tensor(tokenizer.encode(X_train[i], add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "    outputs = model(input_ids)\n",
    "    \n",
    "    # get the logits from the output\n",
    "    logits = outputs[0]\n",
    "    # apply softmax to get the probabilities\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    # get the predicted label index (i.e., the index with the highest probability)\n",
    "    predicted_label_index = torch.argmax(probs, dim=1).item()\n",
    "    X_train_features.append(probs.detach().numpy())\n",
    "    \n",
    "    # print('---------------------')\n",
    "    # print('i: ', i)\n",
    "    # if predicted_label_index == 0:\n",
    "    #     print('severe')\n",
    "    # elif predicted_label_index ==1:\n",
    "    #     print('moderate')\n",
    "    # elif predicted_label_index ==2:\n",
    "    #     print('not depression')    \n",
    "    # else:\n",
    "    #     print('no label')    \n",
    "    # print('PHQ is: ', y_train[i])\n",
    "    # print('probs: ', probs)\n",
    "    \n",
    "    # X_train_features.append(outputs[0].detach().numpy())\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "\n",
    "# extract features from dev data\n",
    "X_dev_features = []\n",
    "for i in range(len(X_dev)):\n",
    "    # print('i dev: ', i)\n",
    "    input_ids = torch.tensor(tokenizer.encode(X_dev[i], add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "    outputs = model(input_ids)\n",
    "\n",
    "    # get the logits from the output\n",
    "    logits = outputs[0]\n",
    "    # apply softmax to get the probabilities\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    # get the predicted label index (i.e., the index with the highest probability)\n",
    "    predicted_label_index = torch.argmax(probs, dim=1).item()\n",
    "    X_dev_features.append(probs.detach().numpy())\n",
    "\n",
    "    # X_dev_features.append(outputs[0].detach().numpy())\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "\n",
    "# extract features from test data\n",
    "X_test_features = []\n",
    "for i in range(len(X_test)):\n",
    "    # print('i test: ', i)\n",
    "    input_ids = torch.tensor(tokenizer.encode(X_test[i], add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "    outputs = model(input_ids)\n",
    "\n",
    "    # get the logits from the output\n",
    "    logits = outputs[0]\n",
    "    # apply softmax to get the probabilities\n",
    "    probs = torch.softmax(logits, dim=1)\n",
    "    # get the predicted label index (i.e., the index with the highest probability)\n",
    "    predicted_label_index = torch.argmax(probs, dim=1).item()\n",
    "    X_test_features.append(probs.detach().numpy())\n",
    "\n",
    "    # X_test_features.append(outputs[0].detach().numpy())\n",
    "    if i % 100 == 0:\n",
    "        print(i)  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n",
      "(1, 3)\n",
      "(1, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_features[2].shape)\n",
    "print(X_dev_features[2].shape)\n",
    "print(X_test_features[10].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.04594771, 0.73226935, 0.22178294]], dtype=float32),\n",
       " array([[0.01544387, 0.12209383, 0.8624622 ]], dtype=float32),\n",
       " array([[0.00854682, 0.16256104, 0.8288921 ]], dtype=float32),\n",
       " array([[0.7878974, 0.1019187, 0.1101839]], dtype=float32),\n",
       " array([[0.11958139, 0.30254945, 0.5778692 ]], dtype=float32),\n",
       " array([[0.5143548 , 0.44336036, 0.04228478]], dtype=float32),\n",
       " array([[0.72259307, 0.2442132 , 0.03319371]], dtype=float32),\n",
       " array([[0.03341649, 0.21408467, 0.75249887]], dtype=float32),\n",
       " array([[0.78910667, 0.13773926, 0.07315407]], dtype=float32),\n",
       " array([[0.01476022, 0.09589555, 0.8893443 ]], dtype=float32),\n",
       " array([[0.04109652, 0.10564982, 0.85325366]], dtype=float32),\n",
       " array([[0.02030646, 0.0707326 , 0.90896094]], dtype=float32),\n",
       " array([[0.00798201, 0.16224383, 0.8297741 ]], dtype=float32),\n",
       " array([[0.03640566, 0.68157387, 0.28202045]], dtype=float32),\n",
       " array([[0.0067701 , 0.10678197, 0.88644797]], dtype=float32),\n",
       " array([[0.5816213 , 0.21935636, 0.19902238]], dtype=float32),\n",
       " array([[0.7426504 , 0.19809932, 0.05925033]], dtype=float32),\n",
       " array([[0.03369924, 0.17173487, 0.7945659 ]], dtype=float32),\n",
       " array([[0.05111441, 0.17105958, 0.777826  ]], dtype=float32),\n",
       " array([[0.8558433 , 0.12471242, 0.01944426]], dtype=float32),\n",
       " array([[0.0188299 , 0.19057746, 0.7905927 ]], dtype=float32),\n",
       " array([[0.8730729 , 0.10229592, 0.02463113]], dtype=float32),\n",
       " array([[0.00698914, 0.03981623, 0.95319456]], dtype=float32),\n",
       " array([[0.04047292, 0.19802503, 0.761502  ]], dtype=float32),\n",
       " array([[0.03174772, 0.18174131, 0.78651094]], dtype=float32),\n",
       " array([[0.04365421, 0.22789125, 0.72845453]], dtype=float32),\n",
       " array([[0.2141097 , 0.5008691 , 0.28502116]], dtype=float32),\n",
       " array([[0.0107011 , 0.07114335, 0.91815555]], dtype=float32),\n",
       " array([[0.01425073, 0.25203156, 0.73371774]], dtype=float32),\n",
       " array([[0.01783968, 0.27795112, 0.7042092 ]], dtype=float32),\n",
       " array([[0.8688958 , 0.09782891, 0.03327524]], dtype=float32),\n",
       " array([[0.02460722, 0.35659164, 0.6188011 ]], dtype=float32),\n",
       " array([[0.01106154, 0.07338125, 0.9155572 ]], dtype=float32),\n",
       " array([[0.8865636, 0.0815273, 0.0319091]], dtype=float32),\n",
       " array([[0.05509952, 0.24509606, 0.6998044 ]], dtype=float32),\n",
       " array([[0.7472575 , 0.22803226, 0.02471024]], dtype=float32),\n",
       " array([[0.65297186, 0.33371404, 0.01331411]], dtype=float32),\n",
       " array([[0.3604172 , 0.46154073, 0.17804205]], dtype=float32),\n",
       " array([[0.08062749, 0.43774515, 0.48162726]], dtype=float32),\n",
       " array([[0.01949434, 0.16628008, 0.8142256 ]], dtype=float32),\n",
       " array([[0.01395288, 0.16645542, 0.8195917 ]], dtype=float32),\n",
       " array([[0.8312366 , 0.15749821, 0.01126515]], dtype=float32),\n",
       " array([[0.7391907 , 0.22140819, 0.03940107]], dtype=float32),\n",
       " array([[0.0058757 , 0.11088411, 0.88324016]], dtype=float32),\n",
       " array([[0.8780019 , 0.07964838, 0.04234963]], dtype=float32),\n",
       " array([[0.8574142 , 0.11156393, 0.03102191]], dtype=float32),\n",
       " array([[0.26727977, 0.36628315, 0.36643705]], dtype=float32),\n",
       " array([[0.12867017, 0.572712  , 0.29861787]], dtype=float32),\n",
       " array([[0.77243495, 0.11549518, 0.11206986]], dtype=float32),\n",
       " array([[0.21605854, 0.33367833, 0.45026305]], dtype=float32),\n",
       " array([[0.01026393, 0.09399413, 0.89574194]], dtype=float32),\n",
       " array([[0.11344688, 0.6614349 , 0.22511828]], dtype=float32),\n",
       " array([[0.2538258, 0.6611553, 0.0850189]], dtype=float32),\n",
       " array([[0.04254511, 0.4299522 , 0.5275027 ]], dtype=float32),\n",
       " array([[0.5099126 , 0.3218824 , 0.16820495]], dtype=float32),\n",
       " array([[0.07417202, 0.73196435, 0.19386363]], dtype=float32),\n",
       " array([[0.4975707 , 0.41614038, 0.08628896]], dtype=float32),\n",
       " array([[0.19429867, 0.39837897, 0.40732235]], dtype=float32),\n",
       " array([[0.38280663, 0.3145293 , 0.30266404]], dtype=float32),\n",
       " array([[0.10383233, 0.25165883, 0.64450884]], dtype=float32),\n",
       " array([[0.02802369, 0.2234253 , 0.74855095]], dtype=float32),\n",
       " array([[0.00710562, 0.0930637 , 0.8998307 ]], dtype=float32),\n",
       " array([[0.01336903, 0.33441794, 0.65221304]], dtype=float32),\n",
       " array([[0.264025  , 0.38065007, 0.35532492]], dtype=float32),\n",
       " array([[0.868108  , 0.08321945, 0.04867265]], dtype=float32),\n",
       " array([[0.02243211, 0.32628018, 0.65128773]], dtype=float32),\n",
       " array([[0.01583048, 0.22402726, 0.76014227]], dtype=float32),\n",
       " array([[0.03329532, 0.62934357, 0.3373611 ]], dtype=float32),\n",
       " array([[0.3730133 , 0.26823333, 0.35875335]], dtype=float32),\n",
       " array([[0.36570558, 0.2799686 , 0.35432583]], dtype=float32),\n",
       " array([[0.01967277, 0.40749153, 0.5728357 ]], dtype=float32),\n",
       " array([[0.0926593, 0.5277644, 0.3795763]], dtype=float32),\n",
       " array([[0.00626644, 0.13964272, 0.85409087]], dtype=float32),\n",
       " array([[0.08127133, 0.72380173, 0.19492693]], dtype=float32),\n",
       " array([[0.12517771, 0.5528101 , 0.32201222]], dtype=float32),\n",
       " array([[0.01013152, 0.10186473, 0.8880037 ]], dtype=float32),\n",
       " array([[0.8296719 , 0.13107623, 0.03925186]], dtype=float32),\n",
       " array([[0.45589274, 0.3379058 , 0.2062015 ]], dtype=float32),\n",
       " array([[0.02048978, 0.37185767, 0.6076526 ]], dtype=float32),\n",
       " array([[0.7002551 , 0.2681696 , 0.03157532]], dtype=float32),\n",
       " array([[0.03473411, 0.6589094 , 0.30635655]], dtype=float32),\n",
       " array([[0.02759416, 0.15998143, 0.8124244 ]], dtype=float32),\n",
       " array([[0.01366016, 0.77947253, 0.20686729]], dtype=float32),\n",
       " array([[0.01491106, 0.12454723, 0.8605417 ]], dtype=float32),\n",
       " array([[0.00812692, 0.08765648, 0.9042166 ]], dtype=float32),\n",
       " array([[0.7543112 , 0.20710875, 0.03858008]], dtype=float32),\n",
       " array([[0.01224561, 0.13773559, 0.8500188 ]], dtype=float32),\n",
       " array([[0.02036112, 0.37324882, 0.60639   ]], dtype=float32),\n",
       " array([[0.15548187, 0.38136378, 0.4631543 ]], dtype=float32),\n",
       " array([[0.23131903, 0.13340293, 0.63527805]], dtype=float32),\n",
       " array([[0.36507356, 0.35398525, 0.2809412 ]], dtype=float32),\n",
       " array([[0.01496991, 0.3053477 , 0.6796824 ]], dtype=float32),\n",
       " array([[0.29185086, 0.29708803, 0.41106102]], dtype=float32),\n",
       " array([[0.01873852, 0.2453367 , 0.7359248 ]], dtype=float32),\n",
       " array([[0.05848473, 0.16968374, 0.7718316 ]], dtype=float32),\n",
       " array([[0.04039736, 0.2322158 , 0.7273869 ]], dtype=float32),\n",
       " array([[0.01646236, 0.1645581 , 0.81897956]], dtype=float32),\n",
       " array([[0.01284489, 0.37628818, 0.61086696]], dtype=float32),\n",
       " array([[0.03052409, 0.3477023 , 0.62177366]], dtype=float32),\n",
       " array([[0.3393547 , 0.3605376 , 0.30010766]], dtype=float32),\n",
       " array([[0.02726676, 0.10591628, 0.86681694]], dtype=float32),\n",
       " array([[0.13435169, 0.35389853, 0.5117498 ]], dtype=float32),\n",
       " array([[0.05189686, 0.13462698, 0.8134762 ]], dtype=float32),\n",
       " array([[0.02371684, 0.2627128 , 0.71357036]], dtype=float32),\n",
       " array([[0.01100837, 0.11859343, 0.8703982 ]], dtype=float32),\n",
       " array([[0.16247581, 0.27015403, 0.5673702 ]], dtype=float32),\n",
       " array([[0.02556386, 0.46626818, 0.508168  ]], dtype=float32),\n",
       " array([[0.37641272, 0.40078592, 0.22280137]], dtype=float32),\n",
       " array([[0.00500031, 0.1255149 , 0.8694847 ]], dtype=float32),\n",
       " array([[0.01118252, 0.14740047, 0.841417  ]], dtype=float32),\n",
       " array([[0.09500024, 0.17562655, 0.7293732 ]], dtype=float32),\n",
       " array([[0.05185543, 0.18561883, 0.76252574]], dtype=float32),\n",
       " array([[0.60464317, 0.3560434 , 0.03931343]], dtype=float32),\n",
       " array([[0.7709353 , 0.15684642, 0.07221831]], dtype=float32),\n",
       " array([[0.04648509, 0.61489314, 0.33862188]], dtype=float32),\n",
       " array([[0.08897487, 0.31751177, 0.5935134 ]], dtype=float32),\n",
       " array([[0.02661587, 0.13602348, 0.8373607 ]], dtype=float32),\n",
       " array([[0.00928082, 0.07090081, 0.91981846]], dtype=float32),\n",
       " array([[0.9036074 , 0.08107354, 0.01531903]], dtype=float32),\n",
       " array([[0.4286942 , 0.4289159 , 0.14238992]], dtype=float32),\n",
       " array([[0.02022666, 0.16880316, 0.8109702 ]], dtype=float32),\n",
       " array([[0.03892323, 0.40178883, 0.55928797]], dtype=float32),\n",
       " array([[0.00543386, 0.4429907 , 0.5515754 ]], dtype=float32),\n",
       " array([[0.08699249, 0.06852   , 0.84448755]], dtype=float32),\n",
       " array([[0.3405166 , 0.33007357, 0.32940984]], dtype=float32),\n",
       " array([[0.82819736, 0.1399611 , 0.0318415 ]], dtype=float32),\n",
       " array([[0.03051773, 0.22321108, 0.74627125]], dtype=float32),\n",
       " array([[0.04257657, 0.5025212 , 0.4549022 ]], dtype=float32),\n",
       " array([[0.00447356, 0.06230894, 0.93321747]], dtype=float32),\n",
       " array([[0.02960832, 0.27903003, 0.6913616 ]], dtype=float32),\n",
       " array([[0.04573428, 0.29391247, 0.6603533 ]], dtype=float32),\n",
       " array([[0.39135784, 0.3492405 , 0.25940162]], dtype=float32),\n",
       " array([[0.81762713, 0.11689819, 0.06547475]], dtype=float32),\n",
       " array([[0.06195324, 0.21809115, 0.7199557 ]], dtype=float32),\n",
       " array([[0.03187715, 0.08435353, 0.8837694 ]], dtype=float32),\n",
       " array([[0.8476525 , 0.13596714, 0.01638041]], dtype=float32),\n",
       " array([[0.19135728, 0.5090529 , 0.29958984]], dtype=float32),\n",
       " array([[0.5944011 , 0.27129868, 0.13430016]], dtype=float32),\n",
       " array([[0.02373565, 0.47208825, 0.50417614]], dtype=float32),\n",
       " array([[0.34701985, 0.3726509 , 0.28032923]], dtype=float32),\n",
       " array([[0.1615393 , 0.34143108, 0.4970296 ]], dtype=float32),\n",
       " array([[0.0335843 , 0.22033858, 0.7460772 ]], dtype=float32),\n",
       " array([[0.02331513, 0.25763327, 0.71905154]], dtype=float32),\n",
       " array([[0.09899922, 0.381422  , 0.5195788 ]], dtype=float32),\n",
       " array([[0.10455621, 0.25522166, 0.64022213]], dtype=float32),\n",
       " array([[0.01914287, 0.65371144, 0.32714573]], dtype=float32),\n",
       " array([[0.17658187, 0.18579188, 0.6376263 ]], dtype=float32),\n",
       " array([[0.02363427, 0.12594666, 0.8504191 ]], dtype=float32),\n",
       " array([[0.55427974, 0.3500753 , 0.095645  ]], dtype=float32),\n",
       " array([[0.06554308, 0.5903053 , 0.34415156]], dtype=float32),\n",
       " array([[0.27069506, 0.237305  , 0.492     ]], dtype=float32),\n",
       " array([[0.57332003, 0.14320464, 0.2834753 ]], dtype=float32),\n",
       " array([[0.79502165, 0.0921312 , 0.11284715]], dtype=float32),\n",
       " array([[0.06976433, 0.61959505, 0.3106407 ]], dtype=float32),\n",
       " array([[0.6651893 , 0.28921172, 0.04559895]], dtype=float32),\n",
       " array([[0.79546237, 0.16673405, 0.03780363]], dtype=float32),\n",
       " array([[0.03949862, 0.26459035, 0.695911  ]], dtype=float32),\n",
       " array([[0.43528703, 0.38765395, 0.17705902]], dtype=float32),\n",
       " array([[0.9121684 , 0.06540862, 0.022423  ]], dtype=float32),\n",
       " array([[0.19324093, 0.5484753 , 0.25828373]], dtype=float32),\n",
       " array([[0.21527468, 0.52562296, 0.2591024 ]], dtype=float32),\n",
       " array([[0.90401655, 0.07142306, 0.02456044]], dtype=float32),\n",
       " array([[0.18060307, 0.444901  , 0.37449598]], dtype=float32)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (163, 1, 3)\n",
      "dev shape:  (56, 1, 3)\n",
      "test shape:  (56, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "# convert to numpy arrays\n",
    "deproberta_features_train = np.array(X_train_features)\n",
    "deproberta_features_dev = np.array(X_dev_features)\n",
    "deproberta_features_test = np.array(X_test_features)\n",
    "\n",
    "print('train shape: ', np.shape(deproberta_features_train))\n",
    "print('dev shape: ', np.shape(deproberta_features_dev))\n",
    "print('test shape: ', np.shape(deproberta_features_test))\n",
    "\n",
    "# deproberta_features_train = np.concatenate((X_train_features, X_dev_features), axis=0)\n",
    "# print('train shape: ', np.shape(deproberta_features_train))\n",
    "\n",
    "# reshape the features\n",
    "deproberta_features_train = deproberta_features_train.reshape(deproberta_features_train.shape[0], deproberta_features_train.shape[2])\n",
    "deproberta_features_dev = deproberta_features_dev.reshape(deproberta_features_dev.shape[0], deproberta_features_dev.shape[2])\n",
    "deproberta_features_test = deproberta_features_test.reshape(deproberta_features_test.shape[0], deproberta_features_test.shape[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(163, 3)\n",
      "(56, 3)\n",
      "(56, 3)\n",
      "rmse for train:  5.910561780143632\n",
      "mae for train:  4.384149544556507\n",
      "rmse for dev:  5.42441007511439\n",
      "mae for dev:  4.1321841993205926\n",
      "rmse for test:  6.528515615032282\n",
      "mae for test:  5.084523139254406\n"
     ]
    }
   ],
   "source": [
    "# train a SVR model on the bert_features and PHQ_Score as the target\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X_train = np.array(deproberta_features_train)\n",
    "X_dev = np.array(deproberta_features_dev)\n",
    "X_test = np.array(deproberta_features_test)\n",
    "y_train = np.array(df_train['PHQ_Score'])\n",
    "y_dev = np.array(df_dev['PHQ_Score'])\n",
    "# y_train = np.concatenate((y_train, y_dev), axis=0)\n",
    "y_test = np.array(df_test['PHQ_Score'])\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_dev.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "# normalize X_train, X_dev and X_test\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_dev = scaler.transform(X_dev)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# train a SVR model on X_train and y_train\n",
    "# svr = SVR(kernel='rbf', C=2, gamma=0.1)\n",
    "svr = SVR(kernel='rbf', C=7, gamma='scale')\n",
    "# svr = SVR(kernel='poly', degree=3, C=0.1, gamma='scale', coef0=1)\n",
    "\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# predict on X_train and calculate the mean squared error and mean absolute error\n",
    "y_pred = svr.predict(X_train)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "print('rmse for train: ', np.sqrt(mse))\n",
    "print('mae for train: ', mae)\n",
    "\n",
    "# # print y_train together with y_pred from Train set\n",
    "# for i in range(len(y_train)):\n",
    "#     if abs(y_train[i] - y_pred[i]) > 5:\n",
    "#         print('i:', i, ' ', y_train[i], ' , ', y_pred[i])\n",
    "\n",
    "# predict on X_dev and calculate the mean squared error and mean absolute error\n",
    "y_pred = svr.predict(X_dev)\n",
    "mse = mean_squared_error(y_dev, y_pred)\n",
    "mae = mean_absolute_error(y_dev, y_pred)\n",
    "print('rmse for dev: ', np.sqrt(mse))\n",
    "print('mae for dev: ', mae)\n",
    "\n",
    "# print y_dev together with y_pred from Dev set\n",
    "# for i in range(len(y_dev)):\n",
    "#     if abs(y_dev[i] - y_pred[i]) > 5:\n",
    "#         print('i:', i, ' ', y_dev[i], ' , ', y_pred[i])\n",
    "\n",
    "# predict on X_dev and calculate the mean squared error and mean absolute error\n",
    "y_pred = svr.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('rmse for test: ', np.sqrt(mse))\n",
    "print('mae for test: ', mae)\n",
    "\n",
    "# # print y_test together with y_pred from Test set\n",
    "# for i in range(len(y_test)):\n",
    "#     if abs(y_test[i] - y_pred[i]) > 5:\n",
    "#         print('i:', i, ' ', y_test[i], ' , ', y_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                int64\n",
       "Gender           object\n",
       "PHQ_Binary        int64\n",
       "PHQ_Score         int64\n",
       "PCL-C (PTSD)      int64\n",
       "PTSD Severity     int64\n",
       "text             object\n",
       "completions      string\n",
       "dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(163, 3)\n",
      "(56, 3)\n",
      "(56, 3)\n",
      "Dev set metrics: accuracy=0.786, precision=0.000, recall=0.000, F1=0.000\n",
      "Test set metrics: accuracy=0.696, precision=0.000, recall=0.000, F1=0.000\n",
      "classification report y_dev: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88        44\n",
      "           1       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.79        56\n",
      "   macro avg       0.39      0.50      0.44        56\n",
      "weighted avg       0.62      0.79      0.69        56\n",
      "\n",
      "classification report y_test: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82        39\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.70        56\n",
      "   macro avg       0.35      0.50      0.41        56\n",
      "weighted avg       0.49      0.70      0.57        56\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/misha/My_Projects/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/misha/My_Projects/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/misha/My_Projects/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/misha/My_Projects/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/misha/My_Projects/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/misha/My_Projects/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/misha/My_Projects/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/misha/My_Projects/venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# I tried classification but results were really bad. No PHQ_Binary = 1 has been detected!\n",
    "# # train a classifier on the bert_features and PHQ Binary as the target\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# X_train = np.array(deproberta_features_train)\n",
    "# X_dev = np.array(deproberta_features_dev)\n",
    "# X_test = np.array(deproberta_features_test)\n",
    "\n",
    "# y_train = np.array(df_train['PHQ_Binary'])\n",
    "# y_dev = np.array(df_dev['PHQ_Binary'])\n",
    "# y_test = np.array(df_test['PHQ_Binary'])\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(X_dev.shape)\n",
    "# print(X_test.shape)\n",
    "\n",
    "# # normalize X_train, X_dev and X_test\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_dev = scaler.transform(X_dev)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# # train an SVM classifier\n",
    "# clf = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# # make predictions on the dev set\n",
    "# y_dev_pred = clf.predict(X_dev)\n",
    "\n",
    "# # evaluate performance on the dev set\n",
    "# accuracy = accuracy_score(y_dev, y_dev_pred)\n",
    "# precision = precision_score(y_dev, y_dev_pred, average='binary', pos_label=1)\n",
    "# recall = recall_score(y_dev, y_dev_pred, average='binary', pos_label=1)\n",
    "# f1 = f1_score(y_dev, y_dev_pred, average='binary', pos_label=1)\n",
    "# print(f'Dev set metrics: accuracy={accuracy:.3f}, precision={precision:.3f}, recall={recall:.3f}, F1={f1:.3f}')\n",
    "\n",
    "# # make predictions on the test set\n",
    "# y_test_pred = clf.predict(X_test)\n",
    "\n",
    "# # evaluate performance on the test set\n",
    "# accuracy = accuracy_score(y_test, y_test_pred)\n",
    "# precision = precision_score(y_test, y_test_pred, average='binary', pos_label=1)\n",
    "# recall = recall_score(y_test, y_test_pred, average='binary', pos_label=1)\n",
    "# f1 = f1_score(y_test, y_test_pred, average='binary', pos_label=1)\n",
    "# print(f'Test set metrics: accuracy={accuracy:.3f}, precision={precision:.3f}, recall={recall:.3f}, F1={f1:.3f}')\n",
    "\n",
    "# # print classification report\n",
    "# print('classification report y_dev: ')\n",
    "# print(classification_report(y_dev, y_dev_pred))\n",
    "\n",
    "# # print classification report\n",
    "# print('classification report y_test: ')\n",
    "# print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n",
      "56\n",
      "56\n",
      "rmse for dev:  5.582438651257683\n",
      "mae for dev:  4.440498014486063\n"
     ]
    }
   ],
   "source": [
    "# trying Bag of words (BoW) approach\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "train_text = df_train['completions'].tolist()\n",
    "dev_text = df_dev['completions'].tolist()\n",
    "test_text = df_test['completions'].tolist()\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train_text)\n",
    "\n",
    "train_bow = vectorizer.transform(train_text)\n",
    "dev_bow = vectorizer.transform(dev_text)\n",
    "test_bow = vectorizer.transform(test_text)\n",
    "\n",
    "X_train = train_bow.toarray()\n",
    "X_dev = dev_bow.toarray()\n",
    "X_test = test_bow.toarray()\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_dev))\n",
    "print(len(X_test))\n",
    "\n",
    "y_train = np.array(df_train['PHQ_Score'])\n",
    "y_dev = np.array(df_dev['PHQ_Score'])\n",
    "y_test = np.array(df_test['PHQ_Score'])\n",
    "\n",
    "svr = SVR(kernel='rbf', C=2, gamma='scale')\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the dev set\n",
    "y_pred = svr.predict(X_dev)\n",
    "mse = mean_squared_error(y_pred, y_dev)\n",
    "mae = mean_absolute_error(y_pred, y_dev)\n",
    "print('rmse for dev: ', np.sqrt(mse))\n",
    "print('mae for dev: ', mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (163, 1024)\n",
      "dev shape:  (56, 1024)\n",
      "train shape:  (219, 1024)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[149], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtrain shape: \u001b[39m\u001b[39m'\u001b[39m, np\u001b[39m.\u001b[39mshape(deproberta_features_train))\n\u001b[1;32m     14\u001b[0m \u001b[39m# reshape the features\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m deproberta_features_train \u001b[39m=\u001b[39m deproberta_features_train\u001b[39m.\u001b[39mreshape(deproberta_features_train\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], deproberta_features_train\u001b[39m.\u001b[39;49mshape[\u001b[39m2\u001b[39;49m])\n\u001b[1;32m     16\u001b[0m \u001b[39m# deproberta_features_dev = deproberta_features_dev.reshape(deproberta_features_dev.shape[0], deproberta_features_dev.shape[2])\u001b[39;00m\n\u001b[1;32m     17\u001b[0m deproberta_features_test \u001b[39m=\u001b[39m deproberta_features_test\u001b[39m.\u001b[39mreshape(deproberta_features_test\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], deproberta_features_test\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m])\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# train on train and dev\n",
    "# convert to numpy arrays\n",
    "deproberta_features_train = np.array(X_train_features)\n",
    "deproberta_features_dev = np.array(X_dev_features)\n",
    "deproberta_features_test = np.array(X_test_features)\n",
    "\n",
    "print('train shape: ', np.shape(deproberta_features_train))\n",
    "print('dev shape: ', np.shape(deproberta_features_dev))\n",
    "\n",
    "deproberta_features_train = np.concatenate((X_train_features, X_dev_features), axis=0)\n",
    "\n",
    "print('train shape: ', np.shape(deproberta_features_train))\n",
    "\n",
    "# reshape the features\n",
    "deproberta_features_train = deproberta_features_train.reshape(deproberta_features_train.shape[0], deproberta_features_train.shape[2])\n",
    "# deproberta_features_dev = deproberta_features_dev.reshape(deproberta_features_dev.shape[0], deproberta_features_dev.shape[2])\n",
    "deproberta_features_test = deproberta_features_test.reshape(deproberta_features_test.shape[0], deproberta_features_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse for train:  5.4572524976891135\n",
      "mae for train:  3.979344948542748\n",
      "rmse for test:  6.0754504853236355\n",
      "mae for test:  4.862346661752325\n"
     ]
    }
   ],
   "source": [
    "# train on train and dev\n",
    "\n",
    "# train a SVR model on the bert_features and PHQ_Score as the target\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X_train = np.array(deproberta_features_train)\n",
    "X_dev = np.array(deproberta_features_dev)\n",
    "X_test = np.array(deproberta_features_test)\n",
    "y_train = np.array(df_train['PHQ_Score'])\n",
    "y_dev = np.array(df_dev['PHQ_Score'])\n",
    "y_train = np.concatenate((y_train, y_dev), axis=0)\n",
    "y_test = np.array(df_test['PHQ_Score'])\n",
    "\n",
    "# normalize X_train, X_dev and X_test\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "# X_dev = scaler.transform(X_dev)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# train a SVR model on X_train and y_train\n",
    "# svr = SVR(kernel='rbf', C=2, gamma=0.1)\n",
    "svr = SVR(kernel='rbf', C=5, gamma=0.1)\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# predict on X_train and calculate the mean squared error and mean absolute error\n",
    "y_pred = svr.predict(X_train)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "print('rmse for train: ', np.sqrt(mse))\n",
    "print('mae for train: ', mae)\n",
    "\n",
    "# predict on X_dev and calculate the mean squared error and mean absolute error\n",
    "# y_pred = svr.predict(X_dev)\n",
    "# mse = mean_squared_error(y_dev, y_pred)\n",
    "# mae = mean_absolute_error(y_dev, y_pred)\n",
    "# print('rmse for dev: ', np.sqrt(mse))\n",
    "# print('mae for dev: ', mae)\n",
    "\n",
    "# predict on X_dev and calculate the mean squared error and mean absolute error\n",
    "\n",
    "y_pred = svr.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('rmse for test: ', np.sqrt(mse))\n",
    "print('mae for test: ', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 0.1, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "RMSE Train: 6.341812750078263\n",
      "MAE Train: 4.938036809815951\n",
      "RMSE Dev: 6.610327417868843\n",
      "MAE Dev: 5.696428571428571\n",
      "RMSE Test: 6.6453528338015495\n",
      "MAE Test: 5.803571428571429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 2, 5, 10, 20, 100],\n",
    "    'gamma': [0.01, 0.1, 1, 2, 5, 10, 100],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "# Create a support vector regression object\n",
    "svr = SVR()\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=svr, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "y_pred = grid_search.predict(X_train)\n",
    "rmse = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "print(\"RMSE Train:\", rmse)\n",
    "print(\"MAE Train:\", mae)\n",
    "\n",
    "# Make predictions on the testing set using the best model\n",
    "y_pred = grid_search.predict(X_dev)\n",
    "# Calculate the root mean squared error and mean absolute error\n",
    "rmse = np.sqrt(mean_squared_error(y_dev, y_pred))\n",
    "mae = mean_absolute_error(y_dev, y_pred)\n",
    "print(\"RMSE Dev:\", rmse)\n",
    "print(\"MAE Dev:\", mae)\n",
    "\n",
    "# Make predictions on the testing set using the best model\n",
    "y_pred = grid_search.predict(X_test)\n",
    "# Calculate the root mean squared error and mean absolute error\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"RMSE Test:\", rmse)\n",
    "print(\"MAE Test:\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "36128b57eae0070e60f84ea73862771965c49f1143c114c27871bafb518edfa1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
