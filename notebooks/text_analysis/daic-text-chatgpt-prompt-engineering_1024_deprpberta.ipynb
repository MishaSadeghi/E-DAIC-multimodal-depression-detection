{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = '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' # for my personal account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
      "/var/folders/p4/x9h3xj457tb303r8d777sm7r0000gn/T/ipykernel_2540/119909400.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>PHQ_Binary</th>\n",
       "      <th>PHQ_Score</th>\n",
       "      <th>PCL-C (PTSD)</th>\n",
       "      <th>PTSD Severity</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>which will record your body. So I'll show you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>Yeah, there's all sorts of different studies ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>306</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>Okay, looks like we're good. But let's move a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>317</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>Okay. How long is this? This is probably goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>320</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>Okay, everything looks good. Okay. Perfect. O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  Gender  PHQ_Binary  PHQ_Score  PCL-C (PTSD)  PTSD Severity  \\\n",
       "0  300    male           0          2             0             25   \n",
       "1  301    male           0          3             0             17   \n",
       "2  306  female           0          0             0             21   \n",
       "3  317    male           0          8             1             51   \n",
       "4  320  female           0         11             1             64   \n",
       "\n",
       "                                                text  \n",
       "0   which will record your body. So I'll show you...  \n",
       "1   Yeah, there's all sorts of different studies ...  \n",
       "2   Okay, looks like we're good. But let's move a...  \n",
       "3   Okay. How long is this? This is probably goin...  \n",
       "4   Okay, everything looks good. Okay. Perfect. O...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "directory_path = '../data/transcripts_from_whisper/'\n",
    "\n",
    "transcripts_df = pd.DataFrame(columns=[\"id\", \"text\"])\n",
    "\n",
    "# extract ids from filenames and text from files\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_id = filename[:3]\n",
    "        with open(os.path.join(directory_path, filename), \"r\") as file:\n",
    "            file_contents = file.read()\n",
    "        transcripts_df = transcripts_df.append({\"id\": file_id, \"text\": file_contents}, ignore_index=True)\n",
    "\n",
    "transcripts_df[\"id\"] = transcripts_df[\"id\"].astype(\"int64\")\n",
    "\n",
    "labels_dev_df = pd.read_csv('../data/labels/dev_split.csv')\n",
    "labels_dev_df.columns = ['id', 'Gender', 'PHQ_Binary', 'PHQ_Score', 'PCL-C (PTSD)', 'PTSD Severity']\n",
    "\n",
    "labels_train_df = pd.read_csv('../data/labels/train_split.csv')\n",
    "labels_train_df.columns = ['id', 'Gender', 'PHQ_Binary', 'PHQ_Score', 'PCL-C (PTSD)', 'PTSD Severity']\n",
    "\n",
    "labels_test_df = pd.read_csv('../data/labels/test_split.csv')\n",
    "labels_test_df.columns = ['id', 'Gender', 'PHQ_Binary', 'PHQ_Score', 'PCL-C (PTSD)', 'PTSD Severity']\n",
    "\n",
    "# merge dataframes on id\n",
    "df_dev = pd.merge(labels_dev_df, transcripts_df, on='id')\n",
    "df_train = pd.merge(labels_train_df, transcripts_df, on='id')\n",
    "df_test = pd.merge(labels_test_df, transcripts_df, on='id')\n",
    "\n",
    "df_dev = df_dev.sort_values(by=\"id\")\n",
    "df_train = df_train.sort_values(by=\"id\")\n",
    "df_test = df_test.sort_values(by=\"id\")\n",
    "\n",
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 163 entries, 0 to 162\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   id             163 non-null    int64 \n",
      " 1   Gender         163 non-null    object\n",
      " 2   PHQ_Binary     163 non-null    int64 \n",
      " 3   PHQ_Score      163 non-null    int64 \n",
      " 4   PCL-C (PTSD)   163 non-null    int64 \n",
      " 5   PTSD Severity  163 non-null    int64 \n",
      " 6   text           163 non-null    object\n",
      "dtypes: int64(5), object(2)\n",
      "memory usage: 10.2+ KB\n",
      "None\n",
      "id                 int64\n",
      "Gender            object\n",
      "PHQ_Binary         int64\n",
      "PHQ_Score          int64\n",
      "PCL-C (PTSD)       int64\n",
      "PTSD Severity    float64\n",
      "text              object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_train.info())\n",
    "print(df_test.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df_train['PHQ_Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# transcripts_df = pd.read_csv('../data/transcripts.csv')\n",
    "# # remove first column\n",
    "# transcripts_df = transcripts_df.iloc[:,1:]\n",
    "# transcripts_df.columns = ['id', 'text']\n",
    "\n",
    "# labels_dev_df = pd.read_csv('../data/labels/dev_split.csv')\n",
    "# labels_dev_df.columns = ['id', 'Gender', 'PHQ_Binary', 'PHQ_Score', 'PCL-C (PTSD)', 'PTSD Severity']\n",
    "\n",
    "# labels_train_df = pd.read_csv('../data/labels/train_split.csv')\n",
    "# labels_train_df.columns = ['id', 'Gender', 'PHQ_Binary', 'PHQ_Score', 'PCL-C (PTSD)', 'PTSD Severity']\n",
    "\n",
    "# labels_test_df = pd.read_csv('../data/labels/test_split.csv')\n",
    "# labels_test_df.columns = ['id', 'Gender', 'PHQ_Binary', 'PHQ_Score', 'PCL-C (PTSD)', 'PTSD Severity']\n",
    "\n",
    "# # merge dataframes on id\n",
    "# df_dev = pd.merge(labels_dev_df, transcripts_df, on='id')\n",
    "# df_train = pd.merge(labels_train_df, transcripts_df, on='id')\n",
    "# df_test = pd.merge(labels_test_df, transcripts_df, on='id')\n",
    "\n",
    "# df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem import PorterStemmer\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# def clean_text(text):\n",
    "#     # remove punctuation and special characters\n",
    "#     text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "#     # lowercase all words\n",
    "#     text = text.lower()\n",
    "\n",
    "#     # remove stop words\n",
    "#     stop_words = set(stopwords.words('english'))\n",
    "#     text = [word for word in text.split() if word not in stop_words]\n",
    "\n",
    "#     # stem/lemmatize words\n",
    "#     # stemmer = PorterStemmer()\n",
    "#     # text = [stemmer.stem(word) for word in text]\n",
    "\n",
    "#     # remove numbers\n",
    "#     # text = [word for word in text if not word.isdigit()]\n",
    "\n",
    "#     return \" \".join(text)\n",
    "\n",
    "# # clean all transcripts\n",
    "# df_dev['text'] = df_dev['text'].apply(clean_text)\n",
    "# df_train['text'] = df_train['text'].apply(clean_text)\n",
    "# df_test['text'] = df_test['text'].apply(clean_text)\n",
    "\n",
    "# df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Your task is to read the following text which is an interview with a person and to summarize the key points that might be related to the depression of the person. Be concise and to the point. It is very essential that you write your answer in the first-person perspective, as if the interviewee is narrating about himself or herself. '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !!!!! this is the prompt that we will use for Chat-GPT API !!!!!\n",
    "# prompt = \"\"\" Here is an interview with a person who might have depression. Determine if the text might be relevant to depression. Explain your answer in a verbose manner.  \"\"\"\n",
    "# prompt = \"\"\"  I am sending a text from an interview with a person. Can you tell me  features that can be clues for depression in the text? Additionally, mention the positive aspects in the person's interview if there is any. Please don't present features in a numbered list and explain your answer in a verbose and detail manner. Here is the text: \"\"\"\n",
    "# prompt = \"\"\"  I am sending a text from an interview with a person. Can you tell me features that are clues for depression detection in the text? Here is the text: \"\"\"\n",
    "# prompt = \"\"\" I am sending a transcript of an interview with a person. What are the key linguistic features that are indicative of depression in written text? Avoid being overly pessimistic and solely focusing on negative features. Be sure to include positive attributes and responses of the person as well. Be concise and to the point. Here is the text: \"\"\"\n",
    "prompt1 = \"\"\" Your task is to read the following text which is an interview with a person and to summarize the key points that might be related to the depression of the person. Please be concise and to the point.\"\"\"\n",
    "# prompt 1 results:\n",
    "# rmse for train:  5.639914434096471\n",
    "# mae for train:  4.253329681080664\n",
    "# rmse for dev:  5.315697780631046\n",
    "# mae for dev:  3.9190065015199598\n",
    "# rmse for test:  5.872976836334969\n",
    "# mae for test:  4.730438183491851\n",
    "# prompt2 = \"\"\" Your task is to read the following text which is an interview with a person and to give a number from 0 to 100 that how likely is that this person has depression. \n",
    "# Only give a number and do not explain your answer. \"\"\"\n",
    "\n",
    "prompt3 = \"\"\" Your task is to read the following text which is an interview with a person and to summarize the key points that might be related to the depression of the person. Be concise and to the point. It is very essential that you write your answer in the first-person perspective, as if the interviewee is narrating about himself or herself. \"\"\"\n",
    "prompt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1142 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated cost: $1.362406\n"
     ]
    }
   ],
   "source": [
    "# GPT-3 cost estimator for all completions\n",
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "\n",
    "token_counts = []\n",
    "# for all tokens in all transcripts in dev, train, and test sets\n",
    "for text in df_dev['text'].tolist() + df_train['text'].tolist() + df_test['text'].tolist():\n",
    "    # tokenize text\n",
    "    tokens = tokenizer.encode(text)\n",
    "    # tokenize prompt\n",
    "    prompt_tokens = tokenizer.encode(prompt3)\n",
    "\n",
    "    # append token count to list\n",
    "    token_counts.append(len(tokens) + len(prompt_tokens) + 512)\n",
    "\n",
    "# Final cost estimataion\n",
    "print(f'Estimated cost: ${(sum(token_counts) / 1000 * 0.002)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def make_prompt(prompt, text):\n",
    "    return \"\"\"{}\\nHere is the interview between triple backticks:\\n```{}```\"\"\".format(prompt, text)\n",
    "\n",
    "# extract ChatGPT completions for each transcript\n",
    "def get_completions(prompt, text):\n",
    "    prompt = make_prompt(prompt, text)\n",
    "    # send request to API\n",
    "    response = requests.post(\n",
    "        \"http://localhost:4100/parallel-requests\",\n",
    "        json={\"prompts\": prompt}\n",
    "    )\n",
    "    # get response\n",
    "    response = response.json()\n",
    "    return response[\"response\"]\n",
    "\n",
    "def get_completions_batch(prompt, texts):\n",
    "    prompts = [make_prompt(prompt, text) for text in texts]\n",
    "    prompts = \"---\".join(prompts)\n",
    "\n",
    "    # send request to API\n",
    "    response = requests.post(\n",
    "        \"http://localhost:4100/parallel-requests\",\n",
    "        json={\"prompts\": prompts}\n",
    "    )\n",
    "\n",
    "    # get response\n",
    "    response = response.json()\n",
    "    return response[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the result\n",
    "# get completion for the first transcript in the dev set\n",
    "l = [300, 301, 306, 317, 320, 321, 331, 334, 336, 343, 344]\n",
    "for id in l:\n",
    "    print('id: ', id)\n",
    "    # id = 368\n",
    "    # find dv_dev row with id\n",
    "    row = df_dev[df_dev['id'] == id]\n",
    "    # get the value of the text column\n",
    "    text = row['text'].values[0]\n",
    "    # print('This is the text:')\n",
    "    # print(make_prompt(prompt3, text))\n",
    "    print('------------------------------------')\n",
    "    print('This is the completion:')\n",
    "    completions = get_completions(prompt3, text)\n",
    "    print(completions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we're sure that the prompt and completion are working as expected\n",
    "# Let's extract completions for all transcripts in the train, dev, and test sets\n",
    "# we will do this in batches of 10 to prevent API rate limits\n",
    "\n",
    "# get complettions in parallel in batches of 10\n",
    "df_dev['completions'] = ''\n",
    "for i in range(0, len(df_dev), 5):\n",
    "    print(f'Getting completions for dev transcripts {i} to {i+5}...')\n",
    "    # create a new column for completions\n",
    "    completions = get_completions_batch(prompt3, df_dev['text'][i:i+5])\n",
    "    # convert list of completions to dataframe\n",
    "    df_completions = pd.DataFrame(completions, columns=['completions'])\n",
    "    # add completions to df_dev\n",
    "    df_dev['completions'][i:i+5] = df_completions['completions']\n",
    "\n",
    "df_train['completions'] = ''\n",
    "for i in range(0, len(df_train), 5):\n",
    "    print(f'Getting completions for train transcripts {i} to {i+5}...')\n",
    "    # create a new column for completions\n",
    "    completions = get_completions_batch(prompt3, df_train['text'][i:i+5])\n",
    "    # convert list of completions to dataframe\n",
    "    df_completions = pd.DataFrame(completions, columns=['completions'])\n",
    "    # add completions to df_dev\n",
    "    df_train['completions'][i:i+5] = df_completions['completions']\n",
    "\n",
    "\n",
    "df_test['completions'] = ''\n",
    "for i in range(0, len(df_test), 5):\n",
    "    print(f'Getting completions for test transcripts {i} to {i+5}...')\n",
    "    # create a new column for completions\n",
    "    completions = get_completions_batch(prompt3, df_test['text'][i:i+5])\n",
    "    # convert list of completions to dataframe\n",
    "    df_completions = pd.DataFrame(completions, columns=['completions'])\n",
    "    # add completions to df_dev\n",
    "    df_test['completions'][i:i+5] = df_completions['completions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'completions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/My_Projects/venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/My_Projects/venv/lib/python3.9/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/My_Projects/venv/lib/python3.9/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'completions'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# find the empty strings in the 'completions' column\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m empty_strings_train \u001b[39m=\u001b[39m df_train\u001b[39m.\u001b[39mloc[df_train[\u001b[39m'\u001b[39;49m\u001b[39mcompletions\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mlen() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m empty_strings_dev \u001b[39m=\u001b[39m df_dev\u001b[39m.\u001b[39mloc[df_dev[\u001b[39m'\u001b[39m\u001b[39mcompletions\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mlen() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m empty_strings_test \u001b[39m=\u001b[39m df_test\u001b[39m.\u001b[39mloc[df_test[\u001b[39m'\u001b[39m\u001b[39mcompletions\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mlen() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/My_Projects/venv/lib/python3.9/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/My_Projects/venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'completions'"
     ]
    }
   ],
   "source": [
    "# find the empty strings in the 'completions' column\n",
    "empty_strings_train = df_train.loc[df_train['completions'].str.len() == 0]\n",
    "empty_strings_dev = df_dev.loc[df_dev['completions'].str.len() == 0]\n",
    "empty_strings_test = df_test.loc[df_test['completions'].str.len() == 0]\n",
    "\n",
    "# print the results\n",
    "print('empty_strings_train: ', empty_strings_train)\n",
    "print('empty_strings_dev: ', empty_strings_dev)\n",
    "print('empty_strings_test: ', empty_strings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>PHQ_Binary</th>\n",
       "      <th>PHQ_Score</th>\n",
       "      <th>PCL-C (PTSD)</th>\n",
       "      <th>PTSD Severity</th>\n",
       "      <th>text</th>\n",
       "      <th>completions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, Gender, PHQ_Binary, PHQ_Score, PCL-C (PTSD), PTSD Severity, text, completions]\n",
       "Index: []"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nan_rows = df_dev[df_dev['completions'].isnull()]\n",
    "# nan_rows   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.to_csv('df_train_prompt_3_firstperson.csv', index=False)\n",
    "# df_dev.to_csv('df_dev_prompt_3_firstperson.csv', index=False)\n",
    "# df_test.to_csv('df_test_prompt_3_firstperson.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "This is the completion:\n",
      "['The interviewee has been diagnosed with PTSD, which was caused by being pushed off a tower during airborne training in the military. They have trouble sleeping and wake up jolted from sleep due to mistrust. They go to therapy to help cope with their trauma but still struggle with social problems and trouble at work. They enjoy antique shopping and are trying to move forward in life.']\n"
     ]
    }
   ],
   "source": [
    "# get completiones for the empty ones (prompt too longs ones) \n",
    "# and write it manually in the CSV files as theye are not so many\n",
    "# it's done for prompt_3_firstperson\n",
    "id = 689\n",
    "# find df row with id\n",
    "row = df_test[df_test['id'] == id]\n",
    "# get the value of the text column\n",
    "text = row['text'].values[0]\n",
    "# print('This is the text:')\n",
    "# print(make_prompt(prompt3, text))\n",
    "print('------------------------------------')\n",
    "print('This is the completion:')\n",
    "completions = get_completions(prompt3, text)\n",
    "print(completions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id, Gender, PHQ_Binary, PHQ_Score, PCL-C (PTSD), PTSD Severity, text, completions]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# df1 = pd.read_csv('df_train_prompt_3_firstperson.csv')\n",
    "# df2 = pd.read_csv('df_dev_prompt_3_firstperson.csv')\n",
    "# df3 = pd.read_csv('df_test_prompt_3_firstperson.csv')\n",
    "# df3.head()\n",
    "\n",
    "# print(df1.loc[df1['completions'].str.len() == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>PHQ_Binary</th>\n",
       "      <th>PHQ_Score</th>\n",
       "      <th>PCL-C (PTSD)</th>\n",
       "      <th>PTSD Severity</th>\n",
       "      <th>text</th>\n",
       "      <th>completions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Alright, there you are. Perfect. So you're go...</td>\n",
       "      <td>I was diagnosed with depression in 2002 after ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>602</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>This is super neat. I like this. Me either at...</td>\n",
       "      <td>I have been diagnosed with PTSD almost two yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>604</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>So if you could just say 1, 2, 3, 4, 5. 1, 2,...</td>\n",
       "      <td>I have not been diagnosed with depression, but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>605</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>I'm going to bring up our virtual human for a...</td>\n",
       "      <td>I was interviewed by a virtual human where I r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>606</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Okay, I just got it. I just got it new. So, o...</td>\n",
       "      <td>The interviewee seems to have a negative attit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  Gender  PHQ_Binary  PHQ_Score  PCL-C (PTSD)  PTSD Severity  \\\n",
       "0  600  female           0          5             0           23.0   \n",
       "1  602  female           1         13             1           67.0   \n",
       "2  604    male           1         12             0           30.0   \n",
       "3  605    male           0          2             0           23.0   \n",
       "4  606  female           0          5             0           46.0   \n",
       "\n",
       "                                                text  \\\n",
       "0   Alright, there you are. Perfect. So you're go...   \n",
       "1   This is super neat. I like this. Me either at...   \n",
       "2   So if you could just say 1, 2, 3, 4, 5. 1, 2,...   \n",
       "3   I'm going to bring up our virtual human for a...   \n",
       "4   Okay, I just got it. I just got it new. So, o...   \n",
       "\n",
       "                                         completions  \n",
       "0  I was diagnosed with depression in 2002 after ...  \n",
       "1  I have been diagnosed with PTSD almost two yea...  \n",
       "2  I have not been diagnosed with depression, but...  \n",
       "3  I was interviewed by a virtual human where I r...  \n",
       "4  The interviewee seems to have a negative attit...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('df_train_prompt_3_firstperson.csv')\n",
    "df_dev = pd.read_csv('df_dev_prompt_3_firstperson.csv')\n",
    "df_test = pd.read_csv('df_test_prompt_3_firstperson.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['completions'] = df_train['completions'].astype('string')\n",
    "df_dev['completions'] = df_dev['completions'].astype('string')\n",
    "df_test['completions'] = df_test['completions'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id, Gender, PHQ_Binary, PHQ_Score, PCL-C (PTSD), PTSD Severity, text, completions]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(df_test.loc[df_test['completions'].str.len() == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>PHQ_Binary</th>\n",
       "      <th>PHQ_Score</th>\n",
       "      <th>PCL-C (PTSD)</th>\n",
       "      <th>PTSD Severity</th>\n",
       "      <th>text</th>\n",
       "      <th>completions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>which will record your body. So I'll show you...</td>\n",
       "      <td>I have not found any key points related to dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>Yeah, there's all sorts of different studies ...</td>\n",
       "      <td>I work as an administrative assistant through ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>306</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>Okay, looks like we're good. But let's move a...</td>\n",
       "      <td>I had an interview with a computer program des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>317</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>Okay. How long is this? This is probably goin...</td>\n",
       "      <td>I moved from New York to start over, and it wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>320</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>Okay, everything looks good. Okay. Perfect. O...</td>\n",
       "      <td>I was interviewed by a virtual human who asked...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  Gender  PHQ_Binary  PHQ_Score  PCL-C (PTSD)  PTSD Severity  \\\n",
       "0  300    male           0          2             0             25   \n",
       "1  301    male           0          3             0             17   \n",
       "2  306  female           0          0             0             21   \n",
       "3  317    male           0          8             1             51   \n",
       "4  320  female           0         11             1             64   \n",
       "\n",
       "                                                text  \\\n",
       "0   which will record your body. So I'll show you...   \n",
       "1   Yeah, there's all sorts of different studies ...   \n",
       "2   Okay, looks like we're good. But let's move a...   \n",
       "3   Okay. How long is this? This is probably goin...   \n",
       "4   Okay, everything looks good. Okay. Perfect. O...   \n",
       "\n",
       "                                         completions  \n",
       "0  I have not found any key points related to dep...  \n",
       "1  I work as an administrative assistant through ...  \n",
       "2  I had an interview with a computer program des...  \n",
       "3  I moved from New York to start over, and it wa...  \n",
       "4  I was interviewed by a virtual human who asked...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# non_nan_df_train = df_train.dropna()\n",
    "# non_nan_df_dev = df_dev.dropna()\n",
    "# non_nan_df_test = df_test.dropna()\n",
    "\n",
    "# non_nan_df_train = non_nan_df_train.reset_index(drop=True)\n",
    "# non_nan_df_dev = non_nan_df_dev.reset_index(drop=True)\n",
    "# non_nan_df_test = non_nan_df_test.reset_index(drop=True)\n",
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print layer names\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "output_dir = \"../model/\"\n",
    "model_name = 'best_deproberta_finetuned_train_3rd_phq_range_12_ep_lr_5e-6'\n",
    "\n",
    "# Load the saved model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(output_dir + '/' + model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n",
      "56\n",
      "56\n",
      "i train:  0\n",
      "torch.Size([1024])\n",
      "i train:  1\n",
      "torch.Size([1024])\n",
      "i train:  2\n",
      "torch.Size([1024])\n",
      "i train:  3\n",
      "torch.Size([1024])\n",
      "i train:  4\n",
      "torch.Size([1024])\n",
      "i train:  5\n",
      "torch.Size([1024])\n",
      "i train:  6\n",
      "torch.Size([1024])\n",
      "i train:  7\n",
      "torch.Size([1024])\n",
      "i train:  8\n",
      "torch.Size([1024])\n",
      "i train:  9\n",
      "torch.Size([1024])\n",
      "i train:  10\n",
      "torch.Size([1024])\n",
      "i train:  11\n",
      "torch.Size([1024])\n",
      "i train:  12\n",
      "torch.Size([1024])\n",
      "i train:  13\n",
      "torch.Size([1024])\n",
      "i train:  14\n",
      "torch.Size([1024])\n",
      "i train:  15\n",
      "torch.Size([1024])\n",
      "i train:  16\n",
      "torch.Size([1024])\n",
      "i train:  17\n",
      "torch.Size([1024])\n",
      "i train:  18\n",
      "torch.Size([1024])\n",
      "i train:  19\n",
      "torch.Size([1024])\n",
      "i train:  20\n",
      "torch.Size([1024])\n",
      "i train:  21\n",
      "torch.Size([1024])\n",
      "i train:  22\n",
      "torch.Size([1024])\n",
      "i train:  23\n",
      "torch.Size([1024])\n",
      "i train:  24\n",
      "torch.Size([1024])\n",
      "i train:  25\n",
      "torch.Size([1024])\n",
      "i train:  26\n",
      "torch.Size([1024])\n",
      "i train:  27\n",
      "torch.Size([1024])\n",
      "i train:  28\n",
      "torch.Size([1024])\n",
      "i train:  29\n",
      "torch.Size([1024])\n",
      "i train:  30\n",
      "torch.Size([1024])\n",
      "i train:  31\n",
      "torch.Size([1024])\n",
      "i train:  32\n",
      "torch.Size([1024])\n",
      "i train:  33\n",
      "torch.Size([1024])\n",
      "i train:  34\n",
      "torch.Size([1024])\n",
      "i train:  35\n",
      "torch.Size([1024])\n",
      "i train:  36\n",
      "torch.Size([1024])\n",
      "i train:  37\n",
      "torch.Size([1024])\n",
      "i train:  38\n",
      "torch.Size([1024])\n",
      "i train:  39\n",
      "torch.Size([1024])\n",
      "i train:  40\n",
      "torch.Size([1024])\n",
      "i train:  41\n",
      "torch.Size([1024])\n",
      "i train:  42\n",
      "torch.Size([1024])\n",
      "i train:  43\n",
      "torch.Size([1024])\n",
      "i train:  44\n",
      "torch.Size([1024])\n",
      "i train:  45\n",
      "torch.Size([1024])\n",
      "i train:  46\n",
      "torch.Size([1024])\n",
      "i train:  47\n",
      "torch.Size([1024])\n",
      "i train:  48\n",
      "torch.Size([1024])\n",
      "i train:  49\n",
      "torch.Size([1024])\n",
      "i train:  50\n",
      "torch.Size([1024])\n",
      "i train:  51\n",
      "torch.Size([1024])\n",
      "i train:  52\n",
      "torch.Size([1024])\n",
      "i train:  53\n",
      "torch.Size([1024])\n",
      "i train:  54\n",
      "torch.Size([1024])\n",
      "i train:  55\n",
      "torch.Size([1024])\n",
      "i train:  56\n",
      "torch.Size([1024])\n",
      "i train:  57\n",
      "torch.Size([1024])\n",
      "i train:  58\n",
      "torch.Size([1024])\n",
      "i train:  59\n",
      "torch.Size([1024])\n",
      "i train:  60\n",
      "torch.Size([1024])\n",
      "i train:  61\n",
      "torch.Size([1024])\n",
      "i train:  62\n",
      "torch.Size([1024])\n",
      "i train:  63\n",
      "torch.Size([1024])\n",
      "i train:  64\n",
      "torch.Size([1024])\n",
      "i train:  65\n",
      "torch.Size([1024])\n",
      "i train:  66\n",
      "torch.Size([1024])\n",
      "i train:  67\n",
      "torch.Size([1024])\n",
      "i train:  68\n",
      "torch.Size([1024])\n",
      "i train:  69\n",
      "torch.Size([1024])\n",
      "i train:  70\n",
      "torch.Size([1024])\n",
      "i train:  71\n",
      "torch.Size([1024])\n",
      "i train:  72\n",
      "torch.Size([1024])\n",
      "i train:  73\n",
      "torch.Size([1024])\n",
      "i train:  74\n",
      "torch.Size([1024])\n",
      "i train:  75\n",
      "torch.Size([1024])\n",
      "i train:  76\n",
      "torch.Size([1024])\n",
      "i train:  77\n",
      "torch.Size([1024])\n",
      "i train:  78\n",
      "torch.Size([1024])\n",
      "i train:  79\n",
      "torch.Size([1024])\n",
      "i train:  80\n",
      "torch.Size([1024])\n",
      "i train:  81\n",
      "torch.Size([1024])\n",
      "i train:  82\n",
      "torch.Size([1024])\n",
      "i train:  83\n",
      "torch.Size([1024])\n",
      "i train:  84\n",
      "torch.Size([1024])\n",
      "i train:  85\n",
      "torch.Size([1024])\n",
      "i train:  86\n",
      "torch.Size([1024])\n",
      "i train:  87\n",
      "torch.Size([1024])\n",
      "i train:  88\n",
      "torch.Size([1024])\n",
      "i train:  89\n",
      "torch.Size([1024])\n",
      "i train:  90\n",
      "torch.Size([1024])\n",
      "i train:  91\n",
      "torch.Size([1024])\n",
      "i train:  92\n",
      "torch.Size([1024])\n",
      "i train:  93\n",
      "torch.Size([1024])\n",
      "i train:  94\n",
      "torch.Size([1024])\n",
      "i train:  95\n",
      "torch.Size([1024])\n",
      "i train:  96\n",
      "torch.Size([1024])\n",
      "i train:  97\n",
      "torch.Size([1024])\n",
      "i train:  98\n",
      "torch.Size([1024])\n",
      "i train:  99\n",
      "torch.Size([1024])\n",
      "i train:  100\n",
      "torch.Size([1024])\n",
      "i train:  101\n",
      "torch.Size([1024])\n",
      "i train:  102\n",
      "torch.Size([1024])\n",
      "i train:  103\n",
      "torch.Size([1024])\n",
      "i train:  104\n",
      "torch.Size([1024])\n",
      "i train:  105\n",
      "torch.Size([1024])\n",
      "i train:  106\n",
      "torch.Size([1024])\n",
      "i train:  107\n",
      "torch.Size([1024])\n",
      "i train:  108\n",
      "torch.Size([1024])\n",
      "i train:  109\n",
      "torch.Size([1024])\n",
      "i train:  110\n",
      "torch.Size([1024])\n",
      "i train:  111\n",
      "torch.Size([1024])\n",
      "i train:  112\n",
      "torch.Size([1024])\n",
      "i train:  113\n",
      "torch.Size([1024])\n",
      "i train:  114\n",
      "torch.Size([1024])\n",
      "i train:  115\n",
      "torch.Size([1024])\n",
      "i train:  116\n",
      "torch.Size([1024])\n",
      "i train:  117\n",
      "torch.Size([1024])\n",
      "i train:  118\n",
      "torch.Size([1024])\n",
      "i train:  119\n",
      "torch.Size([1024])\n",
      "i train:  120\n",
      "torch.Size([1024])\n",
      "i train:  121\n",
      "torch.Size([1024])\n",
      "i train:  122\n",
      "torch.Size([1024])\n",
      "i train:  123\n",
      "torch.Size([1024])\n",
      "i train:  124\n",
      "torch.Size([1024])\n",
      "i train:  125\n",
      "torch.Size([1024])\n",
      "i train:  126\n",
      "torch.Size([1024])\n",
      "i train:  127\n",
      "torch.Size([1024])\n",
      "i train:  128\n",
      "torch.Size([1024])\n",
      "i train:  129\n",
      "torch.Size([1024])\n",
      "i train:  130\n",
      "torch.Size([1024])\n",
      "i train:  131\n",
      "torch.Size([1024])\n",
      "i train:  132\n",
      "torch.Size([1024])\n",
      "i train:  133\n",
      "torch.Size([1024])\n",
      "i train:  134\n",
      "torch.Size([1024])\n",
      "i train:  135\n",
      "torch.Size([1024])\n",
      "i train:  136\n",
      "torch.Size([1024])\n",
      "i train:  137\n",
      "torch.Size([1024])\n",
      "i train:  138\n",
      "torch.Size([1024])\n",
      "i train:  139\n",
      "torch.Size([1024])\n",
      "i train:  140\n",
      "torch.Size([1024])\n",
      "i train:  141\n",
      "torch.Size([1024])\n",
      "i train:  142\n",
      "torch.Size([1024])\n",
      "i train:  143\n",
      "torch.Size([1024])\n",
      "i train:  144\n",
      "torch.Size([1024])\n",
      "i train:  145\n",
      "torch.Size([1024])\n",
      "i train:  146\n",
      "torch.Size([1024])\n",
      "i train:  147\n",
      "torch.Size([1024])\n",
      "i train:  148\n",
      "torch.Size([1024])\n",
      "i train:  149\n",
      "torch.Size([1024])\n",
      "i train:  150\n",
      "torch.Size([1024])\n",
      "i train:  151\n",
      "torch.Size([1024])\n",
      "i train:  152\n",
      "torch.Size([1024])\n",
      "i train:  153\n",
      "torch.Size([1024])\n",
      "i train:  154\n",
      "torch.Size([1024])\n",
      "i train:  155\n",
      "torch.Size([1024])\n",
      "i train:  156\n",
      "torch.Size([1024])\n",
      "i train:  157\n",
      "torch.Size([1024])\n",
      "i train:  158\n",
      "torch.Size([1024])\n",
      "i train:  159\n",
      "torch.Size([1024])\n",
      "i train:  160\n",
      "torch.Size([1024])\n",
      "i train:  161\n",
      "torch.Size([1024])\n",
      "i train:  162\n",
      "torch.Size([1024])\n",
      "i dev:  0\n",
      "i dev:  1\n",
      "i dev:  2\n",
      "i dev:  3\n",
      "i dev:  4\n",
      "i dev:  5\n",
      "i dev:  6\n",
      "i dev:  7\n",
      "i dev:  8\n",
      "i dev:  9\n",
      "i dev:  10\n",
      "i dev:  11\n",
      "i dev:  12\n",
      "i dev:  13\n",
      "i dev:  14\n",
      "i dev:  15\n",
      "i dev:  16\n",
      "i dev:  17\n",
      "i dev:  18\n",
      "i dev:  19\n",
      "i dev:  20\n",
      "i dev:  21\n",
      "i dev:  22\n",
      "i dev:  23\n",
      "i dev:  24\n",
      "i dev:  25\n",
      "i dev:  26\n",
      "i dev:  27\n",
      "i dev:  28\n",
      "i dev:  29\n",
      "i dev:  30\n",
      "i dev:  31\n",
      "i dev:  32\n",
      "i dev:  33\n",
      "i dev:  34\n",
      "i dev:  35\n",
      "i dev:  36\n",
      "i dev:  37\n",
      "i dev:  38\n",
      "i dev:  39\n",
      "i dev:  40\n",
      "i dev:  41\n",
      "i dev:  42\n",
      "i dev:  43\n",
      "i dev:  44\n",
      "i dev:  45\n",
      "i dev:  46\n",
      "i dev:  47\n",
      "i dev:  48\n",
      "i dev:  49\n",
      "i dev:  50\n",
      "i dev:  51\n",
      "i dev:  52\n",
      "i dev:  53\n",
      "i dev:  54\n",
      "i dev:  55\n",
      "i test:  0\n",
      "i test:  1\n",
      "i test:  2\n",
      "i test:  3\n",
      "i test:  4\n",
      "i test:  5\n",
      "i test:  6\n",
      "i test:  7\n",
      "i test:  8\n",
      "i test:  9\n",
      "i test:  10\n",
      "i test:  11\n",
      "i test:  12\n",
      "i test:  13\n",
      "i test:  14\n",
      "i test:  15\n",
      "i test:  16\n",
      "i test:  17\n",
      "i test:  18\n",
      "i test:  19\n",
      "i test:  20\n",
      "i test:  21\n",
      "i test:  22\n",
      "i test:  23\n",
      "i test:  24\n",
      "i test:  25\n",
      "i test:  26\n",
      "i test:  27\n",
      "i test:  28\n",
      "i test:  29\n",
      "i test:  30\n",
      "i test:  31\n",
      "i test:  32\n",
      "i test:  33\n",
      "i test:  34\n",
      "i test:  35\n",
      "i test:  36\n",
      "i test:  37\n",
      "i test:  38\n",
      "i test:  39\n",
      "i test:  40\n",
      "i test:  41\n",
      "i test:  42\n",
      "i test:  43\n",
      "i test:  44\n",
      "i test:  45\n",
      "i test:  46\n",
      "i test:  47\n",
      "i test:  48\n",
      "i test:  49\n",
      "i test:  50\n",
      "i test:  51\n",
      "i test:  52\n",
      "i test:  53\n",
      "i test:  54\n",
      "i test:  55\n"
     ]
    }
   ],
   "source": [
    "# extract deproberta features from column df['text']\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"rafalposwiata/deproberta-large-depression\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"rafalposwiata/deproberta-large-depression\", output_hidden_states=True)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(output_dir + '/' + model_name)\n",
    "\n",
    "# model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "# # first convert NaNs to empty strings\n",
    "# df_train['completions'] = df_train['completions'].fillna('')\n",
    "# df_dev['completions'] = df_dev['completions'].fillna('')\n",
    "# df_test['completions'] = df_test['completions'].fillna('')\n",
    "\n",
    "X_train = df_train['completions']\n",
    "X_dev = df_dev['completions']\n",
    "X_test = df_test['completions']\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_dev))\n",
    "print(len(X_test))\n",
    "\n",
    "# extract features from train data\n",
    "X_train_features = []\n",
    "for i in range(len(X_train)):\n",
    "    print('i train: ', i)\n",
    "    input_ids = torch.tensor(tokenizer.encode(X_train[i], add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "    outputs = model(input_ids)\n",
    "    # print('input_ids: ', input_ids.shape)\n",
    "    # print('0: ', outputs.hidden_states[0].shape)\n",
    "    # print('-1: ', outputs.hidden_states[-1].shape)\n",
    "    # print('-2: ', outputs.hidden_states[-2].shape)\n",
    "    # print('1: ', outputs.hidden_states[1].shape)\n",
    "\n",
    "    # print the shape of all hidden layers\n",
    "    # for i in range(len(outputs.hidden_states)):\n",
    "    #     print(i, outputs.hidden_states[i].shape)\n",
    "\n",
    "    # Extract embeddings from output\n",
    "    embeddings = outputs.hidden_states[-1].detach().squeeze(0).mean(dim=0)\n",
    "    # print(embeddings)\n",
    "    print(embeddings.shape)\n",
    "\n",
    "    # print('len: ', len(outputs.hidden_states))\n",
    "    # state_dict = model.state_dict()\n",
    "    # key_bias = state_dict['classifier.out_proj.weight']\n",
    "    # print('key_bias:', key_bias.shape)\n",
    "\n",
    "    # # Get the second-to-last hidden state (layer 23) from the BERT model\n",
    "    # hidden_states = outputs.hidden_states\n",
    "    # second_to_last_layer = hidden_states[-2]\n",
    "    # # Print the shape of the second-to-last layer\n",
    "    # print(second_to_last_layer.shape)\n",
    "\n",
    "    # X_train_features.append(outputs[0].detach().numpy())\n",
    "    # X_train_features.append(key_bias.detach().numpy().squeeze())\n",
    "    X_train_features.append(embeddings.detach().numpy())\n",
    "    # print(X_train_features[i].shape)\n",
    "    # if i % 100 == 0:\n",
    "    #     print(i)\n",
    "\n",
    "# extract features from dev data\n",
    "X_dev_features = []\n",
    "for i in range(len(X_dev)):\n",
    "    print('i dev: ', i)\n",
    "    input_ids = torch.tensor(tokenizer.encode(X_dev[i], add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "    outputs = model(input_ids)\n",
    "    embeddings = outputs.hidden_states[-1].detach().squeeze(0).mean(dim=0)\n",
    "\n",
    "    # state_dict = model.state_dict()\n",
    "    # key_bias = state_dict['classifier.dense.bias']\n",
    "    # print('key_bias:', key_bias.shape)\n",
    "\n",
    "    # X_dev_features.append(outputs[0].detach().numpy())\n",
    "    # X_dev_features.append(key_bias.detach().numpy().squeeze())\n",
    "    X_dev_features.append(embeddings.detach().numpy())\n",
    "    # if i % 100 == 0:\n",
    "    #     print(i)\n",
    "\n",
    "# extract features from test data\n",
    "X_test_features = []\n",
    "for i in range(len(X_test)):\n",
    "    print('i test: ', i)\n",
    "    input_ids = torch.tensor(tokenizer.encode(X_test[i], add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "    outputs = model(input_ids)\n",
    "    embeddings = outputs.hidden_states[-1].detach().squeeze(0).mean(dim=0)\n",
    "\n",
    "    # state_dict = model.state_dict()\n",
    "    # key_bias = state_dict['classifier.dense.bias']\n",
    "    # print('key_bias:', key_bias.shape)\n",
    "\n",
    "    # X_test_features.append(outputs[0].detach().numpy())\n",
    "    # X_test_features.append(key_bias.detach().numpy().squeeze())\n",
    "    X_test_features.append(embeddings.detach().numpy())\n",
    "    # if i % 100 == 0:\n",
    "    #     print(i)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024,)\n",
      "(1024,)\n",
      "(1024,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_features[2].shape)\n",
    "print(X_dev_features[2].shape)\n",
    "print(X_test_features[11].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (163, 1024)\n",
      "dev shape:  (56, 1024)\n",
      "test shape:  (56, 1024)\n"
     ]
    }
   ],
   "source": [
    "# convert to numpy arrays\n",
    "deproberta_features_train = np.array(X_train_features)\n",
    "deproberta_features_dev = np.array(X_dev_features)\n",
    "deproberta_features_test = np.array(X_test_features)\n",
    "\n",
    "print('train shape: ', np.shape(deproberta_features_train))\n",
    "print('dev shape: ', np.shape(deproberta_features_dev))\n",
    "print('test shape: ', np.shape(deproberta_features_test))\n",
    "\n",
    "# deproberta_features_train = np.concatenate((X_train_features, X_dev_features), axis=0)\n",
    "# print('train shape: ', np.shape(deproberta_features_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4084391 , -0.09935732, -0.43163127, ...,  0.89691556,\n",
       "         0.7443206 , -0.06714761],\n",
       "       [ 0.10318018, -0.38136587, -1.2883239 , ...,  0.3765936 ,\n",
       "         0.49099243,  0.2926815 ],\n",
       "       [ 0.07718515, -0.4537094 , -1.2629414 , ...,  0.26990104,\n",
       "         0.06692801,  0.47941303],\n",
       "       ...,\n",
       "       [ 0.6360905 , -0.34990305, -1.087923  , ..., -0.05559449,\n",
       "        -0.0685708 ,  0.7876898 ],\n",
       "       [-0.04165258,  0.13399853, -1.4322317 , ..., -0.13686857,\n",
       "         0.23502058,  0.79712236],\n",
       "       [ 0.28598315, -0.34193912, -0.63913643, ...,  0.25376493,\n",
       "         0.5720404 ,  0.5542471 ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deproberta_features_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (163, 1024)\n",
      "X_dev:  (56, 1024)\n",
      "X_test:  (56, 1024)\n",
      "Epoch 1/30\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 50.6843 - val_loss: 31.2895\n",
      "Epoch 2/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 37.0566 - val_loss: 28.9554\n",
      "Epoch 3/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 32.1471 - val_loss: 27.4439\n",
      "Epoch 4/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 30.7769 - val_loss: 26.0530\n",
      "Epoch 5/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 29.0782 - val_loss: 25.8539\n",
      "Epoch 6/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 28.0985 - val_loss: 25.9580\n",
      "Epoch 7/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 26.2752 - val_loss: 26.1369\n",
      "Epoch 8/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 26.4972 - val_loss: 27.1778\n",
      "Epoch 9/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 25.3075 - val_loss: 26.3379\n",
      "Epoch 10/30\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 23.6561 - val_loss: 25.9708\n",
      "Epoch 11/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 22.7371 - val_loss: 26.2005\n",
      "Epoch 12/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 22.4882 - val_loss: 25.6612\n",
      "Epoch 13/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 21.6961 - val_loss: 25.8154\n",
      "Epoch 14/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 21.0514 - val_loss: 26.3049\n",
      "Epoch 15/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 21.1776 - val_loss: 27.3958\n",
      "Epoch 16/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 20.6516 - val_loss: 26.5252\n",
      "Epoch 17/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 19.3601 - val_loss: 26.8765\n",
      "Epoch 18/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 18.8330 - val_loss: 26.4434\n",
      "Epoch 19/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 18.2611 - val_loss: 25.9442\n",
      "Epoch 20/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 17.8238 - val_loss: 25.5846\n",
      "Epoch 21/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 17.2617 - val_loss: 25.8140\n",
      "Epoch 22/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 17.2783 - val_loss: 26.5137\n",
      "Epoch 23/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 16.7301 - val_loss: 25.5084\n",
      "Epoch 24/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 16.1012 - val_loss: 26.1407\n",
      "Epoch 25/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 15.7364 - val_loss: 26.0091\n",
      "Epoch 26/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 15.2698 - val_loss: 26.1042\n",
      "Epoch 27/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 14.7855 - val_loss: 26.7931\n",
      "Epoch 28/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 14.5109 - val_loss: 26.7963\n",
      "Epoch 29/30\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 14.4003 - val_loss: 26.4154\n",
      "Epoch 30/30\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 13.8586 - val_loss: 26.4539\n",
      "6/6 [==============================] - 0s 544us/step\n",
      "rmse for train:  3.713227038914128\n",
      "mae for train:  2.900932190379848\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 26.4539\n",
      "---- Validation Loss: 26.453861236572266\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "rmse for dev:  5.143331514112743\n",
      "mae for dev:  3.8693352958985736\n"
     ]
    }
   ],
   "source": [
    "# building our own network \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Define the architecture of the neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(1024,)))  # Example hidden layer with 64 units\n",
    "model.add(Dense(1))  # Output layer with 1 unit for PH-Score prediction\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "X_train = np.array(deproberta_features_train)\n",
    "X_dev = np.array(deproberta_features_dev)\n",
    "X_test = np.array(deproberta_features_test)\n",
    "\n",
    "y_train = np.array(df_train['PHQ_Score'])\n",
    "y_dev = np.array(df_dev['PHQ_Score'])\n",
    "y_test = np.array(df_test['PHQ_Score'])\n",
    "\n",
    "print('X_train: ', X_train.shape)\n",
    "print('X_dev: ', X_dev.shape)\n",
    "print('X_test: ', X_test.shape)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_dev, y_dev))\n",
    "\n",
    "y_pred = model.predict(X_train)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "print('rmse for train: ', np.sqrt(mse))\n",
    "print('mae for train: ', mae)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "loss = model.evaluate(X_dev, y_dev)\n",
    "print('---- Validation Loss:', loss)\n",
    "y_pred = model.predict(X_dev)\n",
    "mse = mean_squared_error(y_dev, y_pred)\n",
    "mae = mean_absolute_error(y_dev, y_pred)\n",
    "print('rmse for dev: ', np.sqrt(mse))\n",
    "print('mae for dev: ', mae)\n",
    "\n",
    "\n",
    "# # Make predictions on new data\n",
    "# y_pred = model.predict(X_test)\n",
    "# print('Predictions:', y_pred)\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "# print('rmse for test: ', np.sqrt(mse))\n",
    "# print('mae for test: ', mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (163, 1024)\n",
      "X_dev:  (56, 1024)\n",
      "X_test:  (56, 1024)\n",
      "Epoch 1/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 83.1692 - val_loss: 97.8084\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 74.8807 - val_loss: 95.5043\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 71.1296 - val_loss: 89.5723\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 69.0054 - val_loss: 86.2343\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 69.8747 - val_loss: 86.2992\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 64.8862 - val_loss: 95.4426\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 63.8717 - val_loss: 102.8296\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 62.2531 - val_loss: 106.1604\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 60.3443 - val_loss: 101.2944\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 59.6794 - val_loss: 95.3209\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 57.2263 - val_loss: 94.3008\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 56.2153 - val_loss: 85.7585\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 54.2235 - val_loss: 77.1011\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 51.0121 - val_loss: 75.2168\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 51.5256 - val_loss: 90.1003\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 50.9815 - val_loss: 80.7253\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 50.2318 - val_loss: 77.2948\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 47.3779 - val_loss: 74.7180\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 44.1136 - val_loss: 72.0904\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 45.0456 - val_loss: 67.3563\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 43.2093 - val_loss: 60.8788\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 39.0532 - val_loss: 64.9759\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 39.3239 - val_loss: 58.1741\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 37.4110 - val_loss: 50.6996\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 36.2308 - val_loss: 51.9045\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 34.6306 - val_loss: 47.1487\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 32.9818 - val_loss: 34.9240\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 32.7550 - val_loss: 29.8451\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 33.3075 - val_loss: 29.6632\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 31.2632 - val_loss: 31.6357\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 28.3980 - val_loss: 36.5628\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 28.6956 - val_loss: 39.3508\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 27.1690 - val_loss: 38.4068\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 25.6693 - val_loss: 37.0793\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 25.5744 - val_loss: 34.3356\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 19.2066 - val_loss: 35.7276\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 21.2859 - val_loss: 40.2724\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 22.7712 - val_loss: 39.3573\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 21.6207 - val_loss: 36.9188\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 24.2244 - val_loss: 38.0627\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 20.6480 - val_loss: 38.6147\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 18.3680 - val_loss: 38.6737\n",
      "6/6 [==============================] - 0s 805us/step\n",
      "rmse for train:  3.9537276677145936\n",
      "mae for train:  2.927151385260506\n"
     ]
    }
   ],
   "source": [
    "# Define the architecture of the neural network with early stopping \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Define the architecture of the neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(1024,)))  # Increase the number of units\n",
    "model.add(Dropout(0.2))  # Apply dropout regularization\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())  # Apply batch normalization\n",
    "model.add(Dense(1))  # Output layer with 1 unit for PH-Score prediction\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "X_train = np.array(deproberta_features_train)\n",
    "X_dev = np.array(deproberta_features_dev)\n",
    "X_test = np.array(deproberta_features_test)\n",
    "\n",
    "y_train = np.array(df_train['PHQ_Score'])\n",
    "y_dev = np.array(df_dev['PHQ_Score'])\n",
    "y_test = np.array(df_test['PHQ_Score'])\n",
    "\n",
    "print('X_train: ', X_train.shape)\n",
    "print('X_dev: ', X_dev.shape)\n",
    "print('X_test: ', X_test.shape)\n",
    "\n",
    "# Define early stopping criteria\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=13, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_dev, y_dev), callbacks=[early_stopping])\n",
    "\n",
    "y_pred = model.predict(X_train)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "print('rmse for train: ', np.sqrt(mse))\n",
    "print('mae for train: ', mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 29.6632\n",
      "---- Validation Loss: 29.663238525390625\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "rmse for dev:  5.4463968098111275\n",
      "mae for dev:  4.042612507673247\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Predictions: [[ 7.7760324]\n",
      " [ 5.4124994]\n",
      " [ 3.7230496]\n",
      " [ 3.241036 ]\n",
      " [ 1.6158199]\n",
      " [ 8.344327 ]\n",
      " [ 4.1613293]\n",
      " [ 2.821192 ]\n",
      " [-3.126041 ]\n",
      " [10.228354 ]\n",
      " [ 3.319537 ]\n",
      " [ 4.1988106]\n",
      " [ 1.7389313]\n",
      " [ 9.037851 ]\n",
      " [ 2.8555124]\n",
      " [ 5.7508626]\n",
      " [ 1.0565864]\n",
      " [ 4.9233747]\n",
      " [ 2.7674208]\n",
      " [ 3.5796237]\n",
      " [10.484255 ]\n",
      " [ 7.1372232]\n",
      " [10.2960825]\n",
      " [ 9.606405 ]\n",
      " [12.064783 ]\n",
      " [ 7.997114 ]\n",
      " [ 1.0779961]\n",
      " [10.677179 ]\n",
      " [11.945141 ]\n",
      " [ 3.0789566]\n",
      " [ 3.702032 ]\n",
      " [11.575085 ]\n",
      " [ 6.2170205]\n",
      " [ 3.561885 ]\n",
      " [ 1.6729285]\n",
      " [ 7.8949137]\n",
      " [ 8.025444 ]\n",
      " [-1.8708442]\n",
      " [ 3.6011908]\n",
      " [10.712795 ]\n",
      " [11.11214  ]\n",
      " [ 9.792528 ]\n",
      " [10.535144 ]\n",
      " [14.036395 ]\n",
      " [ 5.526766 ]\n",
      " [ 6.9499903]\n",
      " [ 8.256998 ]\n",
      " [13.4356365]\n",
      " [ 9.5723   ]\n",
      " [ 6.4318986]\n",
      " [ 6.7082376]\n",
      " [-0.6777706]\n",
      " [ 5.9844103]\n",
      " [16.71651  ]\n",
      " [ 4.311885 ]\n",
      " [ 0.4562664]]\n",
      "rmse for test:  5.390288946830027\n",
      "mae for test:  4.427761250308582\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set\n",
    "loss = model.evaluate(X_dev, y_dev)\n",
    "print('---- Validation Loss:', loss)\n",
    "y_pred = model.predict(X_dev)\n",
    "mse = mean_squared_error(y_dev, y_pred)\n",
    "mae = mean_absolute_error(y_dev, y_pred)\n",
    "print('rmse for dev: ', np.sqrt(mse))\n",
    "print('mae for dev: ', mae)\n",
    "\n",
    "# Make predictions on new data\n",
    "y_pred = model.predict(X_test)\n",
    "print('Predictions:', y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('rmse for test: ', np.sqrt(mse))\n",
    "print('mae for test: ', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (163, 1024)\n",
      "X_dev:  (56, 1024)\n",
      "X_test:  (56, 1024)\n",
      "Epoch 1/50\n",
      "1/6 [====>.........................] - ETA: 1s - loss: 69.2919WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 76.6009 - val_loss: 69.4892\n",
      "Epoch 2/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 50.0702WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 74.9240 - val_loss: 72.0847\n",
      "Epoch 3/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 78.8143WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 71.5415 - val_loss: 71.7110\n",
      "Epoch 4/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 48.6499WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 69.9072 - val_loss: 66.2247\n",
      "Epoch 5/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 47.0952WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 67.1798 - val_loss: 62.5978\n",
      "Epoch 6/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 67.8287WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 64.3604 - val_loss: 60.6288\n",
      "Epoch 7/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 29.1034WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 62.6201 - val_loss: 59.3159\n",
      "Epoch 8/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 77.0075WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 62.3026 - val_loss: 63.1678\n",
      "Epoch 9/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 67.8731WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 57.3149 - val_loss: 72.7107\n",
      "Epoch 10/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 77.9205WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 60.1081 - val_loss: 71.9838\n",
      "Epoch 11/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 45.7462WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 55.9805 - val_loss: 67.9711\n",
      "Epoch 12/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 53.5631WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 54.0362 - val_loss: 67.8728\n",
      "Epoch 13/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 53.4348WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 55.0038 - val_loss: 58.8736\n",
      "Epoch 14/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 30.5087WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 51.9138 - val_loss: 56.2328\n",
      "Epoch 15/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 40.7029WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 49.6765 - val_loss: 62.2690\n",
      "Epoch 16/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 39.1275WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 49.4182 - val_loss: 63.9765\n",
      "Epoch 17/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 48.4910WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 48.1633 - val_loss: 63.4781\n",
      "Epoch 18/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 47.8724WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 44.6146 - val_loss: 59.9640\n",
      "Epoch 19/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 41.1417WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 43.9912 - val_loss: 53.6631\n",
      "Epoch 20/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 38.8332WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 41.3710 - val_loss: 48.4598\n",
      "Epoch 21/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 55.6171WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 40.2150 - val_loss: 54.1577\n",
      "Epoch 22/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 35.3464WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 39.8232 - val_loss: 57.9132\n",
      "Epoch 23/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 25.5364WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 36.8403 - val_loss: 50.6185\n",
      "Epoch 24/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 49.3754WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 36.6092 - val_loss: 41.2386\n",
      "Epoch 25/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 38.9818WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 36.0513 - val_loss: 42.3668\n",
      "Epoch 26/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 30.6542WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 32.4578 - val_loss: 62.4112\n",
      "Epoch 27/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 52.6435WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 32.8331 - val_loss: 78.8093\n",
      "Epoch 28/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 26.3438WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 30.5837 - val_loss: 78.2100\n",
      "Epoch 29/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 28.6524WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 28.4607 - val_loss: 60.9696\n",
      "Epoch 30/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 42.6595WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 28.8345 - val_loss: 60.3989\n",
      "Epoch 31/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 36.8813WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 28.7755 - val_loss: 62.3829\n",
      "Epoch 32/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 23.8678WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 26.4784 - val_loss: 84.6268\n",
      "Epoch 33/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 21.6755WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 26.5849 - val_loss: 93.7471\n",
      "Epoch 34/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 16.5150WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 25.4427 - val_loss: 94.9954\n",
      "Epoch 35/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 25.2439WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 24.9468 - val_loss: 88.1995\n",
      "Epoch 36/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 13.1229WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 21.3279 - val_loss: 76.3927\n",
      "Epoch 37/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 24.6917WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 22.9741 - val_loss: 68.4447\n",
      "Epoch 38/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 15.1664WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 21.2942 - val_loss: 61.9285\n",
      "Epoch 39/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 13.3044WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 18.1505 - val_loss: 52.5674\n",
      "Epoch 40/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 16.1012WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 16.4894 - val_loss: 50.6779\n",
      "Epoch 41/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 18.2973WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 17.3897 - val_loss: 50.7528\n",
      "Epoch 42/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 16.0435WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 18.7490 - val_loss: 46.3419\n",
      "Epoch 43/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 20.7873WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 18.7416 - val_loss: 42.0949\n",
      "Epoch 44/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 11.2590WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 17.0780 - val_loss: 36.5727\n",
      "Epoch 45/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 14.8283WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 18.1645 - val_loss: 44.8787\n",
      "Epoch 46/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 18.9096WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 16.0580 - val_loss: 44.0297\n",
      "Epoch 47/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 14.8974WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 15.8867 - val_loss: 37.2506\n",
      "Epoch 48/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 7.5334WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 15.7640 - val_loss: 37.6271\n",
      "Epoch 49/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 19.6945WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 14.5510 - val_loss: 37.6701\n",
      "Epoch 50/50\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 11.9457WARNING:tensorflow:Can save best model only with val_mean_absolute_error available, skipping.\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 14.9662 - val_loss: 37.7957\n",
      "6/6 [==============================] - 0s 669us/step\n",
      "rmse for train:  2.340804681141448\n",
      "mae for train:  1.7545431077114644\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 37.7957\n",
      "---- Best Model Validation Loss: 37.79568862915039\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "rmse for dev:  6.1478196654799495\n",
      "mae for dev:  4.539275763290269\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Predictions: [[10.730069  ]\n",
      " [ 6.5731697 ]\n",
      " [ 2.6902995 ]\n",
      " [ 3.4968433 ]\n",
      " [ 1.3096614 ]\n",
      " [10.355269  ]\n",
      " [ 7.1600494 ]\n",
      " [ 3.4207356 ]\n",
      " [-2.8627992 ]\n",
      " [16.139757  ]\n",
      " [ 1.8828666 ]\n",
      " [ 4.9213533 ]\n",
      " [ 1.3962445 ]\n",
      " [11.962253  ]\n",
      " [ 2.327729  ]\n",
      " [ 7.07751   ]\n",
      " [ 0.7861839 ]\n",
      " [ 6.1228724 ]\n",
      " [ 4.187895  ]\n",
      " [ 4.3117857 ]\n",
      " [17.623991  ]\n",
      " [10.194418  ]\n",
      " [15.329147  ]\n",
      " [15.2252035 ]\n",
      " [20.345793  ]\n",
      " [10.233108  ]\n",
      " [ 0.18148291]\n",
      " [14.8115635 ]\n",
      " [17.34441   ]\n",
      " [ 2.3399677 ]\n",
      " [ 3.0501666 ]\n",
      " [15.142167  ]\n",
      " [ 7.2466764 ]\n",
      " [ 4.6359186 ]\n",
      " [ 0.2973255 ]\n",
      " [14.174214  ]\n",
      " [14.892352  ]\n",
      " [-3.3438795 ]\n",
      " [ 6.112383  ]\n",
      " [15.5763035 ]\n",
      " [15.946766  ]\n",
      " [15.483661  ]\n",
      " [19.030264  ]\n",
      " [20.951588  ]\n",
      " [ 5.7491856 ]\n",
      " [ 8.586229  ]\n",
      " [14.443631  ]\n",
      " [21.073927  ]\n",
      " [12.427027  ]\n",
      " [ 7.6941757 ]\n",
      " [ 9.0512085 ]\n",
      " [ 0.5066145 ]\n",
      " [ 9.350872  ]\n",
      " [27.737793  ]\n",
      " [ 5.0683336 ]\n",
      " [-0.4162612 ]]\n",
      "rmse for test:  5.9498084651203795\n",
      "mae for test:  4.962882499609675\n"
     ]
    }
   ],
   "source": [
    "# finiding the best MAE on the Dev set\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Define the architecture of the neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(1024,)))  # Increase the number of units\n",
    "model.add(Dropout(0.2))  # Apply dropout regularization\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())  # Apply batch normalization\n",
    "model.add(Dense(1))  # Output layer with 1 unit for PH-Score prediction\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "X_train = np.array(deproberta_features_train)\n",
    "X_dev = np.array(deproberta_features_dev)\n",
    "X_test = np.array(deproberta_features_test)\n",
    "\n",
    "y_train = np.array(df_train['PHQ_Score'])\n",
    "y_dev = np.array(df_dev['PHQ_Score'])\n",
    "y_test = np.array(df_test['PHQ_Score'])\n",
    "\n",
    "print('X_train: ', X_train.shape)\n",
    "print('X_dev: ', X_dev.shape)\n",
    "print('X_test: ', X_test.shape)\n",
    "\n",
    "# Define early stopping criteria\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "# Define model checkpoint to save the model with the best MAE on the dev set\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_mean_absolute_error', mode='min', save_best_only=True)\n",
    "\n",
    "# Train the model with early stopping and model checkpoint\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_dev, y_dev), callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "# Load the best model based on MAE on the dev set\n",
    "# best_model = tf.keras.models.load_model('best_model.h5')\n",
    "best_model = model\n",
    "\n",
    "y_pred = best_model.predict(X_train)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "print('rmse for train: ', np.sqrt(mse))\n",
    "print('mae for train: ', mae)\n",
    "\n",
    "# Evaluate the best model on the dev set\n",
    "loss = best_model.evaluate(X_dev, y_dev)\n",
    "print('---- Best Model Validation Loss:', loss)\n",
    "y_pred = best_model.predict(X_dev)\n",
    "mse = mean_squared_error(y_dev, y_pred)\n",
    "mae = mean_absolute_error(y_dev, y_pred)\n",
    "print('rmse for dev: ', np.sqrt(mse))\n",
    "print('mae for dev: ', mae)\n",
    "\n",
    "# Make predictions on new data using the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "print('Predictions:', y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('rmse for test: ', np.sqrt(mse))\n",
    "print('mae for test: ', mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(163, 1024)\n",
      "(56, 1024)\n",
      "(56, 1024)\n",
      "rmse for train:  5.777744766268478\n",
      "mae for train:  4.3703756258967985\n",
      "rmse for dev:  5.5306540307748655\n",
      "mae for dev:  4.25088541402572\n",
      "rmse for test:  6.562915876328408\n",
      "mae for test:  5.224833809708449\n"
     ]
    }
   ],
   "source": [
    "# train a SVR model on the bert_features and PHQ_Score as the target\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X_train = np.array(deproberta_features_train)\n",
    "X_dev = np.array(deproberta_features_dev)\n",
    "X_test = np.array(deproberta_features_test)\n",
    "y_train = np.array(df_train['PHQ_Score'])\n",
    "y_dev = np.array(df_dev['PHQ_Score'])\n",
    "# y_train = np.concatenate((y_train, y_dev), axis=0)\n",
    "y_test = np.array(df_test['PHQ_Score'])\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_dev.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "# normalize X_train, X_dev and X_test\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_dev = scaler.transform(X_dev)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# train a SVR model on X_train and y_train\n",
    "# svr = SVR(kernel='rbf', C=2, gamma=0.1)\n",
    "svr = SVR(kernel='poly', degree=2, C=0.1, gamma='scale', coef0=1)\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# predict on X_train and calculate the mean squared error and mean absolute error\n",
    "y_pred = svr.predict(X_train)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "print('rmse for train: ', np.sqrt(mse))\n",
    "print('mae for train: ', mae)\n",
    "\n",
    "# predict on X_dev and calculate the mean squared error and mean absolute error\n",
    "y_pred = svr.predict(X_dev)\n",
    "mse = mean_squared_error(y_dev, y_pred)\n",
    "mae = mean_absolute_error(y_dev, y_pred)\n",
    "print('rmse for dev: ', np.sqrt(mse))\n",
    "print('mae for dev: ', mae)\n",
    "\n",
    "# predict on X_dev and calculate the mean squared error and mean absolute error\n",
    "y_pred = svr.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('rmse for test: ', np.sqrt(mse))\n",
    "print('mae for test: ', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 0.1, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "RMSE Train: 0.5068586210300113\n",
      "MAE Train: 0.13830509612002317\n",
      "RMSE Dev: 5.764853416160553\n",
      "MAE Dev: 4.5351516743804385\n",
      "RMSE Test: 5.20040873569417\n",
      "MAE Test: 4.321907479185969\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 2, 5, 10, 20, 100],\n",
    "    'gamma': [0.01, 0.1, 1, 2, 5, 10, 100],\n",
    "    'kernel': ['linear', 'rbf', 'poly']\n",
    "}\n",
    "\n",
    "# Create a support vector regression object\n",
    "svr = SVR()\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=svr, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "y_pred = grid_search.predict(X_train)\n",
    "rmse = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "print(\"RMSE Train:\", rmse)\n",
    "print(\"MAE Train:\", mae)\n",
    "\n",
    "# Make predictions on the testing set using the best model\n",
    "y_pred = grid_search.predict(X_dev)\n",
    "# Calculate the root mean squared error and mean absolute error\n",
    "rmse = np.sqrt(mean_squared_error(y_dev, y_pred))\n",
    "mae = mean_absolute_error(y_dev, y_pred)\n",
    "print(\"RMSE Dev:\", rmse)\n",
    "print(\"MAE Dev:\", mae)\n",
    "\n",
    "# Make predictions on the testing set using the best model\n",
    "y_pred = grid_search.predict(X_test)\n",
    "# Calculate the root mean squared error and mean absolute error\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"RMSE Test:\", rmse)\n",
    "print(\"MAE Test:\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "36128b57eae0070e60f84ea73862771965c49f1143c114c27871bafb518edfa1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
