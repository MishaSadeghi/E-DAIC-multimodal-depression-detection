### Starting TaskPrologue of job 768040 on tg094 at Tue 13 Feb 2024 05:39:49 PM CET
Running on cores 0-31 with governor ondemand
Tue Feb 13 17:39:49 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.113.01             Driver Version: 535.113.01   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100-SXM4-40GB          On  | 00000000:01:00.0 Off |                    0 |
| N/A   42C    P0              58W / 400W |      4MiB / 40960MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
### Finished TaskPrologue

/home/hpc/empk/empk004h/depression-detection/code_for_job/speech_text/llama_fine_tuned_in_pipeline
def_dev:      id  ...                                               text
0  300  ...   which will record your body. So I'll show you...
1  301  ...   Yeah, there's all sorts of different studies ...
2  306  ...   Okay, looks like we're good. But let's move a...
3  317  ...   Okay. How long is this? This is probably goin...
4  320  ...   Okay, everything looks good. Okay. Perfect. O...

[5 rows x 7 columns]
max PHQ score in df_train:  23
prompt_number:  1
prompt:   Your task is to read the following text which is an interview with a person and to summarize the key points that might be related to the depression of the person. Be concise and to the point.
prompt_number:  2
prompt:   Your task is to read the following text which is an interview with a person and to summarize the key points that might be related to the depression of the person. Be concise and to the point. It is very essential that you write your answer in the first-person perspective, as if the interviewee is narrating about himself or herself. 
prompt_number:  3
prompt:   After reading the interview, briefly summarize the main aspects that pertain to the person's depression. 
prompt_number:  4
prompt:   Based on the interview, highlight the key factors that might be indicative of the interviewee's depression. 
prompt_number:  5
prompt:   Your task is to summarize the interviewee's main points that could be linked to their depression. Keep it concise. 
prompt_number:  6
prompt:   After reading the interview, identify and summarize the main challenges or difficulties the interviewee faces that are indicative of depression. 
prompt_number:  7
prompt:   Based on the interview, provide a concise analysis of the interviewee's emotional state and behaviors that may indicate the presence of depression. 
prompt_number:  8
prompt:   Read the interview carefully and extract the most significant indicators of depression exhibited by the interviewee. Summarize them concisely. 
prompt_number:  9
prompt:   Your task is to analyze the interviewee's responses and highlight the key signs or symptoms of depression that are evident in the interview. 
prompt_number:  10
prompt:   Provide a brief summary of the interview, focusing on aspects that strongly suggest the presence of depression in the interviewee. 
Extracting Features for Prompt  1  ..... 
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:24<00:24, 24.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:32<00:00, 14.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:32<00:00, 16.32s/it]
Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at /home/hpc/empk/empk004h/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-hf/snapshots/8cca527612d856d7d32bd94f8103728d614eb852 and are newly initialized: ['score.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Traceback (most recent call last):
  File "/home/woody/empk/empk004h/software/privat/conda/envs/myenv/lib/python3.11/site-packages/peft/config.py", line 181, in _get_peft_type
    config_file = hf_hub_download(
                  ^^^^^^^^^^^^^^^^
  File "/home/woody/empk/empk004h/software/privat/conda/envs/myenv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 110, in _inner_fn
    validate_repo_id(arg_value)
  File "/home/woody/empk/empk004h/software/privat/conda/envs/myenv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 158, in validate_repo_id
    raise HFValidationError(
huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './EDI_finetune_llama_output/checkpoint-15000'. Use `repo_type` argument if needed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/hpc/empk/empk004h/depression-detection/code_for_job/speech_text/llama_fine_tuned_in_pipeline/llama_fine_tuned_in_pipeline.py", line 383, in <module>
    X_train_features, X_dev_features, X_test_features = extract_features(df_train, df_dev, df_test)
                                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/empk/empk004h/depression-detection/code_for_job/speech_text/llama_fine_tuned_in_pipeline/llama_fine_tuned_in_pipeline.py", line 343, in extract_features
    X_train_features = finetuned_llama_inference.run_inference(texts_train)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/empk/empk004h/depression-detection/code_for_job/speech_text/llama_fine_tuned_in_pipeline/finetuned_llama_inference.py", line 72, in run_inference
    output = llama_inference(texts, model_path, './EDI_finetune_llama_output/checkpoint-15000')
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hpc/empk/empk004h/depression-detection/code_for_job/speech_text/llama_fine_tuned_in_pipeline/finetuned_llama_inference.py", line 52, in llama_inference
    model = PeftModel.from_pretrained(model, llama_adapter_dir)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/woody/empk/empk004h/software/privat/conda/envs/myenv/lib/python3.11/site-packages/peft/peft_model.py", line 305, in from_pretrained
    PeftConfig._get_peft_type(
  File "/home/woody/empk/empk004h/software/privat/conda/envs/myenv/lib/python3.11/site-packages/peft/config.py", line 187, in _get_peft_type
    raise ValueError(f"Can't find '{CONFIG_NAME}' at '{model_id}'")
ValueError: Can't find 'adapter_config.json' at './EDI_finetune_llama_output/checkpoint-15000'
srun: error: tg094: task 0: Exited with exit code 1
srun: launch/slurm: _step_signal: Terminating StepId=768040.0
=== JOB_STATISTICS ===
=== current date     : Tue 13 Feb 2024 05:54:08 PM CET
= Job-ID             : 768040 on tinygpu
= Job-Name           : job_llama_fine_tuned_in_pipeline.sh
= Job-Command        : /home/hpc/empk/empk004h/depression-detection/code_for_job/speech_text/llama_fine_tuned_in_pipeline/job_llama_fine_tuned_in_pipeline.sh
= Initial workdir    : /home/hpc/empk/empk004h/depression-detection/code_for_job/speech_text/llama_fine_tuned_in_pipeline
= Queue/Partition    : a100
= Slurm account      : empk with QOS=normal
= Requested resources: cpu=32,mem=120000M,node=1,billing=32,gres/gpu=1,gres/gpu:a100=1 for 20:00:00
= Elapsed runtime    : 00:14:20
= Total RAM usage    : 0.6 GiB of requested 117 GiB (0.5%)   
= Node list          : tg094
= Subm/Elig/Start/End: 2024-02-13T17:36:00 / 2024-02-13T17:36:00 / 2024-02-13T17:39:48 / 2024-02-13T17:54:08
======================
=== Quota infos ======
    Path              Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc           76.4G   104.9G   209.7G        N/A  45,055      500K   1,000K        N/A    
    /home/vault        274.1G     0.0K     0.0K        N/A      74K     300K     450K        N/A    
    /home/woody        311.0G   500.0G   750.0G        N/A     314K   5,000K   7,500K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
NVIDIA A100-SXM4-40GB, 00000000:01:00.0, 3920317, 2 %, 0 %, 4208 MiB, 42332 ms
