### Starting TaskPrologue of job 805348 on tg083 at Tue 23 Apr 2024 05:27:46 PM CEST
Running on cores 4-5,14-15,36-37,46-47 with governor ondemand
Tue Apr 23 17:27:46 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 3080        On  |   00000000:3E:00.0 Off |                  N/A |
| 30%   33C    P8             24W /  300W |       1MiB /  10240MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

/home/hpc/empk/empk004h/depression-detection/code_for_job/speech_text/bias_study
labels_train_df:      id   Gender  PHQ_Binary  PHQ_Score  PCL-C (PTSD)  PTSD Severity
0  302     male           0          4             0             28
1  303   female           0          0             0             17
2  304   female           0          6             0             20
3  305     male           0          7             0             28
4  307  female            0          4             0             23
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:22<?, ?it/s]
Traceback (most recent call last):
  File "/home/hpc/empk/empk004h/depression-detection/code_for_job/speech_text/bias_study/bias_study.py", line 361, in <module>
    guidance = load_model_and_tokenizer("meta-llama/Llama-2-7b-chat-hf", bnb_config, n_gpus, max_memory, token)
  File "/home/hpc/empk/empk004h/depression-detection/code_for_job/speech_text/bias_study/bias_study.py", line 59, in load_model_and_tokenizer
    model = AutoModelForCausalLM.from_pretrained(
  File "/home/woody/empk/empk004h/software/private/conda/envs/venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 563, in from_pretrained
    return model_class.from_pretrained(
  File "/home/woody/empk/empk004h/software/private/conda/envs/venv/lib/python3.10/site-packages/transformers/modeling_utils.py", line 3531, in from_pretrained
    ) = cls._load_pretrained_model(
  File "/home/woody/empk/empk004h/software/private/conda/envs/venv/lib/python3.10/site-packages/transformers/modeling_utils.py", line 3958, in _load_pretrained_model
    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
  File "/home/woody/empk/empk004h/software/private/conda/envs/venv/lib/python3.10/site-packages/transformers/modeling_utils.py", line 812, in _load_state_dict_into_meta_model
    set_module_tensor_to_device(model, param_name, param_device, **set_module_kwargs)
  File "/home/woody/empk/empk004h/software/private/conda/envs/venv/lib/python3.10/site-packages/accelerate/utils/modeling.py", line 399, in set_module_tensor_to_device
    new_value = value.to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 9.77 GiB of which 15.94 MiB is free. Including non-PyTorch memory, this process has 9.75 GiB memory in use. Of the allocated memory 9.54 GiB is allocated by PyTorch, and 1.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
srun: error: tg083: task 0: Exited with exit code 1
srun: Terminating StepId=805348.0
=== JOB_STATISTICS ===
=== current date     : Tue 23 Apr 2024 05:28:25 PM CEST
= Job-ID             : 805348 on tinygpu
= Job-Name           : job_bias_study.sh
= Job-Command        : /home/hpc/empk/empk004h/depression-detection/code_for_job/speech_text/bias_study/job_bias_study.sh
= Initial workdir    : /home/hpc/empk/empk004h/depression-detection/code_for_job/speech_text/bias_study
= Queue/Partition    : rtx3080
= Slurm account      : empk with QOS=normal
= Requested resources:  for 20:00:00
= Elapsed runtime    : 00:00:40
= Total RAM usage    : 0.7 GiB of requested  GiB (%)   
= Node list          : tg083
= Subm/Elig/Start/End: 2024-04-23T17:27:44 / 2024-04-23T17:27:44 / 2024-04-23T17:27:45 / 2024-04-23T17:28:25
======================
=== Quota infos ======
    Path              Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc           50.0G   104.9G   209.7G        N/A  21,866      500K   1,000K        N/A    
    /home/vault       2517.1G     0.0K     0.0K        N/A      86K     300K     450K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
NVIDIA GeForce RTX 3080, 00000000:3E:00.0, 3370491, 3 %, 0 %, 9980 MiB, 24438 ms
