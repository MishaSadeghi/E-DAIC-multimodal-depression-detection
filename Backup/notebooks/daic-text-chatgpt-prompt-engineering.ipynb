{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = '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' # for my personal account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "transcripts_df = pd.read_csv('../data/DAIC/transcripts.csv')\n",
    "# remove first column\n",
    "transcripts_df = transcripts_df.iloc[:,1:]\n",
    "transcripts_df.columns = ['id', 'text']\n",
    "\n",
    "labels_dev_df = pd.read_csv('../data/DAIC/labels/dev_split.csv')\n",
    "labels_dev_df.columns = ['id', 'Gender', 'PHQ_Binary', 'PHQ_Score', 'PCL-C (PTSD)', 'PTSD Severity']\n",
    "\n",
    "labels_train_df = pd.read_csv('../data/DAIC/labels/train_split.csv')\n",
    "labels_train_df.columns = ['id', 'Gender', 'PHQ_Binary', 'PHQ_Score', 'PCL-C (PTSD)', 'PTSD Severity']\n",
    "\n",
    "labels_test_df = pd.read_csv('../data/DAIC/labels/test_split.csv')\n",
    "labels_test_df.columns = ['id', 'Gender', 'PHQ_Binary', 'PHQ_Score', 'PCL-C (PTSD)', 'PTSD Severity']\n",
    "\n",
    "# merge dataframes on id\n",
    "df_dev = pd.merge(labels_dev_df, transcripts_df, on='id')\n",
    "df_train = pd.merge(labels_train_df, transcripts_df, on='id')\n",
    "df_test = pd.merge(labels_test_df, transcripts_df, on='id')\n",
    "\n",
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def clean_text(text):\n",
    "    # remove punctuation and special characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # lowercase all words\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = [word for word in text.split() if word not in stop_words]\n",
    "\n",
    "    # stem/lemmatize words\n",
    "    # stemmer = PorterStemmer()\n",
    "    # text = [stemmer.stem(word) for word in text]\n",
    "\n",
    "    # remove numbers\n",
    "    # text = [word for word in text if not word.isdigit()]\n",
    "\n",
    "    return \" \".join(text)\n",
    "\n",
    "# clean all transcripts\n",
    "df_dev['text'] = df_dev['text'].apply(clean_text)\n",
    "df_train['text'] = df_train['text'].apply(clean_text)\n",
    "df_test['text'] = df_test['text'].apply(clean_text)\n",
    "\n",
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!! this is the prompt that we will use for Chat-GPT API !!!!!\n",
    "prompt = \"\"\" Here is an interview with a person who might have depression. Determine if the text might be relevant to depression. Explain your answer in a verbose manner.  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-3 cost estimator for all completions\n",
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "\n",
    "token_counts = []\n",
    "# for all tokens in all transcripts in dev, train, and test sets\n",
    "for text in df_dev['text'].tolist() + df_train['text'].tolist() + df_test['text'].tolist():\n",
    "    # tokenize text\n",
    "    tokens = tokenizer.encode(text)\n",
    "    # tokenize prompt\n",
    "    prompt_tokens = tokenizer.encode(prompt)\n",
    "\n",
    "    # append token count to list\n",
    "    token_counts.append(len(tokens) + len(prompt_tokens) + 512)\n",
    "\n",
    "# Final cost estimataion\n",
    "print(f'Estimated cost: ${(sum(token_counts) / 1000 * 0.002)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def make_prompt(prompt, text):\n",
    "    return \"\"\"{}\\nText:\\n{}\"\"\".format(prompt, text)\n",
    "\n",
    "# extract ChatGPT completions for each transcript\n",
    "def get_completions(prompt, text):\n",
    "    prompt = make_prompt(prompt, text)\n",
    "    # send request to API\n",
    "    response = requests.post(\n",
    "        \"http://localhost:4100/parallel-requests\",\n",
    "        json={\"prompts\": prompt}\n",
    "    )\n",
    "    # get response\n",
    "    response = response.json()\n",
    "    return response[\"response\"]\n",
    "\n",
    "def get_completions_batch(prompt, texts):\n",
    "    prompts = [make_prompt(prompt, text) for text in texts]\n",
    "    prompts = \"---\".join(prompts)\n",
    "\n",
    "    # send request to API\n",
    "    response = requests.post(\n",
    "        \"http://localhost:4100/parallel-requests\",\n",
    "        json={\"prompts\": prompts}\n",
    "    )\n",
    "\n",
    "    # get response\n",
    "    response = response.json()\n",
    "    return response[\"response\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the result\n",
    "# get completion for the first transcript in the dev set\n",
    "id = 347\n",
    "# find dv_dev row with id\n",
    "row = df_dev[df_dev['id'] == id]\n",
    "# get the value of the text column\n",
    "text = row['text'].values[0]\n",
    "print('This is the text:')\n",
    "print(make_prompt(prompt, text))\n",
    "print('------------------------------------')\n",
    "print('This is the completion:')\n",
    "completion = get_completions(prompt, text)\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we're sure that the prompt and completion are working as expected\n",
    "# Let's extract completions for all transcripts in the train, dev, and test sets\n",
    "# we will do this in batches of 10 to prevent API rate limits\n",
    "\n",
    "# get complettions in parallel in batches of 10\n",
    "df_dev['completions'] = ''\n",
    "for i in range(0, len(df_dev), 10):\n",
    "    print(f'Getting completions for dev transcripts {i} to {i+10}...')\n",
    "    # create a new column for completions\n",
    "    completions = get_completions_batch(prompt, df_dev['text'][i:i+10])\n",
    "    # convert list of completions to dataframe\n",
    "    df_completions = pd.DataFrame(completions, columns=['completions'])\n",
    "    # add completions to df_dev\n",
    "    df_dev['completions'][i:i+10] = df_completions['completions']\n",
    "\n",
    "\n",
    "df_train['completions'] = ''\n",
    "for i in range(0, len(df_train), 10):\n",
    "    print(f'Getting completions for train transcripts {i} to {i+10}...')\n",
    "    # create a new column for completions\n",
    "    completions = get_completions_batch(prompt, df_train['text'][i:i+10])\n",
    "    # convert list of completions to dataframe\n",
    "    df_completions = pd.DataFrame(completions, columns=['completions'])\n",
    "    # add completions to df_dev\n",
    "    df_train['completions'][i:i+10] = df_completions['completions']\n",
    "\n",
    "\n",
    "df_test['completions'] = ''\n",
    "for i in range(0, len(df_test), 10):\n",
    "    print(f'Getting completions for test transcripts {i} to {i+10}...')\n",
    "    # create a new column for completions\n",
    "    completions = get_completions_batch(prompt, df_test['text'][i:i+10])\n",
    "    # convert list of completions to dataframe\n",
    "    df_completions = pd.DataFrame(completions, columns=['completions'])\n",
    "    # add completions to df_dev\n",
    "    df_test['completions'][i:i+10] = df_completions['completions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract deproberta features from column df['text']\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"rafalposwiata/deproberta-large-depression\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"rafalposwiata/deproberta-large-depression\")\n",
    "\n",
    "# model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "X_train = df_train['completions']\n",
    "X_dev = df_dev['completions']\n",
    "X_test = df_test['completions']\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_dev))\n",
    "print(len(X_test))\n",
    "\n",
    "# extract features from train data\n",
    "X_train_features = []\n",
    "for i in range(len(X_train)):\n",
    "    input_ids = torch.tensor(tokenizer.encode(X_train[i], add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "    outputs = model(input_ids)\n",
    "    X_train_features.append(outputs[0].detach().numpy())\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "\n",
    "# extract features from dev data\n",
    "X_dev_features = []\n",
    "for i in range(len(X_dev)):\n",
    "    input_ids = torch.tensor(tokenizer.encode(X_dev[i], add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "    outputs = model(input_ids)\n",
    "    X_dev_features.append(outputs[0].detach().numpy())\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "\n",
    "# extract features from test data\n",
    "X_test_features = []\n",
    "for i in range(len(X_test)):\n",
    "    input_ids = torch.tensor(tokenizer.encode(X_test[i], add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "    outputs = model(input_ids)\n",
    "    X_test_features.append(outputs[0].detach().numpy())\n",
    "    if i % 100 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy arrays\n",
    "deproberta_features_train = np.array(X_train_features)\n",
    "deproberta_features_dev = np.array(X_dev_features)\n",
    "deproberta_features_test = np.array(X_test_features)\n",
    "\n",
    "# reshape the features\n",
    "deproberta_features_train = deproberta_features_train.reshape(deproberta_features_train.shape[0], deproberta_features_train.shape[2])\n",
    "deproberta_features_dev = deproberta_features_dev.reshape(deproberta_features_dev.shape[0], deproberta_features_dev.shape[2])\n",
    "deproberta_features_test = deproberta_features_test.reshape(deproberta_features_test.shape[0], deproberta_features_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a SVR model on the bert_features and PHQ_Score as the target\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X_train = np.array(deproberta_features_train)\n",
    "X_dev = np.array(deproberta_features_dev)\n",
    "X_test = np.array(deproberta_features_test)\n",
    "y_train = np.array(df_train['PHQ_Score'])\n",
    "y_dev = np.array(df_dev['PHQ_Score'])\n",
    "y_test = np.array(df_test['PHQ_Score'])\n",
    "\n",
    "# train a SVR model on X_train and y_train\n",
    "svr = SVR(kernel='rbf', C=3.5, gamma=0.1)\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# predict on X_train and calculate the mean squared error and mean absolute error\n",
    "y_pred = svr.predict(X_train)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "print('rmse for train: ', np.sqrt(mse))\n",
    "print('mae for train: ', mae)\n",
    "\n",
    "# predict on X_dev and calculate the mean squared error and mean absolute error\n",
    "y_pred = svr.predict(X_dev)\n",
    "mse = mean_squared_error(y_dev, y_pred)\n",
    "mae = mean_absolute_error(y_dev, y_pred)\n",
    "print('rmse for dev: ', np.sqrt(mse))\n",
    "print('mae for dev: ', mae)\n",
    "\n",
    "# predict on X_dev and calculate the mean squared error and mean absolute error\n",
    "y_pred = svr.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('rmse for test: ', np.sqrt(mse))\n",
    "print('mae for test: ', mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bfacfc1d625e194ec392e142e035347b9b52a1a4dcc1c7f95dc9d16649dbfb09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
