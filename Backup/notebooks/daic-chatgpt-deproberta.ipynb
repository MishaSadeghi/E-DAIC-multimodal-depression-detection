{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is based on ChatGPT outputs of transcripts using this prompt:\n",
    "# Can you identify any signs or indications of depression in the following text, which is a transcript of an interview with a person?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read an xslx file\n",
    "chatgpt_text_df = pd.read_excel('../data/DAIC/DAIC_Chatgpt_text_1.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "# Change column names\n",
    "chatgpt_text_df.columns = ['id', 'text']\n",
    "chatgpt_text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv file\n",
    "labels_dev_df = pd.read_csv('../data/DAIC/labels/dev_split.csv')\n",
    "labels_dev_df.head()\n",
    "\n",
    "# rename columns\n",
    "labels_dev_df.columns = ['id', 'Gender', 'PHQ_Binary', 'PHQ_Score', 'PCL-C (PTSD)', 'PTSD Severity']\n",
    "labels_dev_df.head()\n",
    "\n",
    "# import csv file\n",
    "labels_train_df = pd.read_csv('../data/DAIC/labels/train_split.csv')\n",
    "labels_train_df.head()\n",
    "\n",
    "# rename columns\n",
    "labels_train_df.columns = ['id', 'Gender', 'PHQ_Binary', 'PHQ_Score', 'PCL-C (PTSD)', 'PTSD Severity']\n",
    "labels_train_df.head()\n",
    "\n",
    "# import csv file\n",
    "labels_test_df = pd.read_csv('../data/DAIC/labels/test_split.csv')\n",
    "labels_test_df.head()\n",
    "\n",
    "# rename columns\n",
    "labels_test_df.columns = ['id', 'Gender', 'PHQ_Binary', 'PHQ_Score', 'PCL-C (PTSD)', 'PTSD Severity']\n",
    "labels_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge two dataframes on id\n",
    "df_dev = pd.merge(labels_dev_df, chatgpt_text_df, on='id')\n",
    "df_dev.head()\n",
    "\n",
    "df_train = pd.merge(labels_train_df, chatgpt_text_df, on='id')\n",
    "df_train.head()\n",
    "\n",
    "df_test = pd.merge(labels_test_df, chatgpt_text_df, on='id')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract deproberta features from column df['text']\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"rafalposwiata/deproberta-large-depression\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"rafalposwiata/deproberta-large-depression\")\n",
    "\n",
    "# model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "X_train = df_train['text']\n",
    "X_dev = df_dev['text']\n",
    "X_test = df_test['text']\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(X_dev))\n",
    "print(len(X_test))\n",
    "\n",
    "# extract features from train data\n",
    "X_train_features = []\n",
    "for i in range(len(X_train)):\n",
    "    input_ids = torch.tensor(tokenizer.encode(X_train[i], add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "    outputs = model(input_ids)\n",
    "    X_train_features.append(outputs[0].detach().numpy())\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "\n",
    "# extract features from dev data\n",
    "X_dev_features = []\n",
    "for i in range(len(X_dev)):\n",
    "    input_ids = torch.tensor(tokenizer.encode(X_dev[i], add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "    outputs = model(input_ids)\n",
    "    X_dev_features.append(outputs[0].detach().numpy())\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "\n",
    "# extract features from test data\n",
    "X_test_features = []\n",
    "for i in range(len(X_test)):\n",
    "    input_ids = torch.tensor(tokenizer.encode(X_test[i], add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "    outputs = model(input_ids)\n",
    "    X_test_features.append(outputs[0].detach().numpy())\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the shape of the features\n",
    "deproberta_features_train = np.array(X_train_features)\n",
    "deproberta_features_dev = np.array(X_dev_features)\n",
    "deproberta_features_test = np.array(X_test_features)\n",
    "\n",
    "# reshape the features\n",
    "deproberta_features_train = deproberta_features_train.reshape(deproberta_features_train.shape[0], deproberta_features_train.shape[2])\n",
    "deproberta_features_dev = deproberta_features_dev.reshape(deproberta_features_dev.shape[0], deproberta_features_dev.shape[2])\n",
    "deproberta_features_test = deproberta_features_test.reshape(deproberta_features_test.shape[0], deproberta_features_test.shape[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the shape of the bert features\n",
    "print(deproberta_features_train.shape)\n",
    "print(deproberta_features_dev.shape)\n",
    "print(deproberta_features_test.shape)\n",
    "\n",
    "print(deproberta_features_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a SVR model on the bert_features and PHQ_Score as the target\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X_train = np.array(bert_features_train)\n",
    "X_dev = np.array(bert_features_dev)\n",
    "X_test = np.array(bert_features_test)\n",
    "y_train = np.array(df_train['PHQ_Score'])\n",
    "y_dev = np.array(df_dev['PHQ_Score'])\n",
    "y_test = np.array(df_test['PHQ_Score'])\n",
    "\n",
    "# train a SVR model on X_train and y_train\n",
    "svr = SVR(kernel='rbf', C=3.5, gamma=0.1)\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# predict on X_train and calculate the mean squared error and mean absolute error\n",
    "y_pred = svr.predict(X_train)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "print('rmse for train: ', np.sqrt(mse))\n",
    "print('mae for train: ', mae)\n",
    "\n",
    "# predict on X_dev and calculate the mean squared error and mean absolute error\n",
    "y_pred = svr.predict(X_dev)\n",
    "mse = mean_squared_error(y_dev, y_pred)\n",
    "mae = mean_absolute_error(y_dev, y_pred)\n",
    "print('rmse for dev: ', np.sqrt(mse))\n",
    "print('mae for dev: ', mae)\n",
    "\n",
    "# predict on X_dev and calculate the mean squared error and mean absolute error\n",
    "y_pred = svr.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('rmse for test: ', np.sqrt(mse))\n",
    "print('mae for test: ', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the best parameters for SVR\n",
    "\n",
    "# define the parameter values that should be searched\n",
    "C_range = [1, 2, 3, 10, 20, 30, 100, 200, 300, 1000]\n",
    "gamma_range = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "\n",
    "# find the best parameters for SVR on the dev set\n",
    "\n",
    "best_c = 1\n",
    "best_gamma = 0.001\n",
    "best_mae = 1000\n",
    "for c in C_range:\n",
    "    for gamma in gamma_range:\n",
    "        svr = SVR(kernel='rbf', C=c, gamma=gamma)\n",
    "        svr.fit(X_train, y_train)\n",
    "        y_pred = svr.predict(X_dev)\n",
    "        mae = mean_absolute_error(y_dev, y_pred)\n",
    "        if mae < best_mae:\n",
    "            best_c = c\n",
    "            best_gamma = gamma\n",
    "            best_mae = mae\n",
    "\n",
    "print('best c: ', best_c)\n",
    "print('best gamma: ', best_gamma)\n",
    "print('best mae: ', best_mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bfacfc1d625e194ec392e142e035347b9b52a1a4dcc1c7f95dc9d16649dbfb09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
